{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X2ra1B2uycc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\mhme2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "train_data = pd.read_csv('Q3_train.csv')\n",
        "train_images = torch.tensor(train_data.drop('label', axis=1).values)\n",
        "train_labels = torch.tensor(train_data['label'].values)\n",
        "test_data = pd.read_csv('Q3_test.csv')\n",
        "test_images = torch.tensor(test_data.drop('label', axis=1).values)\n",
        "test_labels = torch.tensor(test_data['label'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "kwHiiKcSycc-",
        "outputId": "ac7a5d43-b237-442c-806f-c31b00d07432"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O',\n",
        " 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Z', 'X', 'Y']\n",
        "plt.figure(figsize=(5,5))\n",
        "for i in range(9):\n",
        "    j=np.random.randint(0,train_images.shape[0])\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(train_images[j].reshape(28,28), cmap='gray')\n",
        "    plt.title( alphabet[ train_labels[j].item() ] )\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bMLR42Wxycc_"
      },
      "outputs": [],
      "source": [
        "class customDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self, index):\n",
        "        return self.images[index], self.labels[index]\n",
        "\n",
        "train_dataset = customDataset(train_images, train_labels)\n",
        "test_dataset = customDataset(test_images, test_labels)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lNgoUZwzycdA"
      },
      "outputs": [],
      "source": [
        "class NN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            nn.Linear(784, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 200),\n",
        "            nn.BatchNorm1d(200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 150),\n",
        "            nn.BatchNorm1d(150),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(150, 70),\n",
        "            nn.BatchNorm1d(70),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(70, 26)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.layer_stack(x)\n",
        "        x = torch.softmax(x, dim=1)\n",
        "        return x\n",
        "simple_model_SGD = NN()\n",
        "simple_model_Adam = NN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PvpGLU-vycdA"
      },
      "outputs": [],
      "source": [
        "def train_loop(data_loader, model, optimizer, loss_fn):\n",
        "    size = len(data_loader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        X = X.float()\n",
        "        y = y.long()\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            print(f\"gradient mean= {model.layer_stack[0].weight.grad.mean()}\")\n",
        "\n",
        "def test_loop(model, loss_fn, test_losses, train_losses):\n",
        "    size = len(test_dataloader.dataset)\n",
        "    num_batches = len(test_dataloader)\n",
        "    test_loss, correct, train_loss = 0, 0, 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_dataloader:\n",
        "            X = X.float()\n",
        "            y = y.long()\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    test_losses.append(test_loss)\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    size = len(train_dataloader.dataset)\n",
        "    num_batches = len(train_dataloader)\n",
        "    test_loss, correct, train_loss = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in train_dataloader:\n",
        "            X = X.float()\n",
        "            y = y.long()\n",
        "            pred = model(X)\n",
        "            train_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    train_loss /= num_batches\n",
        "    train_losses.append(train_loss)\n",
        "    correct /= size\n",
        "    print(f\"Train Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7CcFVNAoycdB",
        "outputId": "d54c584f-5aa6-4f3d-8d6e-447e6716072f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-----------------------------\n",
            "loss: 3.257147  [    0/27455]\n",
            "gradient mean= 1.7414018657291308e-05\n",
            "loss: 3.249313  [ 6400/27455]\n",
            "gradient mean= -1.2173792129033245e-05\n",
            "loss: 3.188686  [12800/27455]\n",
            "gradient mean= -3.349485996295698e-05\n",
            "loss: 3.151005  [19200/27455]\n",
            "gradient mean= -8.821204392006621e-05\n",
            "loss: 3.122405  [25600/27455]\n",
            "gradient mean= -6.914819823578e-05\n",
            "Test Error: \n",
            " Accuracy: 20.8%, Avg loss: 3.153801 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 28.4%, Avg loss: 3.107955 \n",
            "\n",
            "Epoch 2\n",
            "-----------------------------\n",
            "loss: 3.174323  [    0/27455]\n",
            "gradient mean= 3.016987830051221e-05\n",
            "loss: 3.023911  [ 6400/27455]\n",
            "gradient mean= 1.4607557204726618e-05\n",
            "loss: 3.030168  [12800/27455]\n",
            "gradient mean= -5.055803922004998e-05\n",
            "loss: 3.015961  [19200/27455]\n",
            "gradient mean= -2.3076176148606464e-05\n",
            "loss: 3.047846  [25600/27455]\n",
            "gradient mean= 2.9065698981867172e-05\n",
            "Test Error: \n",
            " Accuracy: 32.1%, Avg loss: 3.089773 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 41.1%, Avg loss: 2.979477 \n",
            "\n",
            "Epoch 3\n",
            "-----------------------------\n",
            "loss: 2.938168  [    0/27455]\n",
            "gradient mean= 7.247154371725628e-06\n",
            "loss: 2.924776  [ 6400/27455]\n",
            "gradient mean= -1.4977899809309747e-07\n",
            "loss: 2.934106  [12800/27455]\n",
            "gradient mean= -2.4401013433816843e-05\n",
            "loss: 2.871117  [19200/27455]\n",
            "gradient mean= 2.965605199278798e-05\n",
            "loss: 2.775986  [25600/27455]\n",
            "gradient mean= 1.7943160855793394e-05\n",
            "Test Error: \n",
            " Accuracy: 41.6%, Avg loss: 2.983369 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 50.7%, Avg loss: 2.841281 \n",
            "\n",
            "Epoch 4\n",
            "-----------------------------\n",
            "loss: 2.891498  [    0/27455]\n",
            "gradient mean= -1.691961006144993e-05\n",
            "loss: 2.788146  [ 6400/27455]\n",
            "gradient mean= 2.5954444936360233e-05\n",
            "loss: 2.879176  [12800/27455]\n",
            "gradient mean= 4.823203198611736e-05\n",
            "loss: 2.789622  [19200/27455]\n",
            "gradient mean= 2.3705519197392277e-05\n",
            "loss: 2.724646  [25600/27455]\n",
            "gradient mean= 4.5853230403736234e-05\n",
            "Test Error: \n",
            " Accuracy: 48.9%, Avg loss: 2.910468 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 59.1%, Avg loss: 2.759663 \n",
            "\n",
            "Epoch 5\n",
            "-----------------------------\n",
            "loss: 2.721735  [    0/27455]\n",
            "gradient mean= -2.8245793146197684e-05\n",
            "loss: 2.804363  [ 6400/27455]\n",
            "gradient mean= 9.678912647359539e-06\n",
            "loss: 2.691864  [12800/27455]\n",
            "gradient mean= 1.5336627257056534e-05\n",
            "loss: 2.662440  [19200/27455]\n",
            "gradient mean= -6.140703771961853e-05\n",
            "loss: 2.680206  [25600/27455]\n",
            "gradient mean= 2.3624341338290833e-05\n",
            "Test Error: \n",
            " Accuracy: 53.9%, Avg loss: 2.888776 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 70.6%, Avg loss: 2.673267 \n",
            "\n",
            "Epoch 6\n",
            "-----------------------------\n",
            "loss: 2.652204  [    0/27455]\n",
            "gradient mean= 4.998169242753647e-05\n",
            "loss: 2.650511  [ 6400/27455]\n",
            "gradient mean= 1.9268456526333466e-05\n",
            "loss: 2.626239  [12800/27455]\n",
            "gradient mean= -0.0001207130917464383\n",
            "loss: 2.589458  [19200/27455]\n",
            "gradient mean= 1.5241966139001306e-05\n",
            "loss: 2.593712  [25600/27455]\n",
            "gradient mean= -1.1497309969854541e-05\n",
            "Test Error: \n",
            " Accuracy: 54.8%, Avg loss: 2.886713 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 77.1%, Avg loss: 2.615494 \n",
            "\n",
            "Epoch 7\n",
            "-----------------------------\n",
            "loss: 2.550984  [    0/27455]\n",
            "gradient mean= 9.520314051769674e-05\n",
            "loss: 2.521681  [ 6400/27455]\n",
            "gradient mean= -6.269916775636375e-05\n",
            "loss: 2.497159  [12800/27455]\n",
            "gradient mean= 9.321744437329471e-05\n",
            "loss: 2.460006  [19200/27455]\n",
            "gradient mean= 3.034113979083486e-05\n",
            "loss: 2.458364  [25600/27455]\n",
            "gradient mean= 2.1399464458227158e-05\n",
            "Test Error: \n",
            " Accuracy: 70.3%, Avg loss: 2.719848 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 87.0%, Avg loss: 2.472574 \n",
            "\n",
            "Epoch 8\n",
            "-----------------------------\n",
            "loss: 2.419948  [    0/27455]\n",
            "gradient mean= 3.317477603559382e-05\n",
            "loss: 2.507784  [ 6400/27455]\n",
            "gradient mean= 5.089083424536511e-05\n",
            "loss: 2.466940  [12800/27455]\n",
            "gradient mean= 1.1348184671078343e-05\n",
            "loss: 2.464054  [19200/27455]\n",
            "gradient mean= 2.961773679999169e-05\n",
            "loss: 2.423503  [25600/27455]\n",
            "gradient mean= -2.325487457710551e-06\n",
            "Test Error: \n",
            " Accuracy: 67.5%, Avg loss: 2.711213 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 87.7%, Avg loss: 2.453078 \n",
            "\n",
            "Epoch 9\n",
            "-----------------------------\n",
            "loss: 2.448806  [    0/27455]\n",
            "gradient mean= -7.180149987107143e-05\n",
            "loss: 2.486064  [ 6400/27455]\n",
            "gradient mean= 2.607419082778506e-05\n",
            "loss: 2.440006  [12800/27455]\n",
            "gradient mean= 9.608706932340283e-07\n",
            "loss: 2.395240  [19200/27455]\n",
            "gradient mean= 5.057239832240157e-05\n",
            "loss: 2.398767  [25600/27455]\n",
            "gradient mean= -0.0001261595170944929\n",
            "Test Error: \n",
            " Accuracy: 69.2%, Avg loss: 2.714670 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 96.0%, Avg loss: 2.407323 \n",
            "\n",
            "Epoch 10\n",
            "-----------------------------\n",
            "loss: 2.395146  [    0/27455]\n",
            "gradient mean= 4.9091911932919174e-05\n",
            "loss: 2.346324  [ 6400/27455]\n",
            "gradient mean= 3.826503598247655e-05\n",
            "loss: 2.341906  [12800/27455]\n",
            "gradient mean= 0.00011637147690635175\n",
            "loss: 2.348480  [19200/27455]\n",
            "gradient mean= -1.9241944755776785e-05\n",
            "loss: 2.340303  [25600/27455]\n",
            "gradient mean= 3.566206942196004e-05\n",
            "Test Error: \n",
            " Accuracy: 76.1%, Avg loss: 2.663139 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.8%, Avg loss: 2.348551 \n",
            "\n",
            "Epoch 11\n",
            "-----------------------------\n",
            "loss: 2.337093  [    0/27455]\n",
            "gradient mean= 4.7657438699388877e-05\n",
            "loss: 2.337525  [ 6400/27455]\n",
            "gradient mean= 3.811059286817908e-05\n",
            "loss: 2.334010  [12800/27455]\n",
            "gradient mean= -1.1315612937323749e-05\n",
            "loss: 2.328427  [19200/27455]\n",
            "gradient mean= 1.1663691111607477e-05\n",
            "loss: 2.330904  [25600/27455]\n",
            "gradient mean= -2.8231193027750123e-06\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.635904 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.332450 \n",
            "\n",
            "Epoch 12\n",
            "-----------------------------\n",
            "loss: 2.332865  [    0/27455]\n",
            "gradient mean= -1.066874301614007e-05\n",
            "loss: 2.331375  [ 6400/27455]\n",
            "gradient mean= -8.73653516464401e-06\n",
            "loss: 2.328374  [12800/27455]\n",
            "gradient mean= 1.3188810953579377e-05\n",
            "loss: 2.330389  [19200/27455]\n",
            "gradient mean= 2.895937541325111e-05\n",
            "loss: 2.329375  [25600/27455]\n",
            "gradient mean= -7.2596212703501806e-06\n",
            "Test Error: \n",
            " Accuracy: 75.7%, Avg loss: 2.642208 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.327418 \n",
            "\n",
            "Epoch 13\n",
            "-----------------------------\n",
            "loss: 2.327861  [    0/27455]\n",
            "gradient mean= 3.1153761028690496e-06\n",
            "loss: 2.329608  [ 6400/27455]\n",
            "gradient mean= -1.511969185230555e-05\n",
            "loss: 2.331379  [12800/27455]\n",
            "gradient mean= -3.689228606162942e-06\n",
            "loss: 2.326629  [19200/27455]\n",
            "gradient mean= -7.22013601262006e-06\n",
            "loss: 2.326732  [25600/27455]\n",
            "gradient mean= 3.1997392397897784e-06\n",
            "Test Error: \n",
            " Accuracy: 77.0%, Avg loss: 2.614507 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.324729 \n",
            "\n",
            "Epoch 14\n",
            "-----------------------------\n",
            "loss: 2.326955  [    0/27455]\n",
            "gradient mean= 7.546338565589394e-06\n",
            "loss: 2.327039  [ 6400/27455]\n",
            "gradient mean= 6.403435691026971e-06\n",
            "loss: 2.326503  [12800/27455]\n",
            "gradient mean= 5.057403086539125e-06\n",
            "loss: 2.327125  [19200/27455]\n",
            "gradient mean= 1.051133222063072e-05\n",
            "loss: 2.327081  [25600/27455]\n",
            "gradient mean= -9.935545676853508e-06\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 2.603421 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.324024 \n",
            "\n",
            "Epoch 15\n",
            "-----------------------------\n",
            "loss: 2.325922  [    0/27455]\n",
            "gradient mean= -3.711007138917921e-06\n",
            "loss: 2.327837  [ 6400/27455]\n",
            "gradient mean= 5.18487979661586e-07\n",
            "loss: 2.324877  [12800/27455]\n",
            "gradient mean= -1.0754429240478203e-06\n",
            "loss: 2.325412  [19200/27455]\n",
            "gradient mean= -1.3677374681719812e-06\n",
            "loss: 2.326085  [25600/27455]\n",
            "gradient mean= 3.3735193483153125e-06\n",
            "Test Error: \n",
            " Accuracy: 77.4%, Avg loss: 2.610023 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.323880 \n",
            "\n",
            "Epoch 16\n",
            "-----------------------------\n",
            "loss: 2.325491  [    0/27455]\n",
            "gradient mean= -4.432749847183004e-06\n",
            "loss: 2.327140  [ 6400/27455]\n",
            "gradient mean= 2.3193260858533904e-05\n",
            "loss: 2.326681  [12800/27455]\n",
            "gradient mean= -3.0159630114212632e-05\n",
            "loss: 2.327885  [19200/27455]\n",
            "gradient mean= -6.745877726643812e-06\n",
            "loss: 2.326415  [25600/27455]\n",
            "gradient mean= -1.1582371371332556e-05\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 2.605642 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.323735 \n",
            "\n",
            "Epoch 17\n",
            "-----------------------------\n",
            "loss: 2.325368  [    0/27455]\n",
            "gradient mean= -5.644497832690831e-06\n",
            "loss: 2.325051  [ 6400/27455]\n",
            "gradient mean= 5.005857474316144e-06\n",
            "loss: 2.325183  [12800/27455]\n",
            "gradient mean= -7.328255691163577e-08\n",
            "loss: 2.326777  [19200/27455]\n",
            "gradient mean= 4.984314273315249e-06\n",
            "loss: 2.325551  [25600/27455]\n",
            "gradient mean= 4.440476914169267e-06\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.601740 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.323566 \n",
            "\n",
            "Epoch 18\n",
            "-----------------------------\n",
            "loss: 2.324774  [    0/27455]\n",
            "gradient mean= 4.443871603143634e-06\n",
            "loss: 2.324277  [ 6400/27455]\n",
            "gradient mean= -6.394574938894948e-06\n",
            "loss: 2.324073  [12800/27455]\n",
            "gradient mean= -6.637989713453862e-07\n",
            "loss: 2.324203  [19200/27455]\n",
            "gradient mean= -2.5591552912374027e-06\n",
            "loss: 2.324686  [25600/27455]\n",
            "gradient mean= 2.047516545644612e-06\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.603061 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.323258 \n",
            "\n",
            "Epoch 19\n",
            "-----------------------------\n",
            "loss: 2.324916  [    0/27455]\n",
            "gradient mean= 3.362041525178938e-06\n",
            "loss: 2.324203  [ 6400/27455]\n",
            "gradient mean= 3.3419873943785205e-06\n",
            "loss: 2.324258  [12800/27455]\n",
            "gradient mean= 1.945886424437049e-06\n",
            "loss: 2.325175  [19200/27455]\n",
            "gradient mean= -3.6363692288432503e-06\n",
            "loss: 2.324363  [25600/27455]\n",
            "gradient mean= -1.6051430407060252e-07\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.592015 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322966 \n",
            "\n",
            "Epoch 20\n",
            "-----------------------------\n",
            "loss: 2.326213  [    0/27455]\n",
            "gradient mean= -7.857869604777079e-06\n",
            "loss: 2.324684  [ 6400/27455]\n",
            "gradient mean= -4.749600066134008e-06\n",
            "loss: 2.324971  [12800/27455]\n",
            "gradient mean= 6.451847639254993e-06\n",
            "loss: 2.323877  [19200/27455]\n",
            "gradient mean= 1.6486185359099181e-06\n",
            "loss: 2.324901  [25600/27455]\n",
            "gradient mean= -8.469731255900115e-06\n",
            "Test Error: \n",
            " Accuracy: 76.6%, Avg loss: 2.596768 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322886 \n",
            "\n",
            "Epoch 21\n",
            "-----------------------------\n",
            "loss: 2.324016  [    0/27455]\n",
            "gradient mean= -6.430928351619514e-06\n",
            "loss: 2.324312  [ 6400/27455]\n",
            "gradient mean= -4.094633368367795e-06\n",
            "loss: 2.324315  [12800/27455]\n",
            "gradient mean= -2.7013255632368782e-08\n",
            "loss: 2.323595  [19200/27455]\n",
            "gradient mean= -3.403782329769456e-06\n",
            "loss: 2.323996  [25600/27455]\n",
            "gradient mean= -6.879026841488667e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.592023 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322832 \n",
            "\n",
            "Epoch 22\n",
            "-----------------------------\n",
            "loss: 2.324129  [    0/27455]\n",
            "gradient mean= -2.483219532223302e-06\n",
            "loss: 2.324789  [ 6400/27455]\n",
            "gradient mean= -1.3552242307923734e-05\n",
            "loss: 2.324206  [12800/27455]\n",
            "gradient mean= -1.916573182825232e-06\n",
            "loss: 2.323981  [19200/27455]\n",
            "gradient mean= -2.26099632527621e-06\n",
            "loss: 2.326129  [25600/27455]\n",
            "gradient mean= -3.675983634821023e-06\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.594023 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322777 \n",
            "\n",
            "Epoch 23\n",
            "-----------------------------\n",
            "loss: 2.323478  [    0/27455]\n",
            "gradient mean= 1.7949157609109534e-06\n",
            "loss: 2.324009  [ 6400/27455]\n",
            "gradient mean= 3.709861630341038e-06\n",
            "loss: 2.324095  [12800/27455]\n",
            "gradient mean= 4.38777897215914e-06\n",
            "loss: 2.323695  [19200/27455]\n",
            "gradient mean= -6.582457899639849e-06\n",
            "loss: 2.323836  [25600/27455]\n",
            "gradient mean= -8.145752872223966e-07\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.595554 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322839 \n",
            "\n",
            "Epoch 24\n",
            "-----------------------------\n",
            "loss: 2.323434  [    0/27455]\n",
            "gradient mean= -4.660225386032835e-06\n",
            "loss: 2.323181  [ 6400/27455]\n",
            "gradient mean= 2.9447412543959217e-06\n",
            "loss: 2.324147  [12800/27455]\n",
            "gradient mean= 2.9928894491604296e-06\n",
            "loss: 2.323830  [19200/27455]\n",
            "gradient mean= 5.732648787670769e-06\n",
            "loss: 2.325328  [25600/27455]\n",
            "gradient mean= -2.2814014300820418e-05\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.584693 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322671 \n",
            "\n",
            "Epoch 25\n",
            "-----------------------------\n",
            "loss: 2.323513  [    0/27455]\n",
            "gradient mean= 9.09395964754367e-07\n",
            "loss: 2.323234  [ 6400/27455]\n",
            "gradient mean= 5.535402465284278e-07\n",
            "loss: 2.323979  [12800/27455]\n",
            "gradient mean= 7.727172487648204e-06\n",
            "loss: 2.324123  [19200/27455]\n",
            "gradient mean= -1.2341765796008985e-06\n",
            "loss: 2.324830  [25600/27455]\n",
            "gradient mean= -1.2956324098922778e-05\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.588648 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322657 \n",
            "\n",
            "Epoch 26\n",
            "-----------------------------\n",
            "loss: 2.323590  [    0/27455]\n",
            "gradient mean= 6.890759323141538e-06\n",
            "loss: 2.323703  [ 6400/27455]\n",
            "gradient mean= 2.7833596050186316e-06\n",
            "loss: 2.323386  [12800/27455]\n",
            "gradient mean= -4.967158020008355e-06\n",
            "loss: 2.323233  [19200/27455]\n",
            "gradient mean= 3.3700024459903943e-07\n",
            "loss: 2.323290  [25600/27455]\n",
            "gradient mean= 1.5515811355726328e-06\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.588102 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322569 \n",
            "\n",
            "Epoch 27\n",
            "-----------------------------\n",
            "loss: 2.323144  [    0/27455]\n",
            "gradient mean= -1.1447838232925278e-06\n",
            "loss: 2.323923  [ 6400/27455]\n",
            "gradient mean= -9.334326932730619e-06\n",
            "loss: 2.323356  [12800/27455]\n",
            "gradient mean= -1.7972357682083384e-06\n",
            "loss: 2.324682  [19200/27455]\n",
            "gradient mean= -1.2509868838606053e-06\n",
            "loss: 2.323805  [25600/27455]\n",
            "gradient mean= 2.696851595374028e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.583706 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322561 \n",
            "\n",
            "Epoch 28\n",
            "-----------------------------\n",
            "loss: 2.323769  [    0/27455]\n",
            "gradient mean= -1.6622547036604374e-06\n",
            "loss: 2.323537  [ 6400/27455]\n",
            "gradient mean= -2.115677943947958e-06\n",
            "loss: 2.323575  [12800/27455]\n",
            "gradient mean= -2.6268251076544402e-06\n",
            "loss: 2.323199  [19200/27455]\n",
            "gradient mean= 3.154751766487607e-06\n",
            "loss: 2.323200  [25600/27455]\n",
            "gradient mean= -2.3091811272024643e-06\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.584494 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322522 \n",
            "\n",
            "Epoch 29\n",
            "-----------------------------\n",
            "loss: 2.323294  [    0/27455]\n",
            "gradient mean= -1.8996042854269035e-06\n",
            "loss: 2.323167  [ 6400/27455]\n",
            "gradient mean= -7.438990934360845e-08\n",
            "loss: 2.323840  [12800/27455]\n",
            "gradient mean= 6.864567694719881e-06\n",
            "loss: 2.323187  [19200/27455]\n",
            "gradient mean= 1.6514471212758508e-07\n",
            "loss: 2.323032  [25600/27455]\n",
            "gradient mean= 9.93513936009549e-07\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.584512 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322503 \n",
            "\n",
            "Epoch 30\n",
            "-----------------------------\n",
            "loss: 2.323036  [    0/27455]\n",
            "gradient mean= 4.689067736762809e-06\n",
            "loss: 2.323099  [ 6400/27455]\n",
            "gradient mean= 1.8414968963043066e-06\n",
            "loss: 2.323868  [12800/27455]\n",
            "gradient mean= 2.8213039513502736e-06\n",
            "loss: 2.323177  [19200/27455]\n",
            "gradient mean= -1.3847832178726094e-06\n",
            "loss: 2.323937  [25600/27455]\n",
            "gradient mean= -2.8093506898585474e-06\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.586144 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322500 \n",
            "\n",
            "Epoch 31\n",
            "-----------------------------\n",
            "loss: 2.322966  [    0/27455]\n",
            "gradient mean= -5.89269859574415e-07\n",
            "loss: 2.322917  [ 6400/27455]\n",
            "gradient mean= 6.726039032400877e-07\n",
            "loss: 2.323084  [12800/27455]\n",
            "gradient mean= 5.021586730435956e-06\n",
            "loss: 2.323619  [19200/27455]\n",
            "gradient mean= -7.48162506170047e-07\n",
            "loss: 2.323222  [25600/27455]\n",
            "gradient mean= 7.132825885491911e-07\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.587595 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322488 \n",
            "\n",
            "Epoch 32\n",
            "-----------------------------\n",
            "loss: 2.323255  [    0/27455]\n",
            "gradient mean= 1.183414951810846e-06\n",
            "loss: 2.323879  [ 6400/27455]\n",
            "gradient mean= 6.461476004915312e-06\n",
            "loss: 2.322996  [12800/27455]\n",
            "gradient mean= 7.054787602100987e-06\n",
            "loss: 2.324013  [19200/27455]\n",
            "gradient mean= 1.1060271845053649e-06\n",
            "loss: 2.323129  [25600/27455]\n",
            "gradient mean= -1.1380077467038063e-06\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 2.581483 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322434 \n",
            "\n",
            "Epoch 33\n",
            "-----------------------------\n",
            "loss: 2.322958  [    0/27455]\n",
            "gradient mean= 5.000633336749161e-06\n",
            "loss: 2.323317  [ 6400/27455]\n",
            "gradient mean= -4.4581395286513725e-07\n",
            "loss: 2.323056  [12800/27455]\n",
            "gradient mean= -1.7037003772202297e-06\n",
            "loss: 2.322951  [19200/27455]\n",
            "gradient mean= 6.60127739138261e-07\n",
            "loss: 2.322927  [25600/27455]\n",
            "gradient mean= -2.033722239502822e-06\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.587144 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322423 \n",
            "\n",
            "Epoch 34\n",
            "-----------------------------\n",
            "loss: 2.323006  [    0/27455]\n",
            "gradient mean= 4.4842514057563676e-07\n",
            "loss: 2.323203  [ 6400/27455]\n",
            "gradient mean= -2.518517874250392e-07\n",
            "loss: 2.324270  [12800/27455]\n",
            "gradient mean= 5.6481417232134845e-06\n",
            "loss: 2.323104  [19200/27455]\n",
            "gradient mean= 6.727809136464202e-07\n",
            "loss: 2.322932  [25600/27455]\n",
            "gradient mean= 1.6709890360289137e-06\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.578050 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322399 \n",
            "\n",
            "Epoch 35\n",
            "-----------------------------\n",
            "loss: 2.322902  [    0/27455]\n",
            "gradient mean= 5.561043394664011e-07\n",
            "loss: 2.322737  [ 6400/27455]\n",
            "gradient mean= -8.066099326242693e-07\n",
            "loss: 2.322964  [12800/27455]\n",
            "gradient mean= 1.3464454013956129e-06\n",
            "loss: 2.322644  [19200/27455]\n",
            "gradient mean= -2.7893296561387615e-09\n",
            "loss: 2.323480  [25600/27455]\n",
            "gradient mean= 8.383979661630292e-07\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.578966 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322409 \n",
            "\n",
            "Epoch 36\n",
            "-----------------------------\n",
            "loss: 2.323122  [    0/27455]\n",
            "gradient mean= 2.89482136395236e-06\n",
            "loss: 2.322816  [ 6400/27455]\n",
            "gradient mean= 2.984576212838874e-07\n",
            "loss: 2.322882  [12800/27455]\n",
            "gradient mean= -2.1604889752779854e-06\n",
            "loss: 2.323257  [19200/27455]\n",
            "gradient mean= -7.368896604020847e-08\n",
            "loss: 2.322838  [25600/27455]\n",
            "gradient mean= 5.484969278768403e-07\n",
            "Test Error: \n",
            " Accuracy: 76.9%, Avg loss: 2.582582 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322451 \n",
            "\n",
            "Epoch 37\n",
            "-----------------------------\n",
            "loss: 2.323007  [    0/27455]\n",
            "gradient mean= -1.6792553481081995e-07\n",
            "loss: 2.322751  [ 6400/27455]\n",
            "gradient mean= 1.7493665893653088e-07\n",
            "loss: 2.322640  [12800/27455]\n",
            "gradient mean= -4.665092774303048e-07\n",
            "loss: 2.322645  [19200/27455]\n",
            "gradient mean= 7.97226675786078e-07\n",
            "loss: 2.323159  [25600/27455]\n",
            "gradient mean= -3.563581412890926e-05\n",
            "Test Error: \n",
            " Accuracy: 76.6%, Avg loss: 2.591195 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322588 \n",
            "\n",
            "Epoch 38\n",
            "-----------------------------\n",
            "loss: 2.324198  [    0/27455]\n",
            "gradient mean= -4.580026597977849e-06\n",
            "loss: 2.323491  [ 6400/27455]\n",
            "gradient mean= 2.9928796720923856e-06\n",
            "loss: 2.322985  [12800/27455]\n",
            "gradient mean= 1.4234856280381791e-06\n",
            "loss: 2.323186  [19200/27455]\n",
            "gradient mean= 4.7757434913364705e-06\n",
            "loss: 2.322887  [25600/27455]\n",
            "gradient mean= 1.350794605059491e-06\n",
            "Test Error: \n",
            " Accuracy: 77.5%, Avg loss: 2.584158 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322356 \n",
            "\n",
            "Epoch 39\n",
            "-----------------------------\n",
            "loss: 2.323377  [    0/27455]\n",
            "gradient mean= -3.816900061792694e-06\n",
            "loss: 2.323007  [ 6400/27455]\n",
            "gradient mean= -1.0613205176923657e-06\n",
            "loss: 2.322800  [12800/27455]\n",
            "gradient mean= -2.717720448686123e-08\n",
            "loss: 2.322842  [19200/27455]\n",
            "gradient mean= -9.648583727539517e-07\n",
            "loss: 2.322851  [25600/27455]\n",
            "gradient mean= -5.50967843082617e-06\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.578986 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322360 \n",
            "\n",
            "Epoch 40\n",
            "-----------------------------\n",
            "loss: 2.323152  [    0/27455]\n",
            "gradient mean= 5.824675099574961e-06\n",
            "loss: 2.327830  [ 6400/27455]\n",
            "gradient mean= 1.9576912109187106e-06\n",
            "loss: 2.323010  [12800/27455]\n",
            "gradient mean= -1.015012500715784e-07\n",
            "loss: 2.322866  [19200/27455]\n",
            "gradient mean= 1.3801670775137609e-06\n",
            "loss: 2.322845  [25600/27455]\n",
            "gradient mean= -1.3093840607325546e-06\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.581877 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322351 \n",
            "\n",
            "Epoch 41\n",
            "-----------------------------\n",
            "loss: 2.322800  [    0/27455]\n",
            "gradient mean= 2.3491611500503495e-06\n",
            "loss: 2.322935  [ 6400/27455]\n",
            "gradient mean= 1.5716914276708849e-06\n",
            "loss: 2.322945  [12800/27455]\n",
            "gradient mean= 3.404080871405313e-06\n",
            "loss: 2.322672  [19200/27455]\n",
            "gradient mean= 5.133059630679782e-07\n",
            "loss: 2.322647  [25600/27455]\n",
            "gradient mean= 1.7730252466208185e-07\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 2.579154 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322335 \n",
            "\n",
            "Epoch 42\n",
            "-----------------------------\n",
            "loss: 2.323005  [    0/27455]\n",
            "gradient mean= 9.850905371422414e-07\n",
            "loss: 2.322741  [ 6400/27455]\n",
            "gradient mean= 2.240843457457231e-07\n",
            "loss: 2.322644  [12800/27455]\n",
            "gradient mean= 1.8076912056130823e-06\n",
            "loss: 2.322848  [19200/27455]\n",
            "gradient mean= 2.6379320843261667e-06\n",
            "loss: 2.323020  [25600/27455]\n",
            "gradient mean= -3.371460479684174e-06\n",
            "Test Error: \n",
            " Accuracy: 77.4%, Avg loss: 2.583917 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322312 \n",
            "\n",
            "Epoch 43\n",
            "-----------------------------\n",
            "loss: 2.322468  [    0/27455]\n",
            "gradient mean= -6.552526770065015e-07\n",
            "loss: 2.322906  [ 6400/27455]\n",
            "gradient mean= -7.489157951567904e-07\n",
            "loss: 2.322493  [12800/27455]\n",
            "gradient mean= 3.5704297829397547e-07\n",
            "loss: 2.322575  [19200/27455]\n",
            "gradient mean= -5.198298822506331e-07\n",
            "loss: 2.323323  [25600/27455]\n",
            "gradient mean= 2.990184100326587e-07\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.575225 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322306 \n",
            "\n",
            "Epoch 44\n",
            "-----------------------------\n",
            "loss: 2.322696  [    0/27455]\n",
            "gradient mean= 3.644786943368672e-07\n",
            "loss: 2.322824  [ 6400/27455]\n",
            "gradient mean= -1.3253613815322751e-06\n",
            "loss: 2.322680  [12800/27455]\n",
            "gradient mean= -5.12573819833051e-07\n",
            "loss: 2.322809  [19200/27455]\n",
            "gradient mean= -1.030262183121522e-06\n",
            "loss: 2.322923  [25600/27455]\n",
            "gradient mean= 6.5270728555333335e-06\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.573651 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322294 \n",
            "\n",
            "Epoch 45\n",
            "-----------------------------\n",
            "loss: 2.322633  [    0/27455]\n",
            "gradient mean= -4.644891760108294e-07\n",
            "loss: 2.322568  [ 6400/27455]\n",
            "gradient mean= -5.110812821840227e-07\n",
            "loss: 2.322561  [12800/27455]\n",
            "gradient mean= -4.752015456688241e-07\n",
            "loss: 2.322587  [19200/27455]\n",
            "gradient mean= 2.1067990019218996e-06\n",
            "loss: 2.322690  [25600/27455]\n",
            "gradient mean= 4.801713089364057e-07\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 2.576198 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322298 \n",
            "\n",
            "Epoch 46\n",
            "-----------------------------\n",
            "loss: 2.322822  [    0/27455]\n",
            "gradient mean= -1.69291490692558e-06\n",
            "loss: 2.323048  [ 6400/27455]\n",
            "gradient mean= 2.2907327092980267e-06\n",
            "loss: 2.322589  [12800/27455]\n",
            "gradient mean= -1.0013266091846162e-06\n",
            "loss: 2.322751  [19200/27455]\n",
            "gradient mean= 1.8885763211073936e-06\n",
            "loss: 2.322586  [25600/27455]\n",
            "gradient mean= -1.5216151041386183e-06\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.578390 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322286 \n",
            "\n",
            "Epoch 47\n",
            "-----------------------------\n",
            "loss: 2.322670  [    0/27455]\n",
            "gradient mean= -1.5122232071007602e-06\n",
            "loss: 2.323816  [ 6400/27455]\n",
            "gradient mean= -9.786725058802404e-06\n",
            "loss: 2.322772  [12800/27455]\n",
            "gradient mean= 1.7911282839122578e-06\n",
            "loss: 2.323318  [19200/27455]\n",
            "gradient mean= -1.4307970559457317e-06\n",
            "loss: 2.322500  [25600/27455]\n",
            "gradient mean= -2.493910926659737e-07\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 2.583190 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322287 \n",
            "\n",
            "Epoch 48\n",
            "-----------------------------\n",
            "loss: 2.322649  [    0/27455]\n",
            "gradient mean= -1.5471727010663017e-06\n",
            "loss: 2.323866  [ 6400/27455]\n",
            "gradient mean= 1.1354810339980759e-05\n",
            "loss: 2.322630  [12800/27455]\n",
            "gradient mean= -3.2887442102946807e-07\n",
            "loss: 2.322645  [19200/27455]\n",
            "gradient mean= -2.2790354705648497e-06\n",
            "loss: 2.322687  [25600/27455]\n",
            "gradient mean= 7.452083536918508e-07\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.574377 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322284 \n",
            "\n",
            "Epoch 49\n",
            "-----------------------------\n",
            "loss: 2.322944  [    0/27455]\n",
            "gradient mean= -3.839889814116759e-06\n",
            "loss: 2.322770  [ 6400/27455]\n",
            "gradient mean= 2.5680850512799225e-07\n",
            "loss: 2.323241  [12800/27455]\n",
            "gradient mean= -2.3108536879590247e-06\n",
            "loss: 2.322643  [19200/27455]\n",
            "gradient mean= 1.617962993805122e-06\n",
            "loss: 2.323143  [25600/27455]\n",
            "gradient mean= 3.052058445973671e-06\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.577675 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322268 \n",
            "\n",
            "Epoch 50\n",
            "-----------------------------\n",
            "loss: 2.322620  [    0/27455]\n",
            "gradient mean= -1.3420876712189056e-06\n",
            "loss: 2.322496  [ 6400/27455]\n",
            "gradient mean= 1.1138008630950935e-06\n",
            "loss: 2.322484  [12800/27455]\n",
            "gradient mean= -1.4382990229933057e-06\n",
            "loss: 2.322579  [19200/27455]\n",
            "gradient mean= -6.866034709673841e-07\n",
            "loss: 2.322644  [25600/27455]\n",
            "gradient mean= 9.62504714152601e-07\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.576844 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322265 \n",
            "\n",
            "Epoch 51\n",
            "-----------------------------\n",
            "loss: 2.322816  [    0/27455]\n",
            "gradient mean= -2.1694231691071764e-06\n",
            "loss: 2.322497  [ 6400/27455]\n",
            "gradient mean= -1.536025820314535e-06\n",
            "loss: 2.322662  [12800/27455]\n",
            "gradient mean= -1.9711340826233936e-07\n",
            "loss: 2.323156  [19200/27455]\n",
            "gradient mean= 1.4921506590326317e-05\n",
            "loss: 2.322946  [25600/27455]\n",
            "gradient mean= 6.128608674771385e-06\n",
            "Test Error: \n",
            " Accuracy: 77.4%, Avg loss: 2.580873 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322278 \n",
            "\n",
            "Epoch 52\n",
            "-----------------------------\n",
            "loss: 2.322752  [    0/27455]\n",
            "gradient mean= 5.224862320574175e-07\n",
            "loss: 2.322599  [ 6400/27455]\n",
            "gradient mean= -1.1502174857014325e-06\n",
            "loss: 2.322675  [12800/27455]\n",
            "gradient mean= -6.879394049974508e-07\n",
            "loss: 2.322647  [19200/27455]\n",
            "gradient mean= 1.718369730951963e-06\n",
            "loss: 2.322734  [25600/27455]\n",
            "gradient mean= 4.896978111901262e-07\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.576062 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322263 \n",
            "\n",
            "Epoch 53\n",
            "-----------------------------\n",
            "loss: 2.322892  [    0/27455]\n",
            "gradient mean= -2.4295277398778126e-05\n",
            "loss: 2.322498  [ 6400/27455]\n",
            "gradient mean= -1.1262014822932542e-06\n",
            "loss: 2.322603  [12800/27455]\n",
            "gradient mean= 7.430726896018314e-07\n",
            "loss: 2.322659  [19200/27455]\n",
            "gradient mean= 8.115758873827872e-07\n",
            "loss: 2.322698  [25600/27455]\n",
            "gradient mean= 3.8075447150731634e-07\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.576115 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322253 \n",
            "\n",
            "Epoch 54\n",
            "-----------------------------\n",
            "loss: 2.322584  [    0/27455]\n",
            "gradient mean= -1.3702193655262818e-06\n",
            "loss: 2.322913  [ 6400/27455]\n",
            "gradient mean= 3.1230256354319863e-06\n",
            "loss: 2.322764  [12800/27455]\n",
            "gradient mean= 4.876822004007408e-07\n",
            "loss: 2.323043  [19200/27455]\n",
            "gradient mean= 6.272882160374138e-07\n",
            "loss: 2.322658  [25600/27455]\n",
            "gradient mean= 2.4846315227478044e-07\n",
            "Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 2.572721 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322247 \n",
            "\n",
            "Epoch 55\n",
            "-----------------------------\n",
            "loss: 2.322540  [    0/27455]\n",
            "gradient mean= 1.0342100722482428e-06\n",
            "loss: 2.322344  [ 6400/27455]\n",
            "gradient mean= -6.854619982732402e-08\n",
            "loss: 2.322509  [12800/27455]\n",
            "gradient mean= -2.3938483195706795e-07\n",
            "loss: 2.322418  [19200/27455]\n",
            "gradient mean= 4.617972422238381e-07\n",
            "loss: 2.322642  [25600/27455]\n",
            "gradient mean= 1.3427053318082471e-06\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.577716 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322249 \n",
            "\n",
            "Epoch 56\n",
            "-----------------------------\n",
            "loss: 2.322412  [    0/27455]\n",
            "gradient mean= -9.642519671615446e-07\n",
            "loss: 2.322602  [ 6400/27455]\n",
            "gradient mean= 2.192457259297953e-06\n",
            "loss: 2.322607  [12800/27455]\n",
            "gradient mean= -1.8269739712195587e-06\n",
            "loss: 2.322809  [19200/27455]\n",
            "gradient mean= 2.121868874382926e-06\n",
            "loss: 2.322937  [25600/27455]\n",
            "gradient mean= -2.3941215658851434e-06\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.577645 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322237 \n",
            "\n",
            "Epoch 57\n",
            "-----------------------------\n",
            "loss: 2.322526  [    0/27455]\n",
            "gradient mean= 8.811454677015718e-07\n",
            "loss: 2.322433  [ 6400/27455]\n",
            "gradient mean= 1.2991296927111762e-08\n",
            "loss: 2.322769  [12800/27455]\n",
            "gradient mean= 3.936604571208591e-06\n",
            "loss: 2.322420  [19200/27455]\n",
            "gradient mean= 7.343582524299563e-07\n",
            "loss: 2.323442  [25600/27455]\n",
            "gradient mean= -2.7917094485019334e-06\n",
            "Test Error: \n",
            " Accuracy: 77.5%, Avg loss: 2.578511 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322246 \n",
            "\n",
            "Epoch 58\n",
            "-----------------------------\n",
            "loss: 2.322777  [    0/27455]\n",
            "gradient mean= 1.1399805543987895e-06\n",
            "loss: 2.323005  [ 6400/27455]\n",
            "gradient mean= 1.5615066217833373e-07\n",
            "loss: 2.323734  [12800/27455]\n",
            "gradient mean= 1.7258038269574172e-06\n",
            "loss: 2.322600  [19200/27455]\n",
            "gradient mean= 1.3839040775565081e-06\n",
            "loss: 2.322626  [25600/27455]\n",
            "gradient mean= 1.542681161481596e-06\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.573886 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322237 \n",
            "\n",
            "Epoch 59\n",
            "-----------------------------\n",
            "loss: 2.322604  [    0/27455]\n",
            "gradient mean= -1.7825478835220565e-06\n",
            "loss: 2.322788  [ 6400/27455]\n",
            "gradient mean= -3.820698111667298e-06\n",
            "loss: 2.322451  [12800/27455]\n",
            "gradient mean= 5.938852041253995e-07\n",
            "loss: 2.322711  [19200/27455]\n",
            "gradient mean= 8.095925636553147e-07\n",
            "loss: 2.322455  [25600/27455]\n",
            "gradient mean= -1.2828178341806051e-06\n",
            "Test Error: \n",
            " Accuracy: 77.5%, Avg loss: 2.577781 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322230 \n",
            "\n",
            "Epoch 60\n",
            "-----------------------------\n",
            "loss: 2.322536  [    0/27455]\n",
            "gradient mean= 6.78034439260955e-07\n",
            "loss: 2.322582  [ 6400/27455]\n",
            "gradient mean= -7.10485210220213e-07\n",
            "loss: 2.322577  [12800/27455]\n",
            "gradient mean= -4.274279490346089e-06\n",
            "loss: 2.322465  [19200/27455]\n",
            "gradient mean= -2.1818767947934248e-07\n",
            "loss: 2.322752  [25600/27455]\n",
            "gradient mean= 3.978037966589909e-06\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.572595 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322231 \n",
            "\n",
            "Epoch 61\n",
            "-----------------------------\n",
            "loss: 2.322739  [    0/27455]\n",
            "gradient mean= -2.059456846836838e-06\n",
            "loss: 2.322523  [ 6400/27455]\n",
            "gradient mean= -3.4361752909717325e-07\n",
            "loss: 2.322468  [12800/27455]\n",
            "gradient mean= 5.136221830071008e-07\n",
            "loss: 2.322508  [19200/27455]\n",
            "gradient mean= 3.461456685727171e-07\n",
            "loss: 2.322509  [25600/27455]\n",
            "gradient mean= -1.6327091998391552e-06\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.570985 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322231 \n",
            "\n",
            "Epoch 62\n",
            "-----------------------------\n",
            "loss: 2.322463  [    0/27455]\n",
            "gradient mean= 1.3083999874652363e-06\n",
            "loss: 2.322399  [ 6400/27455]\n",
            "gradient mean= -7.325093065446708e-07\n",
            "loss: 2.322419  [12800/27455]\n",
            "gradient mean= -6.93567642429116e-07\n",
            "loss: 2.322494  [19200/27455]\n",
            "gradient mean= 1.2737258430206566e-06\n",
            "loss: 2.322593  [25600/27455]\n",
            "gradient mean= -7.083424691245455e-08\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.573135 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322225 \n",
            "\n",
            "Epoch 63\n",
            "-----------------------------\n",
            "loss: 2.322506  [    0/27455]\n",
            "gradient mean= -9.83371023721702e-07\n",
            "loss: 2.322393  [ 6400/27455]\n",
            "gradient mean= -3.063467772790318e-07\n",
            "loss: 2.322407  [12800/27455]\n",
            "gradient mean= -9.379697019085143e-08\n",
            "loss: 2.322438  [19200/27455]\n",
            "gradient mean= -4.038460019728518e-07\n",
            "loss: 2.322539  [25600/27455]\n",
            "gradient mean= -9.904238140734378e-07\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.579219 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322227 \n",
            "\n",
            "Epoch 64\n",
            "-----------------------------\n",
            "loss: 2.322482  [    0/27455]\n",
            "gradient mean= 4.683582517372997e-07\n",
            "loss: 2.322517  [ 6400/27455]\n",
            "gradient mean= 1.6449547501906636e-06\n",
            "loss: 2.322431  [12800/27455]\n",
            "gradient mean= -2.0733364181069192e-07\n",
            "loss: 2.322636  [19200/27455]\n",
            "gradient mean= -9.56095163928694e-07\n",
            "loss: 2.322360  [25600/27455]\n",
            "gradient mean= -6.687042173325608e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.572037 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322217 \n",
            "\n",
            "Epoch 65\n",
            "-----------------------------\n",
            "loss: 2.322789  [    0/27455]\n",
            "gradient mean= 2.4791538635327015e-06\n",
            "loss: 2.322481  [ 6400/27455]\n",
            "gradient mean= 1.4785302759889873e-08\n",
            "loss: 2.322369  [12800/27455]\n",
            "gradient mean= -1.1147570688763153e-07\n",
            "loss: 2.322389  [19200/27455]\n",
            "gradient mean= -5.101006763652549e-07\n",
            "loss: 2.322395  [25600/27455]\n",
            "gradient mean= 1.6886417597561376e-07\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 2.575322 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322208 \n",
            "\n",
            "Epoch 66\n",
            "-----------------------------\n",
            "loss: 2.322680  [    0/27455]\n",
            "gradient mean= 9.827243729887414e-07\n",
            "loss: 2.322816  [ 6400/27455]\n",
            "gradient mean= -1.2536919484773534e-06\n",
            "loss: 2.322529  [12800/27455]\n",
            "gradient mean= -1.2106767144359765e-06\n",
            "loss: 2.322520  [19200/27455]\n",
            "gradient mean= -5.813740244775545e-07\n",
            "loss: 2.323214  [25600/27455]\n",
            "gradient mean= 1.0880331728913006e-06\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.573121 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322206 \n",
            "\n",
            "Epoch 67\n",
            "-----------------------------\n",
            "loss: 2.322715  [    0/27455]\n",
            "gradient mean= -2.0430290987860644e-06\n",
            "loss: 2.322535  [ 6400/27455]\n",
            "gradient mean= 3.8741251273677335e-07\n",
            "loss: 2.322536  [12800/27455]\n",
            "gradient mean= 2.208921401347652e-08\n",
            "loss: 2.322392  [19200/27455]\n",
            "gradient mean= 7.09604762505478e-07\n",
            "loss: 2.322435  [25600/27455]\n",
            "gradient mean= 3.094130818226404e-07\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.575883 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322206 \n",
            "\n",
            "Epoch 68\n",
            "-----------------------------\n",
            "loss: 2.322536  [    0/27455]\n",
            "gradient mean= 2.3472439636407216e-07\n",
            "loss: 2.322556  [ 6400/27455]\n",
            "gradient mean= 6.51616630875651e-07\n",
            "loss: 2.322450  [12800/27455]\n",
            "gradient mean= 7.155089747357124e-07\n",
            "loss: 2.322808  [19200/27455]\n",
            "gradient mean= -3.6230717341823038e-06\n",
            "loss: 2.322364  [25600/27455]\n",
            "gradient mean= -8.289321158372331e-07\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.575655 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322205 \n",
            "\n",
            "Epoch 69\n",
            "-----------------------------\n",
            "loss: 2.322463  [    0/27455]\n",
            "gradient mean= -8.062922347562562e-07\n",
            "loss: 2.322384  [ 6400/27455]\n",
            "gradient mean= -1.8063136053569906e-07\n",
            "loss: 2.322446  [12800/27455]\n",
            "gradient mean= -1.5022921573404346e-08\n",
            "loss: 2.322429  [19200/27455]\n",
            "gradient mean= 1.9289525425847387e-06\n",
            "loss: 2.322379  [25600/27455]\n",
            "gradient mean= -2.537043712891318e-07\n",
            "Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 2.574328 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322198 \n",
            "\n",
            "Epoch 70\n",
            "-----------------------------\n",
            "loss: 2.322844  [    0/27455]\n",
            "gradient mean= -8.978602750175924e-07\n",
            "loss: 2.322442  [ 6400/27455]\n",
            "gradient mean= 5.198146482143784e-07\n",
            "loss: 2.322358  [12800/27455]\n",
            "gradient mean= -7.378814643743681e-07\n",
            "loss: 2.322463  [19200/27455]\n",
            "gradient mean= -9.474893403194073e-08\n",
            "loss: 2.322344  [25600/27455]\n",
            "gradient mean= -1.968723637446601e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.569652 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322199 \n",
            "\n",
            "Epoch 71\n",
            "-----------------------------\n",
            "loss: 2.322712  [    0/27455]\n",
            "gradient mean= -2.3754287212796044e-06\n",
            "loss: 2.323059  [ 6400/27455]\n",
            "gradient mean= 2.0315378890245483e-07\n",
            "loss: 2.322325  [12800/27455]\n",
            "gradient mean= 7.401375068383231e-09\n",
            "loss: 2.322399  [19200/27455]\n",
            "gradient mean= -4.562830326904077e-07\n",
            "loss: 2.322956  [25600/27455]\n",
            "gradient mean= 4.8164256440941244e-06\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 2.569884 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322194 \n",
            "\n",
            "Epoch 72\n",
            "-----------------------------\n",
            "loss: 2.322407  [    0/27455]\n",
            "gradient mean= -1.1846109373436775e-06\n",
            "loss: 2.322491  [ 6400/27455]\n",
            "gradient mean= -6.675169288428151e-07\n",
            "loss: 2.322265  [12800/27455]\n",
            "gradient mean= 3.4931821346617653e-07\n",
            "loss: 2.322647  [19200/27455]\n",
            "gradient mean= -1.1681968317134306e-06\n",
            "loss: 2.322400  [25600/27455]\n",
            "gradient mean= -1.832015755098837e-06\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 2.571770 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322197 \n",
            "\n",
            "Epoch 73\n",
            "-----------------------------\n",
            "loss: 2.322409  [    0/27455]\n",
            "gradient mean= -1.503854996087739e-08\n",
            "loss: 2.322410  [ 6400/27455]\n",
            "gradient mean= 1.570894454516747e-07\n",
            "loss: 2.322329  [12800/27455]\n",
            "gradient mean= -2.0527299682271405e-07\n",
            "loss: 2.322330  [19200/27455]\n",
            "gradient mean= -6.948537247808417e-07\n",
            "loss: 2.322402  [25600/27455]\n",
            "gradient mean= 2.0655122057178232e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.572146 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322192 \n",
            "\n",
            "Epoch 74\n",
            "-----------------------------\n",
            "loss: 2.322402  [    0/27455]\n",
            "gradient mean= 3.415746618884441e-07\n",
            "loss: 2.322404  [ 6400/27455]\n",
            "gradient mean= -1.1240415460633812e-06\n",
            "loss: 2.322402  [12800/27455]\n",
            "gradient mean= -5.749297429247235e-07\n",
            "loss: 2.322481  [19200/27455]\n",
            "gradient mean= 5.690536113434064e-07\n",
            "loss: 2.322403  [25600/27455]\n",
            "gradient mean= 3.1683416068517545e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.570575 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322194 \n",
            "\n",
            "Epoch 75\n",
            "-----------------------------\n",
            "loss: 2.322372  [    0/27455]\n",
            "gradient mean= 9.207357010154738e-08\n",
            "loss: 2.322315  [ 6400/27455]\n",
            "gradient mean= 2.3523523129398427e-09\n",
            "loss: 2.322697  [12800/27455]\n",
            "gradient mean= -2.016594407905359e-06\n",
            "loss: 2.322308  [19200/27455]\n",
            "gradient mean= 1.3046641811342852e-07\n",
            "loss: 2.322304  [25600/27455]\n",
            "gradient mean= -3.3448051794948697e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.573983 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322193 \n",
            "\n",
            "Epoch 76\n",
            "-----------------------------\n",
            "loss: 2.322350  [    0/27455]\n",
            "gradient mean= 1.5826130095319968e-07\n",
            "loss: 2.323333  [ 6400/27455]\n",
            "gradient mean= 4.624390896879049e-07\n",
            "loss: 2.322373  [12800/27455]\n",
            "gradient mean= -4.297915836559696e-07\n",
            "loss: 2.322288  [19200/27455]\n",
            "gradient mean= -2.150288196389738e-07\n",
            "loss: 2.322656  [25600/27455]\n",
            "gradient mean= -7.703383744228631e-07\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.570906 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322191 \n",
            "\n",
            "Epoch 77\n",
            "-----------------------------\n",
            "loss: 2.322319  [    0/27455]\n",
            "gradient mean= 5.727351890527643e-07\n",
            "loss: 2.322348  [ 6400/27455]\n",
            "gradient mean= -5.456791427604912e-07\n",
            "loss: 2.322417  [12800/27455]\n",
            "gradient mean= 1.165210861131527e-07\n",
            "loss: 2.322565  [19200/27455]\n",
            "gradient mean= 1.2953651093994267e-06\n",
            "loss: 2.322459  [25600/27455]\n",
            "gradient mean= -8.514662113157101e-07\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.570874 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322184 \n",
            "\n",
            "Epoch 78\n",
            "-----------------------------\n",
            "loss: 2.322531  [    0/27455]\n",
            "gradient mean= -1.2340750572548131e-06\n",
            "loss: 2.322424  [ 6400/27455]\n",
            "gradient mean= -4.754317046717915e-07\n",
            "loss: 2.322353  [12800/27455]\n",
            "gradient mean= -1.0148460205527954e-06\n",
            "loss: 2.322668  [19200/27455]\n",
            "gradient mean= -2.162247255910188e-06\n",
            "loss: 2.322788  [25600/27455]\n",
            "gradient mean= -2.472104654316354e-07\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.568541 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322183 \n",
            "\n",
            "Epoch 79\n",
            "-----------------------------\n",
            "loss: 2.322317  [    0/27455]\n",
            "gradient mean= -7.988354013832577e-07\n",
            "loss: 2.322477  [ 6400/27455]\n",
            "gradient mean= -1.7104636071962886e-06\n",
            "loss: 2.322384  [12800/27455]\n",
            "gradient mean= -4.258603070184108e-08\n",
            "loss: 2.322363  [19200/27455]\n",
            "gradient mean= 2.179996130280415e-07\n",
            "loss: 2.322300  [25600/27455]\n",
            "gradient mean= -7.144068092657108e-08\n",
            "Test Error: \n",
            " Accuracy: 77.5%, Avg loss: 2.573299 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322185 \n",
            "\n",
            "Epoch 80\n",
            "-----------------------------\n",
            "loss: 2.322351  [    0/27455]\n",
            "gradient mean= 6.640642027377908e-07\n",
            "loss: 2.322325  [ 6400/27455]\n",
            "gradient mean= -5.663304847303152e-08\n",
            "loss: 2.322355  [12800/27455]\n",
            "gradient mean= 1.8672556834076204e-08\n",
            "loss: 2.322523  [19200/27455]\n",
            "gradient mean= 1.2451107522792881e-06\n",
            "loss: 2.322399  [25600/27455]\n",
            "gradient mean= -4.054752480442403e-07\n",
            "Test Error: \n",
            " Accuracy: 77.3%, Avg loss: 2.573669 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322185 \n",
            "\n",
            "Epoch 81\n",
            "-----------------------------\n",
            "loss: 2.322572  [    0/27455]\n",
            "gradient mean= -3.013118430317263e-07\n",
            "loss: 2.322363  [ 6400/27455]\n",
            "gradient mean= 5.107081051392015e-07\n",
            "loss: 2.323887  [12800/27455]\n",
            "gradient mean= 9.696835149952676e-06\n",
            "loss: 2.322443  [19200/27455]\n",
            "gradient mean= -1.981574548892695e-08\n",
            "loss: 2.322315  [25600/27455]\n",
            "gradient mean= 4.7280568082896934e-07\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.573737 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322180 \n",
            "\n",
            "Epoch 82\n",
            "-----------------------------\n",
            "loss: 2.322401  [    0/27455]\n",
            "gradient mean= 6.306283921730937e-07\n",
            "loss: 2.322319  [ 6400/27455]\n",
            "gradient mean= -4.6760811756030307e-07\n",
            "loss: 2.322246  [12800/27455]\n",
            "gradient mean= -2.8147661623734166e-07\n",
            "loss: 2.322699  [19200/27455]\n",
            "gradient mean= -1.93144887816743e-06\n",
            "loss: 2.322354  [25600/27455]\n",
            "gradient mean= 9.224392272244586e-08\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 2.572539 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322179 \n",
            "\n",
            "Epoch 83\n",
            "-----------------------------\n",
            "loss: 2.322324  [    0/27455]\n",
            "gradient mean= 2.3464437504117086e-07\n",
            "loss: 2.322283  [ 6400/27455]\n",
            "gradient mean= 3.018376730778982e-07\n",
            "loss: 2.322394  [12800/27455]\n",
            "gradient mean= -1.4556100040863384e-06\n",
            "loss: 2.322287  [19200/27455]\n",
            "gradient mean= -4.4488334083325753e-07\n",
            "loss: 2.322464  [25600/27455]\n",
            "gradient mean= -1.9176313514890353e-07\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.573109 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322174 \n",
            "\n",
            "Epoch 84\n",
            "-----------------------------\n",
            "loss: 2.322280  [    0/27455]\n",
            "gradient mean= 8.147225827315197e-08\n",
            "loss: 2.322342  [ 6400/27455]\n",
            "gradient mean= 1.2435868939064676e-06\n",
            "loss: 2.322267  [12800/27455]\n",
            "gradient mean= 8.146797654262627e-07\n",
            "loss: 2.322514  [19200/27455]\n",
            "gradient mean= 6.093007414165186e-07\n",
            "loss: 2.322384  [25600/27455]\n",
            "gradient mean= 1.932058239617618e-06\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 2.572536 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322174 \n",
            "\n",
            "Epoch 85\n",
            "-----------------------------\n",
            "loss: 2.322577  [    0/27455]\n",
            "gradient mean= -1.798963012333843e-06\n",
            "loss: 2.322323  [ 6400/27455]\n",
            "gradient mean= -6.718764211655071e-07\n",
            "loss: 2.322315  [12800/27455]\n",
            "gradient mean= 5.528515885089291e-07\n",
            "loss: 2.322449  [19200/27455]\n",
            "gradient mean= -1.5673350617362303e-06\n",
            "loss: 2.322349  [25600/27455]\n",
            "gradient mean= 3.9176140376184776e-07\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.572036 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322175 \n",
            "\n",
            "Epoch 86\n",
            "-----------------------------\n",
            "loss: 2.322375  [    0/27455]\n",
            "gradient mean= -2.0721437010706723e-07\n",
            "loss: 2.322276  [ 6400/27455]\n",
            "gradient mean= 9.080517315851466e-08\n",
            "loss: 2.323034  [12800/27455]\n",
            "gradient mean= -2.7613841666607186e-06\n",
            "loss: 2.322372  [19200/27455]\n",
            "gradient mean= 4.3994538145852857e-07\n",
            "loss: 2.322533  [25600/27455]\n",
            "gradient mean= -1.102746978176583e-06\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 2.575101 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322173 \n",
            "\n",
            "Epoch 87\n",
            "-----------------------------\n",
            "loss: 2.322371  [    0/27455]\n",
            "gradient mean= 8.561550544072816e-07\n",
            "loss: 2.322301  [ 6400/27455]\n",
            "gradient mean= 2.6258007324031496e-07\n",
            "loss: 2.322355  [12800/27455]\n",
            "gradient mean= 6.958892981856479e-07\n",
            "loss: 2.322458  [19200/27455]\n",
            "gradient mean= -6.358708901643695e-07\n",
            "loss: 2.322813  [25600/27455]\n",
            "gradient mean= -1.6209081366014289e-07\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 2.574211 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322172 \n",
            "\n",
            "Epoch 88\n",
            "-----------------------------\n",
            "loss: 2.322314  [    0/27455]\n",
            "gradient mean= -2.2775711272515764e-07\n",
            "loss: 2.322296  [ 6400/27455]\n",
            "gradient mean= -4.3209610112171504e-07\n",
            "loss: 2.322583  [12800/27455]\n",
            "gradient mean= -2.810296564348391e-07\n",
            "loss: 2.322411  [19200/27455]\n",
            "gradient mean= -1.074859824257146e-06\n",
            "loss: 2.322483  [25600/27455]\n",
            "gradient mean= 1.6584069726377493e-06\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.570930 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322168 \n",
            "\n",
            "Epoch 89\n",
            "-----------------------------\n",
            "loss: 2.322428  [    0/27455]\n",
            "gradient mean= 7.528932428613189e-07\n",
            "loss: 2.322362  [ 6400/27455]\n",
            "gradient mean= -6.13765791968035e-07\n",
            "loss: 2.322267  [12800/27455]\n",
            "gradient mean= -8.936787310176442e-09\n",
            "loss: 2.322548  [19200/27455]\n",
            "gradient mean= -6.060419082132285e-07\n",
            "loss: 2.322276  [25600/27455]\n",
            "gradient mean= -3.650318092240923e-08\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 2.572532 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322170 \n",
            "\n",
            "Epoch 90\n",
            "-----------------------------\n",
            "loss: 2.322431  [    0/27455]\n",
            "gradient mean= -7.779323141221539e-07\n",
            "loss: 2.322356  [ 6400/27455]\n",
            "gradient mean= 2.897236228704969e-08\n",
            "loss: 2.322258  [12800/27455]\n",
            "gradient mean= 2.114442310130471e-07\n",
            "loss: 2.322463  [19200/27455]\n",
            "gradient mean= 2.575460200660018e-07\n",
            "loss: 2.322338  [25600/27455]\n",
            "gradient mean= -7.60798627652548e-07\n",
            "Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 2.569313 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322163 \n",
            "\n",
            "Epoch 91\n",
            "-----------------------------\n",
            "loss: 2.322307  [    0/27455]\n",
            "gradient mean= -1.8470032614459342e-07\n",
            "loss: 2.322329  [ 6400/27455]\n",
            "gradient mean= 9.42123676850315e-07\n",
            "loss: 2.322596  [12800/27455]\n",
            "gradient mean= 2.6549714675638825e-06\n",
            "loss: 2.322323  [19200/27455]\n",
            "gradient mean= -1.329468886979157e-06\n",
            "loss: 2.322468  [25600/27455]\n",
            "gradient mean= 1.4298750556918094e-06\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.567660 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322164 \n",
            "\n",
            "Epoch 92\n",
            "-----------------------------\n",
            "loss: 2.322300  [    0/27455]\n",
            "gradient mean= 2.9448436578149995e-08\n",
            "loss: 2.322367  [ 6400/27455]\n",
            "gradient mean= -5.401973908192303e-07\n",
            "loss: 2.322366  [12800/27455]\n",
            "gradient mean= 3.492788493986154e-07\n",
            "loss: 2.322327  [19200/27455]\n",
            "gradient mean= 9.557462590237265e-07\n",
            "loss: 2.322394  [25600/27455]\n",
            "gradient mean= -1.3243316061561927e-06\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.572274 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322163 \n",
            "\n",
            "Epoch 93\n",
            "-----------------------------\n",
            "loss: 2.322272  [    0/27455]\n",
            "gradient mean= -3.7137382946639264e-07\n",
            "loss: 2.322516  [ 6400/27455]\n",
            "gradient mean= 5.006436367693823e-07\n",
            "loss: 2.322404  [12800/27455]\n",
            "gradient mean= -1.213781388287316e-06\n",
            "loss: 2.322415  [19200/27455]\n",
            "gradient mean= -1.0013666269514943e-06\n",
            "loss: 2.322245  [25600/27455]\n",
            "gradient mean= -2.2117731646176253e-08\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 2.568429 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322167 \n",
            "\n",
            "Epoch 94\n",
            "-----------------------------\n",
            "loss: 2.322448  [    0/27455]\n",
            "gradient mean= -2.256120836818809e-07\n",
            "loss: 2.322423  [ 6400/27455]\n",
            "gradient mean= 1.924621074067545e-06\n",
            "loss: 2.322309  [12800/27455]\n",
            "gradient mean= 1.2082034928084795e-08\n",
            "loss: 2.322342  [19200/27455]\n",
            "gradient mean= 2.3084260192263173e-07\n",
            "loss: 2.322284  [25600/27455]\n",
            "gradient mean= -6.814136099819734e-07\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 2.569986 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322167 \n",
            "\n",
            "Epoch 95\n",
            "-----------------------------\n",
            "loss: 2.322399  [    0/27455]\n",
            "gradient mean= 7.731989626336144e-07\n",
            "loss: 2.322487  [ 6400/27455]\n",
            "gradient mean= -3.2316293072653934e-06\n",
            "loss: 2.322360  [12800/27455]\n",
            "gradient mean= -1.0560257805991569e-06\n",
            "loss: 2.322263  [19200/27455]\n",
            "gradient mean= -4.337340158144798e-07\n",
            "loss: 2.322334  [25600/27455]\n",
            "gradient mean= 2.202485305247137e-08\n",
            "Test Error: \n",
            " Accuracy: 79.0%, Avg loss: 2.570214 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322164 \n",
            "\n",
            "Epoch 96\n",
            "-----------------------------\n",
            "loss: 2.322286  [    0/27455]\n",
            "gradient mean= -1.6361674681775185e-07\n",
            "loss: 2.322631  [ 6400/27455]\n",
            "gradient mean= -6.537106287396455e-07\n",
            "loss: 2.322238  [12800/27455]\n",
            "gradient mean= -3.472281377980835e-07\n",
            "loss: 2.322274  [19200/27455]\n",
            "gradient mean= -2.7416459147389105e-07\n",
            "loss: 2.322322  [25600/27455]\n",
            "gradient mean= 8.577448511459806e-07\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.569348 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322164 \n",
            "\n",
            "Epoch 97\n",
            "-----------------------------\n",
            "loss: 2.322531  [    0/27455]\n",
            "gradient mean= -3.858498303088709e-07\n",
            "loss: 2.322270  [ 6400/27455]\n",
            "gradient mean= 1.0363955738057484e-07\n",
            "loss: 2.322254  [12800/27455]\n",
            "gradient mean= -7.964703030438613e-08\n",
            "loss: 2.322357  [19200/27455]\n",
            "gradient mean= -9.906067965914644e-09\n",
            "loss: 2.322255  [25600/27455]\n",
            "gradient mean= -3.4287697303625464e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.568396 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322161 \n",
            "\n",
            "Epoch 98\n",
            "-----------------------------\n",
            "loss: 2.322807  [    0/27455]\n",
            "gradient mean= -3.286560058768373e-06\n",
            "loss: 2.322319  [ 6400/27455]\n",
            "gradient mean= 5.557066629080509e-07\n",
            "loss: 2.322343  [12800/27455]\n",
            "gradient mean= -1.73053152252578e-07\n",
            "loss: 2.322387  [19200/27455]\n",
            "gradient mean= 1.1706449640769279e-06\n",
            "loss: 2.322325  [25600/27455]\n",
            "gradient mean= -4.406660423228459e-07\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.572733 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322156 \n",
            "\n",
            "Epoch 99\n",
            "-----------------------------\n",
            "loss: 2.322401  [    0/27455]\n",
            "gradient mean= 8.017906338864123e-07\n",
            "loss: 2.322304  [ 6400/27455]\n",
            "gradient mean= 7.729140634182841e-07\n",
            "loss: 2.322423  [12800/27455]\n",
            "gradient mean= -3.6737682762577606e-07\n",
            "loss: 2.322469  [19200/27455]\n",
            "gradient mean= -2.704300413824967e-06\n",
            "loss: 2.322628  [25600/27455]\n",
            "gradient mean= 7.040966920612846e-07\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 2.571464 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322161 \n",
            "\n",
            "Epoch 100\n",
            "-----------------------------\n",
            "loss: 2.322320  [    0/27455]\n",
            "gradient mean= 3.5691503086354714e-08\n",
            "loss: 2.322330  [ 6400/27455]\n",
            "gradient mean= 5.313060000844416e-07\n",
            "loss: 2.322286  [12800/27455]\n",
            "gradient mean= 2.5980961027016747e-07\n",
            "loss: 2.322349  [19200/27455]\n",
            "gradient mean= 6.48771447231411e-07\n",
            "loss: 2.322404  [25600/27455]\n",
            "gradient mean= -1.0944030464088428e-06\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.571464 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322162 \n",
            "\n",
            "Epoch 101\n",
            "-----------------------------\n",
            "loss: 2.322581  [    0/27455]\n",
            "gradient mean= 1.074104375220486e-06\n",
            "loss: 2.322645  [ 6400/27455]\n",
            "gradient mean= 2.0288651114697132e-07\n",
            "loss: 2.322653  [12800/27455]\n",
            "gradient mean= 4.0221792119155e-08\n",
            "loss: 2.322282  [19200/27455]\n",
            "gradient mean= 2.374480772004972e-07\n",
            "loss: 2.322268  [25600/27455]\n",
            "gradient mean= -4.666917732265574e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.572195 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322158 \n",
            "\n",
            "Epoch 102\n",
            "-----------------------------\n",
            "loss: 2.322320  [    0/27455]\n",
            "gradient mean= 7.29817699607338e-08\n",
            "loss: 2.322567  [ 6400/27455]\n",
            "gradient mean= -7.672369406463986e-07\n",
            "loss: 2.322355  [12800/27455]\n",
            "gradient mean= 3.0303397124953335e-08\n",
            "loss: 2.322284  [19200/27455]\n",
            "gradient mean= 2.729693164837954e-07\n",
            "loss: 2.322414  [25600/27455]\n",
            "gradient mean= 7.503426786570344e-07\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 2.565415 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322155 \n",
            "\n",
            "Epoch 103\n",
            "-----------------------------\n",
            "loss: 2.322277  [    0/27455]\n",
            "gradient mean= 5.031751584283484e-07\n",
            "loss: 2.322375  [ 6400/27455]\n",
            "gradient mean= 3.580523184609774e-07\n",
            "loss: 2.322333  [12800/27455]\n",
            "gradient mean= 7.207751195892342e-07\n",
            "loss: 2.322300  [19200/27455]\n",
            "gradient mean= 1.780599845346842e-08\n",
            "loss: 2.322657  [25600/27455]\n",
            "gradient mean= 9.55051504547555e-08\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.567995 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322155 \n",
            "\n",
            "Epoch 104\n",
            "-----------------------------\n",
            "loss: 2.322255  [    0/27455]\n",
            "gradient mean= -4.3655867898451106e-07\n",
            "loss: 2.322380  [ 6400/27455]\n",
            "gradient mean= -2.171860380428825e-08\n",
            "loss: 2.322270  [12800/27455]\n",
            "gradient mean= 2.2564537971447862e-07\n",
            "loss: 2.322326  [19200/27455]\n",
            "gradient mean= -2.994353280882933e-07\n",
            "loss: 2.322338  [25600/27455]\n",
            "gradient mean= -2.2550015899014397e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.571876 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322155 \n",
            "\n",
            "Epoch 105\n",
            "-----------------------------\n",
            "loss: 2.322462  [    0/27455]\n",
            "gradient mean= -1.444926510885125e-06\n",
            "loss: 2.322298  [ 6400/27455]\n",
            "gradient mean= -9.800756970435032e-07\n",
            "loss: 2.322395  [12800/27455]\n",
            "gradient mean= 7.366969612121466e-07\n",
            "loss: 2.322376  [19200/27455]\n",
            "gradient mean= -1.043372435560741e-06\n",
            "loss: 2.322303  [25600/27455]\n",
            "gradient mean= -2.2459953186171333e-07\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.567817 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322153 \n",
            "\n",
            "Epoch 106\n",
            "-----------------------------\n",
            "loss: 2.322243  [    0/27455]\n",
            "gradient mean= -2.75845309261058e-07\n",
            "loss: 2.322282  [ 6400/27455]\n",
            "gradient mean= 8.229368120282743e-08\n",
            "loss: 2.322264  [12800/27455]\n",
            "gradient mean= -1.6374259814710967e-07\n",
            "loss: 2.322380  [19200/27455]\n",
            "gradient mean= -3.460185737935717e-08\n",
            "loss: 2.322879  [25600/27455]\n",
            "gradient mean= -2.733301698754076e-06\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.566162 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322153 \n",
            "\n",
            "Epoch 107\n",
            "-----------------------------\n",
            "loss: 2.322275  [    0/27455]\n",
            "gradient mean= -1.3789056652058207e-07\n",
            "loss: 2.322290  [ 6400/27455]\n",
            "gradient mean= -1.2789908510058012e-07\n",
            "loss: 2.322505  [12800/27455]\n",
            "gradient mean= -1.913476353365695e-06\n",
            "loss: 2.322274  [19200/27455]\n",
            "gradient mean= -5.465325898512674e-07\n",
            "loss: 2.322243  [25600/27455]\n",
            "gradient mean= 4.877570631833805e-07\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.570088 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322154 \n",
            "\n",
            "Epoch 108\n",
            "-----------------------------\n",
            "loss: 2.322315  [    0/27455]\n",
            "gradient mean= 1.2156687034803326e-06\n",
            "loss: 2.322398  [ 6400/27455]\n",
            "gradient mean= -2.105305838995264e-06\n",
            "loss: 2.322234  [12800/27455]\n",
            "gradient mean= -2.1403710093181871e-07\n",
            "loss: 2.322215  [19200/27455]\n",
            "gradient mean= 9.676846701722752e-08\n",
            "loss: 2.322298  [25600/27455]\n",
            "gradient mean= -1.2449509085854515e-06\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.569769 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322152 \n",
            "\n",
            "Epoch 109\n",
            "-----------------------------\n",
            "loss: 2.322485  [    0/27455]\n",
            "gradient mean= 8.437754104306805e-07\n",
            "loss: 2.322320  [ 6400/27455]\n",
            "gradient mean= 9.387172816843758e-09\n",
            "loss: 2.322308  [12800/27455]\n",
            "gradient mean= 1.7652813255608635e-07\n",
            "loss: 2.322318  [19200/27455]\n",
            "gradient mean= -8.639186717118719e-07\n",
            "loss: 2.322382  [25600/27455]\n",
            "gradient mean= -2.1006942461099243e-06\n",
            "Test Error: \n",
            " Accuracy: 78.8%, Avg loss: 2.566392 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322151 \n",
            "\n",
            "Epoch 110\n",
            "-----------------------------\n",
            "loss: 2.322226  [    0/27455]\n",
            "gradient mean= 5.3744952310808e-07\n",
            "loss: 2.322235  [ 6400/27455]\n",
            "gradient mean= 1.0606282074832052e-07\n",
            "loss: 2.322254  [12800/27455]\n",
            "gradient mean= 1.5427468724737992e-07\n",
            "loss: 2.322417  [19200/27455]\n",
            "gradient mean= -1.088924136638525e-06\n",
            "loss: 2.322266  [25600/27455]\n",
            "gradient mean= -2.9520418820538907e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.568251 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322167 \n",
            "\n",
            "Epoch 111\n",
            "-----------------------------\n",
            "loss: 2.322328  [    0/27455]\n",
            "gradient mean= -1.042398025674629e-06\n",
            "loss: 2.322277  [ 6400/27455]\n",
            "gradient mean= -5.875643296349153e-07\n",
            "loss: 2.322731  [12800/27455]\n",
            "gradient mean= 3.517502591421362e-07\n",
            "loss: 2.322206  [19200/27455]\n",
            "gradient mean= -1.270255278740251e-08\n",
            "loss: 2.322277  [25600/27455]\n",
            "gradient mean= -4.567085625239997e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.568284 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322157 \n",
            "\n",
            "Epoch 112\n",
            "-----------------------------\n",
            "loss: 2.322253  [    0/27455]\n",
            "gradient mean= 2.5381442014804634e-07\n",
            "loss: 2.322252  [ 6400/27455]\n",
            "gradient mean= 1.0126620964001631e-07\n",
            "loss: 2.322290  [12800/27455]\n",
            "gradient mean= -1.2903536799058202e-06\n",
            "loss: 2.322292  [19200/27455]\n",
            "gradient mean= 5.1269701373257703e-08\n",
            "loss: 2.322358  [25600/27455]\n",
            "gradient mean= 2.132511127683756e-07\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 2.565181 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322151 \n",
            "\n",
            "Epoch 113\n",
            "-----------------------------\n",
            "loss: 2.322335  [    0/27455]\n",
            "gradient mean= 1.1693439319060417e-06\n",
            "loss: 2.322238  [ 6400/27455]\n",
            "gradient mean= 3.3415511779821827e-07\n",
            "loss: 2.322305  [12800/27455]\n",
            "gradient mean= -5.682543928742234e-07\n",
            "loss: 2.322193  [19200/27455]\n",
            "gradient mean= 1.3801980003336212e-07\n",
            "loss: 2.322220  [25600/27455]\n",
            "gradient mean= 2.727218273435028e-08\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.569404 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322148 \n",
            "\n",
            "Epoch 114\n",
            "-----------------------------\n",
            "loss: 2.322291  [    0/27455]\n",
            "gradient mean= -4.875651029578876e-07\n",
            "loss: 2.322381  [ 6400/27455]\n",
            "gradient mean= -7.870723948144587e-07\n",
            "loss: 2.322235  [12800/27455]\n",
            "gradient mean= -1.8127695966541069e-07\n",
            "loss: 2.322265  [19200/27455]\n",
            "gradient mean= -3.0533030326296284e-07\n",
            "loss: 2.322198  [25600/27455]\n",
            "gradient mean= 9.530310762784211e-08\n",
            "Test Error: \n",
            " Accuracy: 77.3%, Avg loss: 2.571337 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322148 \n",
            "\n",
            "Epoch 115\n",
            "-----------------------------\n",
            "loss: 2.322480  [    0/27455]\n",
            "gradient mean= -2.435194090821824e-08\n",
            "loss: 2.322343  [ 6400/27455]\n",
            "gradient mean= 6.260701752580644e-07\n",
            "loss: 2.322294  [12800/27455]\n",
            "gradient mean= 3.8253077150329773e-07\n",
            "loss: 2.322309  [19200/27455]\n",
            "gradient mean= -8.224102430176572e-07\n",
            "loss: 2.322429  [25600/27455]\n",
            "gradient mean= 2.2320705284073483e-06\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.571426 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322145 \n",
            "\n",
            "Epoch 116\n",
            "-----------------------------\n",
            "loss: 2.322469  [    0/27455]\n",
            "gradient mean= -1.3222330608186894e-06\n",
            "loss: 2.322412  [ 6400/27455]\n",
            "gradient mean= 1.839519313762139e-06\n",
            "loss: 2.322380  [12800/27455]\n",
            "gradient mean= 2.077039653158863e-06\n",
            "loss: 2.322256  [19200/27455]\n",
            "gradient mean= -6.340246727631893e-07\n",
            "loss: 2.322208  [25600/27455]\n",
            "gradient mean= 1.564231268957883e-07\n",
            "Test Error: \n",
            " Accuracy: 78.8%, Avg loss: 2.565524 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322148 \n",
            "\n",
            "Epoch 117\n",
            "-----------------------------\n",
            "loss: 2.322333  [    0/27455]\n",
            "gradient mean= 1.0581692322375602e-06\n",
            "loss: 2.322320  [ 6400/27455]\n",
            "gradient mean= -3.82295439749214e-07\n",
            "loss: 2.322358  [12800/27455]\n",
            "gradient mean= 5.126721447368254e-08\n",
            "loss: 2.322250  [19200/27455]\n",
            "gradient mean= 2.5042112383744097e-07\n",
            "loss: 2.322418  [25600/27455]\n",
            "gradient mean= -1.6875367236934835e-06\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.567923 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322147 \n",
            "\n",
            "Epoch 118\n",
            "-----------------------------\n",
            "loss: 2.322217  [    0/27455]\n",
            "gradient mean= -3.104990469182667e-07\n",
            "loss: 2.322246  [ 6400/27455]\n",
            "gradient mean= 9.343281135443249e-07\n",
            "loss: 2.322335  [12800/27455]\n",
            "gradient mean= 6.107210310801747e-07\n",
            "loss: 2.322289  [19200/27455]\n",
            "gradient mean= 1.689138571236981e-07\n",
            "loss: 2.322306  [25600/27455]\n",
            "gradient mean= 4.728912585960643e-07\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.574502 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322147 \n",
            "\n",
            "Epoch 119\n",
            "-----------------------------\n",
            "loss: 2.322236  [    0/27455]\n",
            "gradient mean= 9.008259382881079e-08\n",
            "loss: 2.322273  [ 6400/27455]\n",
            "gradient mean= 3.0110416560091835e-07\n",
            "loss: 2.322339  [12800/27455]\n",
            "gradient mean= 4.239801754124528e-08\n",
            "loss: 2.322359  [19200/27455]\n",
            "gradient mean= 3.524050953274127e-06\n",
            "loss: 2.322635  [25600/27455]\n",
            "gradient mean= 7.264531518558215e-07\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 2.567803 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322146 \n",
            "\n",
            "Epoch 120\n",
            "-----------------------------\n",
            "loss: 2.322195  [    0/27455]\n",
            "gradient mean= -2.746473910519853e-07\n",
            "loss: 2.322274  [ 6400/27455]\n",
            "gradient mean= -1.1729704851859424e-07\n",
            "loss: 2.322223  [12800/27455]\n",
            "gradient mean= -3.1200954708765494e-07\n",
            "loss: 2.322276  [19200/27455]\n",
            "gradient mean= -3.636751557678508e-07\n",
            "loss: 2.322283  [25600/27455]\n",
            "gradient mean= -1.2405706684148754e-07\n",
            "Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 2.565048 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322147 \n",
            "\n",
            "Epoch 121\n",
            "-----------------------------\n",
            "loss: 2.322342  [    0/27455]\n",
            "gradient mean= -9.205292883507354e-08\n",
            "loss: 2.322215  [ 6400/27455]\n",
            "gradient mean= 2.628945594551624e-07\n",
            "loss: 2.322332  [12800/27455]\n",
            "gradient mean= 1.6805388725060766e-07\n",
            "loss: 2.322241  [19200/27455]\n",
            "gradient mean= -4.813961709260184e-07\n",
            "loss: 2.322292  [25600/27455]\n",
            "gradient mean= -2.5770452793949516e-07\n",
            "Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 2.563198 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322144 \n",
            "\n",
            "Epoch 122\n",
            "-----------------------------\n",
            "loss: 2.322577  [    0/27455]\n",
            "gradient mean= 3.006792326232244e-07\n",
            "loss: 2.322510  [ 6400/27455]\n",
            "gradient mean= -1.6063358998508193e-06\n",
            "loss: 2.322196  [12800/27455]\n",
            "gradient mean= 4.18114005640291e-08\n",
            "loss: 2.322375  [19200/27455]\n",
            "gradient mean= -3.643805257524946e-07\n",
            "loss: 2.322318  [25600/27455]\n",
            "gradient mean= 7.520034159824718e-07\n",
            "Test Error: \n",
            " Accuracy: 78.9%, Avg loss: 2.563592 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322144 \n",
            "\n",
            "Epoch 123\n",
            "-----------------------------\n",
            "loss: 2.322276  [    0/27455]\n",
            "gradient mean= 1.618159444660705e-06\n",
            "loss: 2.322266  [ 6400/27455]\n",
            "gradient mean= -2.933978748842492e-07\n",
            "loss: 2.322382  [12800/27455]\n",
            "gradient mean= -3.3403571251255926e-06\n",
            "loss: 2.322325  [19200/27455]\n",
            "gradient mean= -2.8291162834648276e-07\n",
            "loss: 2.322205  [25600/27455]\n",
            "gradient mean= -3.533633474717135e-08\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.567120 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322142 \n",
            "\n",
            "Epoch 124\n",
            "-----------------------------\n",
            "loss: 2.322425  [    0/27455]\n",
            "gradient mean= -8.49477430620027e-08\n",
            "loss: 2.322234  [ 6400/27455]\n",
            "gradient mean= 1.5202935799152328e-07\n",
            "loss: 2.322390  [12800/27455]\n",
            "gradient mean= 1.1376694430964562e-07\n",
            "loss: 2.322271  [19200/27455]\n",
            "gradient mean= -3.058049458104506e-07\n",
            "loss: 2.322448  [25600/27455]\n",
            "gradient mean= 4.2108800357709697e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.567943 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322143 \n",
            "\n",
            "Epoch 125\n",
            "-----------------------------\n",
            "loss: 2.322248  [    0/27455]\n",
            "gradient mean= -6.094851556781578e-08\n",
            "loss: 2.322227  [ 6400/27455]\n",
            "gradient mean= -3.083099500145181e-07\n",
            "loss: 2.322374  [12800/27455]\n",
            "gradient mean= 4.867052325607801e-07\n",
            "loss: 2.322343  [19200/27455]\n",
            "gradient mean= 3.711099907377502e-06\n",
            "loss: 2.322291  [25600/27455]\n",
            "gradient mean= -6.097437790231197e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.566092 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322143 \n",
            "\n",
            "Epoch 126\n",
            "-----------------------------\n",
            "loss: 2.322312  [    0/27455]\n",
            "gradient mean= -1.067319885805773e-06\n",
            "loss: 2.322418  [ 6400/27455]\n",
            "gradient mean= -6.669328627140203e-07\n",
            "loss: 2.322269  [12800/27455]\n",
            "gradient mean= 6.663629505965218e-07\n",
            "loss: 2.322221  [19200/27455]\n",
            "gradient mean= 1.1080689432674262e-07\n",
            "loss: 2.322267  [25600/27455]\n",
            "gradient mean= 3.4230076551011734e-08\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.569518 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322143 \n",
            "\n",
            "Epoch 127\n",
            "-----------------------------\n",
            "loss: 2.322251  [    0/27455]\n",
            "gradient mean= -2.9218444552725487e-08\n",
            "loss: 2.322254  [ 6400/27455]\n",
            "gradient mean= 3.71310790114876e-07\n",
            "loss: 2.322235  [12800/27455]\n",
            "gradient mean= -3.580456109375518e-08\n",
            "loss: 2.322213  [19200/27455]\n",
            "gradient mean= 9.386497623609102e-08\n",
            "loss: 2.322284  [25600/27455]\n",
            "gradient mean= 1.2823740291878494e-07\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.571469 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322138 \n",
            "\n",
            "Epoch 128\n",
            "-----------------------------\n",
            "loss: 2.322296  [    0/27455]\n",
            "gradient mean= 2.2846280955945986e-07\n",
            "loss: 2.322232  [ 6400/27455]\n",
            "gradient mean= 1.5655685103865835e-07\n",
            "loss: 2.322261  [12800/27455]\n",
            "gradient mean= -1.898307715464398e-07\n",
            "loss: 2.322255  [19200/27455]\n",
            "gradient mean= -2.6600460500958434e-07\n",
            "loss: 2.322211  [25600/27455]\n",
            "gradient mean= -2.971522405914584e-08\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.568595 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322140 \n",
            "\n",
            "Epoch 129\n",
            "-----------------------------\n",
            "loss: 2.322222  [    0/27455]\n",
            "gradient mean= 1.6909817190935428e-07\n",
            "loss: 2.322360  [ 6400/27455]\n",
            "gradient mean= 2.914571950896061e-06\n",
            "loss: 2.322176  [12800/27455]\n",
            "gradient mean= 9.199150952099444e-08\n",
            "loss: 2.322237  [19200/27455]\n",
            "gradient mean= -1.2365315171791735e-07\n",
            "loss: 2.322232  [25600/27455]\n",
            "gradient mean= -1.1709331459996974e-07\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.568960 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322142 \n",
            "\n",
            "Epoch 130\n",
            "-----------------------------\n",
            "loss: 2.322227  [    0/27455]\n",
            "gradient mean= -6.042193376742944e-07\n",
            "loss: 2.322304  [ 6400/27455]\n",
            "gradient mean= -1.95526457247297e-08\n",
            "loss: 2.322251  [12800/27455]\n",
            "gradient mean= 2.1982373255013954e-07\n",
            "loss: 2.322202  [19200/27455]\n",
            "gradient mean= -2.5932993708011054e-07\n",
            "loss: 2.322300  [25600/27455]\n",
            "gradient mean= 5.330177188511698e-08\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 2.568406 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322137 \n",
            "\n",
            "Epoch 131\n",
            "-----------------------------\n",
            "loss: 2.322202  [    0/27455]\n",
            "gradient mean= 6.814796194021255e-08\n",
            "loss: 2.322492  [ 6400/27455]\n",
            "gradient mean= 9.916625458572526e-07\n",
            "loss: 2.322298  [12800/27455]\n",
            "gradient mean= 6.840038508926227e-07\n",
            "loss: 2.322493  [19200/27455]\n",
            "gradient mean= 2.230674596148674e-07\n",
            "loss: 2.322242  [25600/27455]\n",
            "gradient mean= -1.4771960366033454e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.564035 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322139 \n",
            "\n",
            "Epoch 132\n",
            "-----------------------------\n",
            "loss: 2.322256  [    0/27455]\n",
            "gradient mean= -4.2704147062977427e-07\n",
            "loss: 2.322220  [ 6400/27455]\n",
            "gradient mean= -1.7196094859173172e-07\n",
            "loss: 2.322212  [12800/27455]\n",
            "gradient mean= 3.325641273477231e-07\n",
            "loss: 2.322258  [19200/27455]\n",
            "gradient mean= -6.840803479235547e-08\n",
            "loss: 2.322531  [25600/27455]\n",
            "gradient mean= -2.2858506198986106e-08\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.563077 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322138 \n",
            "\n",
            "Epoch 133\n",
            "-----------------------------\n",
            "loss: 2.322778  [    0/27455]\n",
            "gradient mean= -1.9551129298633896e-05\n",
            "loss: 2.322246  [ 6400/27455]\n",
            "gradient mean= 6.421349780794117e-07\n",
            "loss: 2.322240  [12800/27455]\n",
            "gradient mean= -8.435249583271798e-07\n",
            "loss: 2.322260  [19200/27455]\n",
            "gradient mean= -1.1366240215693324e-07\n",
            "loss: 2.322231  [25600/27455]\n",
            "gradient mean= -2.0829034497182874e-08\n",
            "Test Error: \n",
            " Accuracy: 78.2%, Avg loss: 2.565442 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322137 \n",
            "\n",
            "Epoch 134\n",
            "-----------------------------\n",
            "loss: 2.322227  [    0/27455]\n",
            "gradient mean= -8.467999919048452e-07\n",
            "loss: 2.322291  [ 6400/27455]\n",
            "gradient mean= -3.709775455718045e-07\n",
            "loss: 2.322272  [12800/27455]\n",
            "gradient mean= 3.7643795280928316e-07\n",
            "loss: 2.322338  [19200/27455]\n",
            "gradient mean= 1.328809844380885e-07\n",
            "loss: 2.322253  [25600/27455]\n",
            "gradient mean= -1.7526429019198986e-07\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.566431 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322137 \n",
            "\n",
            "Epoch 135\n",
            "-----------------------------\n",
            "loss: 2.322280  [    0/27455]\n",
            "gradient mean= -8.480050155412755e-07\n",
            "loss: 2.322242  [ 6400/27455]\n",
            "gradient mean= 9.240593357162652e-08\n",
            "loss: 2.322412  [12800/27455]\n",
            "gradient mean= 8.081027544903918e-07\n",
            "loss: 2.322228  [19200/27455]\n",
            "gradient mean= 9.610638471713173e-07\n",
            "loss: 2.322322  [25600/27455]\n",
            "gradient mean= -5.386846737565065e-07\n",
            "Test Error: \n",
            " Accuracy: 78.9%, Avg loss: 2.567555 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322137 \n",
            "\n",
            "Epoch 136\n",
            "-----------------------------\n",
            "loss: 2.322366  [    0/27455]\n",
            "gradient mean= 2.824268676704378e-06\n",
            "loss: 2.322219  [ 6400/27455]\n",
            "gradient mean= 2.092095883199363e-07\n",
            "loss: 2.322238  [12800/27455]\n",
            "gradient mean= -2.0305861880842713e-08\n",
            "loss: 2.322254  [19200/27455]\n",
            "gradient mean= -3.6430424188438337e-07\n",
            "loss: 2.322298  [25600/27455]\n",
            "gradient mean= -3.7971375377310324e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.566978 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322135 \n",
            "\n",
            "Epoch 137\n",
            "-----------------------------\n",
            "loss: 2.322274  [    0/27455]\n",
            "gradient mean= -1.5328814129134116e-07\n",
            "loss: 2.322192  [ 6400/27455]\n",
            "gradient mean= 1.8764880849175825e-07\n",
            "loss: 2.322222  [12800/27455]\n",
            "gradient mean= 1.9209979029710667e-07\n",
            "loss: 2.322253  [19200/27455]\n",
            "gradient mean= 2.0557631330575532e-07\n",
            "loss: 2.322324  [25600/27455]\n",
            "gradient mean= 1.6135900295921601e-06\n",
            "Test Error: \n",
            " Accuracy: 78.7%, Avg loss: 2.566684 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322137 \n",
            "\n",
            "Epoch 138\n",
            "-----------------------------\n",
            "loss: 2.322309  [    0/27455]\n",
            "gradient mean= 2.683369189071527e-07\n",
            "loss: 2.322242  [ 6400/27455]\n",
            "gradient mean= -5.422789968179131e-07\n",
            "loss: 2.322214  [12800/27455]\n",
            "gradient mean= 1.2065254395565717e-07\n",
            "loss: 2.322479  [19200/27455]\n",
            "gradient mean= -4.573661840368004e-07\n",
            "loss: 2.322251  [25600/27455]\n",
            "gradient mean= 3.792353879816801e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.565059 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322134 \n",
            "\n",
            "Epoch 139\n",
            "-----------------------------\n",
            "loss: 2.322219  [    0/27455]\n",
            "gradient mean= -1.066147987671684e-07\n",
            "loss: 2.322294  [ 6400/27455]\n",
            "gradient mean= 1.6289118320855778e-07\n",
            "loss: 2.322256  [12800/27455]\n",
            "gradient mean= -5.819477451041166e-07\n",
            "loss: 2.322223  [19200/27455]\n",
            "gradient mean= -7.957523280310852e-07\n",
            "loss: 2.322236  [25600/27455]\n",
            "gradient mean= 2.7343170927451865e-07\n",
            "Test Error: \n",
            " Accuracy: 79.1%, Avg loss: 2.563790 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322137 \n",
            "\n",
            "Epoch 140\n",
            "-----------------------------\n",
            "loss: 2.322187  [    0/27455]\n",
            "gradient mean= -2.8422499553926173e-07\n",
            "loss: 2.322208  [ 6400/27455]\n",
            "gradient mean= -2.0757943275384605e-07\n",
            "loss: 2.322353  [12800/27455]\n",
            "gradient mean= 7.66271739394142e-08\n",
            "loss: 2.322192  [19200/27455]\n",
            "gradient mean= 3.0554352292710973e-07\n",
            "loss: 2.322265  [25600/27455]\n",
            "gradient mean= -3.509280759317335e-07\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.567153 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322139 \n",
            "\n",
            "Epoch 141\n",
            "-----------------------------\n",
            "loss: 2.322159  [    0/27455]\n",
            "gradient mean= 8.810757456956253e-09\n",
            "loss: 2.322217  [ 6400/27455]\n",
            "gradient mean= 1.808160163818684e-07\n",
            "loss: 2.322199  [12800/27455]\n",
            "gradient mean= 6.816554076749526e-08\n",
            "loss: 2.322272  [19200/27455]\n",
            "gradient mean= -1.1290930856944215e-08\n",
            "loss: 2.322234  [25600/27455]\n",
            "gradient mean= -2.7885309350494936e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.562466 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322133 \n",
            "\n",
            "Epoch 142\n",
            "-----------------------------\n",
            "loss: 2.322248  [    0/27455]\n",
            "gradient mean= -5.148514787833847e-07\n",
            "loss: 2.322212  [ 6400/27455]\n",
            "gradient mean= -4.6275602016976336e-07\n",
            "loss: 2.322281  [12800/27455]\n",
            "gradient mean= -5.493077992468898e-07\n",
            "loss: 2.322273  [19200/27455]\n",
            "gradient mean= -1.5240875939070975e-07\n",
            "loss: 2.322217  [25600/27455]\n",
            "gradient mean= -1.7085596937249647e-07\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.572215 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322136 \n",
            "\n",
            "Epoch 143\n",
            "-----------------------------\n",
            "loss: 2.322313  [    0/27455]\n",
            "gradient mean= -3.338860210533312e-08\n",
            "loss: 2.322330  [ 6400/27455]\n",
            "gradient mean= 3.3441608593420824e-06\n",
            "loss: 2.322361  [12800/27455]\n",
            "gradient mean= -7.171140055106662e-07\n",
            "loss: 2.322237  [19200/27455]\n",
            "gradient mean= 2.1494784618880658e-07\n",
            "loss: 2.322281  [25600/27455]\n",
            "gradient mean= -3.371195873569377e-07\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.563790 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322135 \n",
            "\n",
            "Epoch 144\n",
            "-----------------------------\n",
            "loss: 2.322215  [    0/27455]\n",
            "gradient mean= -2.0020657132135966e-07\n",
            "loss: 2.322278  [ 6400/27455]\n",
            "gradient mean= -8.277165619574589e-08\n",
            "loss: 2.322237  [12800/27455]\n",
            "gradient mean= -1.4990058616604074e-06\n",
            "loss: 2.322254  [19200/27455]\n",
            "gradient mean= 4.082280611328315e-07\n",
            "loss: 2.322170  [25600/27455]\n",
            "gradient mean= 1.0199968869528675e-08\n",
            "Test Error: \n",
            " Accuracy: 77.7%, Avg loss: 2.566773 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322133 \n",
            "\n",
            "Epoch 145\n",
            "-----------------------------\n",
            "loss: 2.322313  [    0/27455]\n",
            "gradient mean= -5.711446533496201e-07\n",
            "loss: 2.322196  [ 6400/27455]\n",
            "gradient mean= 2.2586462478102476e-07\n",
            "loss: 2.322185  [12800/27455]\n",
            "gradient mean= 1.3238101814749825e-07\n",
            "loss: 2.322257  [19200/27455]\n",
            "gradient mean= 2.1065764599370596e-07\n",
            "loss: 2.322231  [25600/27455]\n",
            "gradient mean= -9.885426379696582e-07\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.567863 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322134 \n",
            "\n",
            "Epoch 146\n",
            "-----------------------------\n",
            "loss: 2.322306  [    0/27455]\n",
            "gradient mean= -6.549917230813662e-08\n",
            "loss: 2.322231  [ 6400/27455]\n",
            "gradient mean= 3.3496846185698814e-07\n",
            "loss: 2.322200  [12800/27455]\n",
            "gradient mean= 3.1677291190135293e-07\n",
            "loss: 2.322332  [19200/27455]\n",
            "gradient mean= -1.1183592505403794e-06\n",
            "loss: 2.322363  [25600/27455]\n",
            "gradient mean= -1.0332942110835575e-06\n",
            "Test Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.562008 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322131 \n",
            "\n",
            "Epoch 147\n",
            "-----------------------------\n",
            "loss: 2.322233  [    0/27455]\n",
            "gradient mean= -5.054467919762828e-07\n",
            "loss: 2.322208  [ 6400/27455]\n",
            "gradient mean= 3.933729431082611e-07\n",
            "loss: 2.322198  [12800/27455]\n",
            "gradient mean= 3.6979133710701717e-07\n",
            "loss: 2.322192  [19200/27455]\n",
            "gradient mean= 2.3957710482136463e-07\n",
            "loss: 2.322293  [25600/27455]\n",
            "gradient mean= 5.184057272344944e-08\n",
            "Test Error: \n",
            " Accuracy: 77.9%, Avg loss: 2.566784 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322133 \n",
            "\n",
            "Epoch 148\n",
            "-----------------------------\n",
            "loss: 2.322250  [    0/27455]\n",
            "gradient mean= 7.013642555619981e-09\n",
            "loss: 2.322224  [ 6400/27455]\n",
            "gradient mean= 1.221669663209468e-07\n",
            "loss: 2.322276  [12800/27455]\n",
            "gradient mean= -1.7310561872818653e-08\n",
            "loss: 2.322206  [19200/27455]\n",
            "gradient mean= 4.757906424401881e-08\n",
            "loss: 2.322183  [25600/27455]\n",
            "gradient mean= 1.840303269773358e-07\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 2.566880 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322133 \n",
            "\n",
            "Epoch 149\n",
            "-----------------------------\n",
            "loss: 2.322278  [    0/27455]\n",
            "gradient mean= 2.01075877725998e-07\n",
            "loss: 2.322263  [ 6400/27455]\n",
            "gradient mean= -8.329026002229512e-08\n",
            "loss: 2.322252  [12800/27455]\n",
            "gradient mean= 9.766234825292486e-07\n",
            "loss: 2.322199  [19200/27455]\n",
            "gradient mean= -7.041877552182996e-07\n",
            "loss: 2.322305  [25600/27455]\n",
            "gradient mean= 3.6471357134360005e-07\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 2.566654 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322130 \n",
            "\n",
            "Epoch 150\n",
            "-----------------------------\n",
            "loss: 2.322234  [    0/27455]\n",
            "gradient mean= -6.903066491759091e-07\n",
            "loss: 2.322215  [ 6400/27455]\n",
            "gradient mean= -2.730724304456089e-07\n",
            "loss: 2.322176  [12800/27455]\n",
            "gradient mean= 2.5629690370010394e-08\n",
            "loss: 2.322212  [19200/27455]\n",
            "gradient mean= -2.281489486222199e-07\n",
            "loss: 2.322193  [25600/27455]\n",
            "gradient mean= 5.819535431328404e-08\n",
            "Test Error: \n",
            " Accuracy: 78.6%, Avg loss: 2.560814 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322128 \n",
            "\n",
            "Done!\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 150\n",
        "optimizer = torch.optim.SGD(simple_model_SGD.parameters(), lr=3e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-----------------------------\")\n",
        "    train_loop(train_dataloader, simple_model_SGD, optimizer, loss_fn)\n",
        "    test_loop(simple_model_SGD, loss_fn, test_losses, train_losses)\n",
        "print(\"Done!\")\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-----------------------------\n",
            "loss: 3.258813  [    0/27455]\n",
            "gradient mean= 8.746817002247553e-06\n",
            "loss: 2.982475  [ 6400/27455]\n",
            "gradient mean= -2.0948145902366377e-05\n",
            "loss: 2.927320  [12800/27455]\n",
            "gradient mean= -3.512855255394243e-05\n",
            "loss: 2.682502  [19200/27455]\n",
            "gradient mean= -0.0001362572656944394\n",
            "loss: 2.594649  [25600/27455]\n",
            "gradient mean= -5.398034045356326e-05\n",
            "Test Error: \n",
            " Accuracy: 52.4%, Avg loss: 2.905083 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 61.5%, Avg loss: 2.830707 \n",
            "\n",
            "Epoch 2\n",
            "-----------------------------\n",
            "loss: 2.599598  [    0/27455]\n",
            "gradient mean= -7.266447937581688e-05\n",
            "loss: 2.459844  [ 6400/27455]\n",
            "gradient mean= -3.584342630347237e-05\n",
            "loss: 2.389660  [12800/27455]\n",
            "gradient mean= -7.000588084338233e-05\n",
            "loss: 2.374947  [19200/27455]\n",
            "gradient mean= 6.385258893715218e-05\n",
            "loss: 2.349891  [25600/27455]\n",
            "gradient mean= -6.034233229001984e-05\n",
            "Test Error: \n",
            " Accuracy: 39.9%, Avg loss: 2.947018 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 57.2%, Avg loss: 2.787764 \n",
            "\n",
            "Epoch 3\n",
            "-----------------------------\n",
            "loss: 2.349134  [    0/27455]\n",
            "gradient mean= 1.5359970348072238e-05\n",
            "loss: 2.333480  [ 6400/27455]\n",
            "gradient mean= 4.2553463572403416e-05\n",
            "loss: 2.341639  [12800/27455]\n",
            "gradient mean= -3.129744072793983e-05\n",
            "loss: 2.332485  [19200/27455]\n",
            "gradient mean= -2.8319675038801506e-05\n",
            "loss: 2.351002  [25600/27455]\n",
            "gradient mean= -3.067106081289239e-05\n",
            "Test Error: \n",
            " Accuracy: 45.5%, Avg loss: 2.883722 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 57.3%, Avg loss: 2.770970 \n",
            "\n",
            "Epoch 4\n",
            "-----------------------------\n",
            "loss: 2.339514  [    0/27455]\n",
            "gradient mean= -2.8860108614026103e-06\n",
            "loss: 2.341462  [ 6400/27455]\n",
            "gradient mean= 2.2508516849484295e-05\n",
            "loss: 2.337070  [12800/27455]\n",
            "gradient mean= 2.950335510831792e-05\n",
            "loss: 2.325397  [19200/27455]\n",
            "gradient mean= -3.7572128348983824e-05\n",
            "loss: 2.327249  [25600/27455]\n",
            "gradient mean= -3.9828187254897784e-06\n",
            "Test Error: \n",
            " Accuracy: 50.4%, Avg loss: 2.829470 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 70.0%, Avg loss: 2.639284 \n",
            "\n",
            "Epoch 5\n",
            "-----------------------------\n",
            "loss: 2.333945  [    0/27455]\n",
            "gradient mean= 4.225661905365996e-05\n",
            "loss: 2.324417  [ 6400/27455]\n",
            "gradient mean= 6.866219791845651e-06\n",
            "loss: 2.325005  [12800/27455]\n",
            "gradient mean= -8.895973451217287e-07\n",
            "loss: 2.331669  [19200/27455]\n",
            "gradient mean= -1.7832715457188897e-05\n",
            "loss: 2.335473  [25600/27455]\n",
            "gradient mean= 3.326142905279994e-05\n",
            "Test Error: \n",
            " Accuracy: 67.2%, Avg loss: 2.669527 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 87.2%, Avg loss: 2.476453 \n",
            "\n",
            "Epoch 6\n",
            "-----------------------------\n",
            "loss: 2.324012  [    0/27455]\n",
            "gradient mean= -5.950149898126256e-06\n",
            "loss: 2.322711  [ 6400/27455]\n",
            "gradient mean= -6.601813424822467e-07\n",
            "loss: 2.324484  [12800/27455]\n",
            "gradient mean= 4.106155301997205e-06\n",
            "loss: 2.323889  [19200/27455]\n",
            "gradient mean= 4.0877600326894026e-07\n",
            "loss: 2.325022  [25600/27455]\n",
            "gradient mean= 2.1937707060715184e-05\n",
            "Test Error: \n",
            " Accuracy: 67.2%, Avg loss: 2.661217 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 90.3%, Avg loss: 2.439136 \n",
            "\n",
            "Epoch 7\n",
            "-----------------------------\n",
            "loss: 2.323256  [    0/27455]\n",
            "gradient mean= 2.8969263894396136e-06\n",
            "loss: 2.323062  [ 6400/27455]\n",
            "gradient mean= -2.236384233356148e-07\n",
            "loss: 2.322914  [12800/27455]\n",
            "gradient mean= -3.0871153740008594e-06\n",
            "loss: 2.322885  [19200/27455]\n",
            "gradient mean= 2.2399931367544923e-06\n",
            "loss: 2.322570  [25600/27455]\n",
            "gradient mean= 7.989527261997864e-07\n",
            "Test Error: \n",
            " Accuracy: 71.3%, Avg loss: 2.623290 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 92.9%, Avg loss: 2.406064 \n",
            "\n",
            "Epoch 8\n",
            "-----------------------------\n",
            "loss: 2.325652  [    0/27455]\n",
            "gradient mean= -9.061500350071583e-06\n",
            "loss: 2.328597  [ 6400/27455]\n",
            "gradient mean= -2.3630602299817838e-05\n",
            "loss: 2.322791  [12800/27455]\n",
            "gradient mean= -6.49887965664675e-07\n",
            "loss: 2.323071  [19200/27455]\n",
            "gradient mean= 1.4024403753865045e-05\n",
            "loss: 2.322220  [25600/27455]\n",
            "gradient mean= 1.9720781097021245e-07\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 2.512690 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322291 \n",
            "\n",
            "Epoch 9\n",
            "-----------------------------\n",
            "loss: 2.322395  [    0/27455]\n",
            "gradient mean= 2.6113821149920113e-06\n",
            "loss: 2.326912  [ 6400/27455]\n",
            "gradient mean= -2.4919714633142576e-05\n",
            "loss: 2.323108  [12800/27455]\n",
            "gradient mean= -2.625869910843903e-06\n",
            "loss: 2.322453  [19200/27455]\n",
            "gradient mean= -1.5871223979502247e-07\n",
            "loss: 2.322252  [25600/27455]\n",
            "gradient mean= -9.645572873751007e-08\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.752394 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 73.0%, Avg loss: 2.601899 \n",
            "\n",
            "Epoch 10\n",
            "-----------------------------\n",
            "loss: 2.322831  [    0/27455]\n",
            "gradient mean= -3.407524673093576e-06\n",
            "loss: 2.324425  [ 6400/27455]\n",
            "gradient mean= -1.0198315294474014e-06\n",
            "loss: 2.322523  [12800/27455]\n",
            "gradient mean= 2.6133607207157183e-06\n",
            "loss: 2.322972  [19200/27455]\n",
            "gradient mean= -5.694213314200169e-07\n",
            "loss: 2.327766  [25600/27455]\n",
            "gradient mean= 4.862295827479102e-05\n",
            "Test Error: \n",
            " Accuracy: 54.6%, Avg loss: 2.783458 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 69.9%, Avg loss: 2.633437 \n",
            "\n",
            "Epoch 11\n",
            "-----------------------------\n",
            "loss: 2.325022  [    0/27455]\n",
            "gradient mean= 8.061419066507369e-05\n",
            "loss: 2.323530  [ 6400/27455]\n",
            "gradient mean= -7.737034138699528e-06\n",
            "loss: 2.323966  [12800/27455]\n",
            "gradient mean= -1.0687178473745007e-05\n",
            "loss: 2.324755  [19200/27455]\n",
            "gradient mean= -2.1609030227409676e-05\n",
            "loss: 2.322164  [25600/27455]\n",
            "gradient mean= -1.7276680353006668e-07\n",
            "Test Error: \n",
            " Accuracy: 67.3%, Avg loss: 2.647311 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 88.4%, Avg loss: 2.449106 \n",
            "\n",
            "Epoch 12\n",
            "-----------------------------\n",
            "loss: 2.330468  [    0/27455]\n",
            "gradient mean= -1.196031917061191e-05\n",
            "loss: 2.322185  [ 6400/27455]\n",
            "gradient mean= 2.0512378284820443e-07\n",
            "loss: 2.322312  [12800/27455]\n",
            "gradient mean= 5.735224704039865e-07\n",
            "loss: 2.323868  [19200/27455]\n",
            "gradient mean= 5.610307198367082e-06\n",
            "loss: 2.326441  [25600/27455]\n",
            "gradient mean= -2.5849643861874938e-05\n",
            "Test Error: \n",
            " Accuracy: 63.9%, Avg loss: 2.693097 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 88.5%, Avg loss: 2.455116 \n",
            "\n",
            "Epoch 13\n",
            "-----------------------------\n",
            "loss: 2.323400  [    0/27455]\n",
            "gradient mean= -1.924733396663214e-06\n",
            "loss: 2.325063  [ 6400/27455]\n",
            "gradient mean= 3.866930910589872e-06\n",
            "loss: 2.322290  [12800/27455]\n",
            "gradient mean= -1.3101686135996715e-06\n",
            "loss: 2.332753  [19200/27455]\n",
            "gradient mean= 2.5415982236154377e-05\n",
            "loss: 2.342038  [25600/27455]\n",
            "gradient mean= 6.628215487580746e-05\n",
            "Test Error: \n",
            " Accuracy: 65.7%, Avg loss: 2.675533 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 88.7%, Avg loss: 2.447142 \n",
            "\n",
            "Epoch 14\n",
            "-----------------------------\n",
            "loss: 2.322572  [    0/27455]\n",
            "gradient mean= 6.808776333855349e-07\n",
            "loss: 2.324545  [ 6400/27455]\n",
            "gradient mean= -1.966320451174397e-05\n",
            "loss: 2.322482  [12800/27455]\n",
            "gradient mean= -7.952078249218175e-07\n",
            "loss: 2.338854  [19200/27455]\n",
            "gradient mean= 4.473592980502872e-06\n",
            "loss: 2.322267  [25600/27455]\n",
            "gradient mean= 5.241884082352044e-07\n",
            "Test Error: \n",
            " Accuracy: 70.0%, Avg loss: 2.635134 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 92.2%, Avg loss: 2.411879 \n",
            "\n",
            "Epoch 15\n",
            "-----------------------------\n",
            "loss: 2.331365  [    0/27455]\n",
            "gradient mean= -2.3830147256376222e-05\n",
            "loss: 2.335774  [ 6400/27455]\n",
            "gradient mean= 2.1031676169513958e-06\n",
            "loss: 2.324893  [12800/27455]\n",
            "gradient mean= 2.6724301278591156e-06\n",
            "loss: 2.325919  [19200/27455]\n",
            "gradient mean= -3.4612883155205054e-06\n",
            "loss: 2.322113  [25600/27455]\n",
            "gradient mean= 1.4619369714807817e-08\n",
            "Test Error: \n",
            " Accuracy: 68.3%, Avg loss: 2.648015 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 89.3%, Avg loss: 2.436930 \n",
            "\n",
            "Epoch 16\n",
            "-----------------------------\n",
            "loss: 2.322186  [    0/27455]\n",
            "gradient mean= 5.60436490104621e-07\n",
            "loss: 2.322400  [ 6400/27455]\n",
            "gradient mean= -1.1739200544980122e-06\n",
            "loss: 2.334724  [12800/27455]\n",
            "gradient mean= -1.3276307072374038e-05\n",
            "loss: 2.324846  [19200/27455]\n",
            "gradient mean= 7.123971499822801e-06\n",
            "loss: 2.331561  [25600/27455]\n",
            "gradient mean= 0.00011331599671393633\n",
            "Test Error: \n",
            " Accuracy: 77.5%, Avg loss: 2.551176 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.0%, Avg loss: 2.335360 \n",
            "\n",
            "Epoch 17\n",
            "-----------------------------\n",
            "loss: 2.322531  [    0/27455]\n",
            "gradient mean= -6.318129663895888e-08\n",
            "loss: 2.323164  [ 6400/27455]\n",
            "gradient mean= 2.2093604457040783e-06\n",
            "loss: 2.322141  [12800/27455]\n",
            "gradient mean= -1.7047587164142897e-07\n",
            "loss: 2.351964  [19200/27455]\n",
            "gradient mean= -1.0021171874541324e-06\n",
            "loss: 2.322140  [25600/27455]\n",
            "gradient mean= 1.0040782427722661e-07\n",
            "Test Error: \n",
            " Accuracy: 69.4%, Avg loss: 2.634790 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 89.5%, Avg loss: 2.432293 \n",
            "\n",
            "Epoch 18\n",
            "-----------------------------\n",
            "loss: 2.322348  [    0/27455]\n",
            "gradient mean= -2.190941813751124e-06\n",
            "loss: 2.322202  [ 6400/27455]\n",
            "gradient mean= -1.1125184329330295e-07\n",
            "loss: 2.322111  [12800/27455]\n",
            "gradient mean= 5.8673805369835463e-08\n",
            "loss: 2.322402  [19200/27455]\n",
            "gradient mean= 1.8125123233403428e-06\n",
            "loss: 2.326288  [25600/27455]\n",
            "gradient mean= -3.522084443829954e-05\n",
            "Test Error: \n",
            " Accuracy: 58.2%, Avg loss: 2.748238 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 80.0%, Avg loss: 2.530081 \n",
            "\n",
            "Epoch 19\n",
            "-----------------------------\n",
            "loss: 2.337569  [    0/27455]\n",
            "gradient mean= -6.710145680699497e-05\n",
            "loss: 2.322415  [ 6400/27455]\n",
            "gradient mean= -3.903518518200144e-06\n",
            "loss: 2.322142  [12800/27455]\n",
            "gradient mean= -4.361805139296848e-08\n",
            "loss: 2.322543  [19200/27455]\n",
            "gradient mean= -2.3663459103318019e-07\n",
            "loss: 2.337626  [25600/27455]\n",
            "gradient mean= 2.9042395908618346e-05\n",
            "Test Error: \n",
            " Accuracy: 73.2%, Avg loss: 2.594313 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.0%, Avg loss: 2.387040 \n",
            "\n",
            "Epoch 20\n",
            "-----------------------------\n",
            "loss: 2.322591  [    0/27455]\n",
            "gradient mean= 1.5557570520741137e-07\n",
            "loss: 2.323049  [ 6400/27455]\n",
            "gradient mean= 2.6281359168933704e-06\n",
            "loss: 2.323895  [12800/27455]\n",
            "gradient mean= 1.99927126232069e-06\n",
            "loss: 2.322258  [19200/27455]\n",
            "gradient mean= -6.056649795027624e-07\n",
            "loss: 2.337976  [25600/27455]\n",
            "gradient mean= -3.010396198988019e-07\n",
            "Test Error: \n",
            " Accuracy: 59.3%, Avg loss: 2.736030 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 79.0%, Avg loss: 2.540872 \n",
            "\n",
            "Epoch 21\n",
            "-----------------------------\n",
            "loss: 2.322222  [    0/27455]\n",
            "gradient mean= 1.0434918067403487e-06\n",
            "loss: 2.322983  [ 6400/27455]\n",
            "gradient mean= 1.1752057616831735e-05\n",
            "loss: 2.324902  [12800/27455]\n",
            "gradient mean= -1.4823687024545507e-06\n",
            "loss: 2.322151  [19200/27455]\n",
            "gradient mean= 2.8203280066918524e-07\n",
            "loss: 2.322241  [25600/27455]\n",
            "gradient mean= -4.3842348418365873e-07\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.551177 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.6%, Avg loss: 2.339099 \n",
            "\n",
            "Epoch 22\n",
            "-----------------------------\n",
            "loss: 2.322153  [    0/27455]\n",
            "gradient mean= -1.3740677218265773e-07\n",
            "loss: 2.322388  [ 6400/27455]\n",
            "gradient mean= 4.66313366587201e-07\n",
            "loss: 2.336402  [12800/27455]\n",
            "gradient mean= 1.2712897841993254e-05\n",
            "loss: 2.322111  [19200/27455]\n",
            "gradient mean= -3.3942505694994907e-08\n",
            "loss: 2.322392  [25600/27455]\n",
            "gradient mean= -4.27266422775574e-06\n",
            "Test Error: \n",
            " Accuracy: 73.9%, Avg loss: 2.586441 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 95.9%, Avg loss: 2.367054 \n",
            "\n",
            "Epoch 23\n",
            "-----------------------------\n",
            "loss: 2.334243  [    0/27455]\n",
            "gradient mean= 1.0319957254978362e-05\n",
            "loss: 2.322649  [ 6400/27455]\n",
            "gradient mean= 1.1584907042561099e-06\n",
            "loss: 2.328264  [12800/27455]\n",
            "gradient mean= -2.4653863874846138e-05\n",
            "loss: 2.322491  [19200/27455]\n",
            "gradient mean= -3.1258975923265098e-06\n",
            "loss: 2.322353  [25600/27455]\n",
            "gradient mean= -2.921208988482249e-06\n",
            "Test Error: \n",
            " Accuracy: 70.3%, Avg loss: 2.625211 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.9%, Avg loss: 2.379576 \n",
            "\n",
            "Epoch 24\n",
            "-----------------------------\n",
            "loss: 2.354323  [    0/27455]\n",
            "gradient mean= 5.1267426897538826e-05\n",
            "loss: 2.322756  [ 6400/27455]\n",
            "gradient mean= -3.6504109175439226e-06\n",
            "loss: 2.322116  [12800/27455]\n",
            "gradient mean= 1.0297452490704018e-07\n",
            "loss: 2.322100  [19200/27455]\n",
            "gradient mean= 1.6673396885380498e-08\n",
            "loss: 2.323270  [25600/27455]\n",
            "gradient mean= -3.123689793937956e-06\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 2.504636 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.323047 \n",
            "\n",
            "Epoch 25\n",
            "-----------------------------\n",
            "loss: 2.322247  [    0/27455]\n",
            "gradient mean= -9.124867688115046e-07\n",
            "loss: 2.322228  [ 6400/27455]\n",
            "gradient mean= 2.6713226475294505e-07\n",
            "loss: 2.322170  [12800/27455]\n",
            "gradient mean= -2.0229580854902451e-07\n",
            "loss: 2.322471  [19200/27455]\n",
            "gradient mean= -6.375226803356782e-06\n",
            "loss: 2.322446  [25600/27455]\n",
            "gradient mean= -1.1840398173035283e-07\n",
            "Test Error: \n",
            " Accuracy: 48.6%, Avg loss: 2.832604 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 64.4%, Avg loss: 2.681416 \n",
            "\n",
            "Epoch 26\n",
            "-----------------------------\n",
            "loss: 2.322214  [    0/27455]\n",
            "gradient mean= 4.4327430259727407e-07\n",
            "loss: 2.322330  [ 6400/27455]\n",
            "gradient mean= -5.213197482589749e-07\n",
            "loss: 2.322258  [12800/27455]\n",
            "gradient mean= -5.902366524423996e-07\n",
            "loss: 2.332496  [19200/27455]\n",
            "gradient mean= 3.3402538974769413e-05\n",
            "loss: 2.338730  [25600/27455]\n",
            "gradient mean= -1.0784192454593722e-05\n",
            "Test Error: \n",
            " Accuracy: 72.4%, Avg loss: 2.606625 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 96.8%, Avg loss: 2.358962 \n",
            "\n",
            "Epoch 27\n",
            "-----------------------------\n",
            "loss: 2.322114  [    0/27455]\n",
            "gradient mean= 3.2643097114259945e-08\n",
            "loss: 2.322117  [ 6400/27455]\n",
            "gradient mean= -7.385064559883858e-09\n",
            "loss: 2.322359  [12800/27455]\n",
            "gradient mean= -3.323922044273786e-07\n",
            "loss: 2.322118  [19200/27455]\n",
            "gradient mean= -9.651230215013129e-08\n",
            "loss: 2.322116  [25600/27455]\n",
            "gradient mean= 1.1216258144486346e-07\n",
            "Test Error: \n",
            " Accuracy: 70.7%, Avg loss: 2.619994 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.5%, Avg loss: 2.381848 \n",
            "\n",
            "Epoch 28\n",
            "-----------------------------\n",
            "loss: 2.322439  [    0/27455]\n",
            "gradient mean= 1.3952748076917487e-06\n",
            "loss: 2.322617  [ 6400/27455]\n",
            "gradient mean= -3.271331934229238e-06\n",
            "loss: 2.322140  [12800/27455]\n",
            "gradient mean= 1.7893391657253233e-07\n",
            "loss: 2.322107  [19200/27455]\n",
            "gradient mean= 1.6386560730552446e-07\n",
            "loss: 2.322096  [25600/27455]\n",
            "gradient mean= 2.1561137319991985e-09\n",
            "Test Error: \n",
            " Accuracy: 76.4%, Avg loss: 2.564717 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 96.8%, Avg loss: 2.358242 \n",
            "\n",
            "Epoch 29\n",
            "-----------------------------\n",
            "loss: 2.322101  [    0/27455]\n",
            "gradient mean= -7.669072488170059e-09\n",
            "loss: 2.327779  [ 6400/27455]\n",
            "gradient mean= 1.001989767246414e-05\n",
            "loss: 2.337827  [12800/27455]\n",
            "gradient mean= -9.714924686932136e-08\n",
            "loss: 2.329219  [19200/27455]\n",
            "gradient mean= 2.4378201487706974e-05\n",
            "loss: 2.322239  [25600/27455]\n",
            "gradient mean= -9.146570505436102e-07\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 2.516321 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.9%, Avg loss: 2.334142 \n",
            "\n",
            "Epoch 30\n",
            "-----------------------------\n",
            "loss: 2.322133  [    0/27455]\n",
            "gradient mean= -5.678470582637374e-09\n",
            "loss: 2.322099  [ 6400/27455]\n",
            "gradient mean= 3.032045015061158e-08\n",
            "loss: 2.322100  [12800/27455]\n",
            "gradient mean= 8.162680309453663e-09\n",
            "loss: 2.322104  [19200/27455]\n",
            "gradient mean= -9.021311475621019e-10\n",
            "loss: 2.322852  [25600/27455]\n",
            "gradient mean= 7.151371846703114e-06\n",
            "Test Error: \n",
            " Accuracy: 71.2%, Avg loss: 2.619470 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 89.3%, Avg loss: 2.432478 \n",
            "\n",
            "Epoch 31\n",
            "-----------------------------\n",
            "loss: 2.325865  [    0/27455]\n",
            "gradient mean= -5.681207767338492e-06\n",
            "loss: 2.322105  [ 6400/27455]\n",
            "gradient mean= 6.102493443904677e-08\n",
            "loss: 2.322951  [12800/27455]\n",
            "gradient mean= -3.5149091672792565e-06\n",
            "loss: 2.330575  [19200/27455]\n",
            "gradient mean= 1.6788373613962904e-05\n",
            "loss: 2.322373  [25600/27455]\n",
            "gradient mean= 5.139641871210188e-06\n",
            "Test Error: \n",
            " Accuracy: 78.5%, Avg loss: 2.541693 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.0%, Avg loss: 2.334791 \n",
            "\n",
            "Epoch 32\n",
            "-----------------------------\n",
            "loss: 2.322784  [    0/27455]\n",
            "gradient mean= -1.132280317506229e-06\n",
            "loss: 2.322126  [ 6400/27455]\n",
            "gradient mean= 2.7301529925694012e-08\n",
            "loss: 2.322101  [12800/27455]\n",
            "gradient mean= -3.864498765437929e-08\n",
            "loss: 2.322151  [19200/27455]\n",
            "gradient mean= -8.666262374390499e-08\n",
            "loss: 2.322113  [25600/27455]\n",
            "gradient mean= 1.784218817135752e-08\n",
            "Test Error: \n",
            " Accuracy: 68.6%, Avg loss: 2.637664 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 86.0%, Avg loss: 2.467977 \n",
            "\n",
            "Epoch 33\n",
            "-----------------------------\n",
            "loss: 2.323669  [    0/27455]\n",
            "gradient mean= 5.6202247833425645e-06\n",
            "loss: 2.322484  [ 6400/27455]\n",
            "gradient mean= -2.700866730265261e-07\n",
            "loss: 2.322118  [12800/27455]\n",
            "gradient mean= 5.6472684306640986e-09\n",
            "loss: 2.322130  [19200/27455]\n",
            "gradient mean= 1.48698900415134e-10\n",
            "loss: 2.322159  [25600/27455]\n",
            "gradient mean= -4.2571991798467934e-07\n",
            "Test Error: \n",
            " Accuracy: 71.1%, Avg loss: 2.615846 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 95.8%, Avg loss: 2.367740 \n",
            "\n",
            "Epoch 34\n",
            "-----------------------------\n",
            "loss: 2.323314  [    0/27455]\n",
            "gradient mean= -5.116822649142705e-06\n",
            "loss: 2.322098  [ 6400/27455]\n",
            "gradient mean= 2.9266169931929653e-08\n",
            "loss: 2.322102  [12800/27455]\n",
            "gradient mean= 1.4890286337276848e-08\n",
            "loss: 2.322155  [19200/27455]\n",
            "gradient mean= 2.3426690631822567e-07\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= 2.871927806680219e-09\n",
            "Test Error: \n",
            " Accuracy: 80.0%, Avg loss: 2.528889 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.326110 \n",
            "\n",
            "Epoch 35\n",
            "-----------------------------\n",
            "loss: 2.322113  [    0/27455]\n",
            "gradient mean= 3.2166391861210286e-07\n",
            "loss: 2.322099  [ 6400/27455]\n",
            "gradient mean= -7.9352195925253e-09\n",
            "loss: 2.322168  [12800/27455]\n",
            "gradient mean= -7.20109838425742e-08\n",
            "loss: 2.322099  [19200/27455]\n",
            "gradient mean= 3.065651554834403e-08\n",
            "loss: 2.322096  [25600/27455]\n",
            "gradient mean= 1.5500248196076427e-08\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 2.505549 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327285 \n",
            "\n",
            "Epoch 36\n",
            "-----------------------------\n",
            "loss: 2.322127  [    0/27455]\n",
            "gradient mean= -2.0184044657867162e-08\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -6.514832007198379e-10\n",
            "loss: 2.323069  [12800/27455]\n",
            "gradient mean= -5.7923011809180025e-06\n",
            "loss: 2.323195  [19200/27455]\n",
            "gradient mean= 1.7402449884684756e-05\n",
            "loss: 2.322110  [25600/27455]\n",
            "gradient mean= -2.110017582879209e-08\n",
            "Test Error: \n",
            " Accuracy: 66.6%, Avg loss: 2.656375 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 90.9%, Avg loss: 2.419139 \n",
            "\n",
            "Epoch 37\n",
            "-----------------------------\n",
            "loss: 2.323727  [    0/27455]\n",
            "gradient mean= 3.638090788626869e-07\n",
            "loss: 2.322390  [ 6400/27455]\n",
            "gradient mean= -3.632453854152118e-06\n",
            "loss: 2.322106  [12800/27455]\n",
            "gradient mean= 1.542574956658882e-08\n",
            "loss: 2.323050  [19200/27455]\n",
            "gradient mean= 3.3759581583581166e-06\n",
            "loss: 2.322190  [25600/27455]\n",
            "gradient mean= 3.506982295675698e-07\n",
            "Test Error: \n",
            " Accuracy: 81.9%, Avg loss: 2.508063 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322310 \n",
            "\n",
            "Epoch 38\n",
            "-----------------------------\n",
            "loss: 2.322114  [    0/27455]\n",
            "gradient mean= 2.5408817805328e-07\n",
            "loss: 2.322453  [ 6400/27455]\n",
            "gradient mean= 2.1202777134021744e-06\n",
            "loss: 2.331576  [12800/27455]\n",
            "gradient mean= 5.302310000843136e-06\n",
            "loss: 2.327587  [19200/27455]\n",
            "gradient mean= 1.1561905921553262e-06\n",
            "loss: 2.322622  [25600/27455]\n",
            "gradient mean= -1.088554085981741e-06\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 2.506167 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.2%, Avg loss: 2.330274 \n",
            "\n",
            "Epoch 39\n",
            "-----------------------------\n",
            "loss: 2.336793  [    0/27455]\n",
            "gradient mean= 1.133380123974348e-06\n",
            "loss: 2.322434  [ 6400/27455]\n",
            "gradient mean= 4.524462440258503e-07\n",
            "loss: 2.323093  [12800/27455]\n",
            "gradient mean= 2.147788507045334e-07\n",
            "loss: 2.322109  [19200/27455]\n",
            "gradient mean= -9.317083993209963e-08\n",
            "loss: 2.322185  [25600/27455]\n",
            "gradient mean= -3.2307079322890786e-07\n",
            "Test Error: \n",
            " Accuracy: 85.0%, Avg loss: 2.481583 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322191 \n",
            "\n",
            "Epoch 40\n",
            "-----------------------------\n",
            "loss: 2.322414  [    0/27455]\n",
            "gradient mean= -8.550438224119716e-07\n",
            "loss: 2.338716  [ 6400/27455]\n",
            "gradient mean= -7.1635658969171345e-06\n",
            "loss: 2.322314  [12800/27455]\n",
            "gradient mean= -4.4717941705130215e-07\n",
            "loss: 2.322653  [19200/27455]\n",
            "gradient mean= -7.361000825767405e-06\n",
            "loss: 2.322185  [25600/27455]\n",
            "gradient mean= -4.3952059058938175e-07\n",
            "Test Error: \n",
            " Accuracy: 69.5%, Avg loss: 2.628005 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 91.5%, Avg loss: 2.410708 \n",
            "\n",
            "Epoch 41\n",
            "-----------------------------\n",
            "loss: 2.322435  [    0/27455]\n",
            "gradient mean= -4.854404664911272e-07\n",
            "loss: 2.322181  [ 6400/27455]\n",
            "gradient mean= 1.647441649765824e-07\n",
            "loss: 2.322096  [12800/27455]\n",
            "gradient mean= 2.1957966112040594e-08\n",
            "loss: 2.322101  [19200/27455]\n",
            "gradient mean= -1.0511743475660751e-08\n",
            "loss: 2.322098  [25600/27455]\n",
            "gradient mean= 1.5951527876367777e-09\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 2.485123 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322095 \n",
            "\n",
            "Epoch 42\n",
            "-----------------------------\n",
            "loss: 2.322563  [    0/27455]\n",
            "gradient mean= -7.387761797872372e-07\n",
            "loss: 2.322134  [ 6400/27455]\n",
            "gradient mean= -1.6051830087349117e-08\n",
            "loss: 2.322260  [12800/27455]\n",
            "gradient mean= 1.052783204613661e-06\n",
            "loss: 2.322138  [19200/27455]\n",
            "gradient mean= 4.266544806341699e-08\n",
            "loss: 2.332721  [25600/27455]\n",
            "gradient mean= -1.2317844266362954e-05\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 2.555268 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.326149 \n",
            "\n",
            "Epoch 43\n",
            "-----------------------------\n",
            "loss: 2.322099  [    0/27455]\n",
            "gradient mean= 1.4380027835159126e-08\n",
            "loss: 2.322160  [ 6400/27455]\n",
            "gradient mean= -7.514630624427809e-07\n",
            "loss: 2.322098  [12800/27455]\n",
            "gradient mean= 1.288745998806462e-08\n",
            "loss: 2.322101  [19200/27455]\n",
            "gradient mean= 4.07115541278813e-09\n",
            "loss: 2.322106  [25600/27455]\n",
            "gradient mean= -5.459515506345269e-09\n",
            "Test Error: \n",
            " Accuracy: 76.2%, Avg loss: 2.556311 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 97.0%, Avg loss: 2.354027 \n",
            "\n",
            "Epoch 44\n",
            "-----------------------------\n",
            "loss: 2.322135  [    0/27455]\n",
            "gradient mean= -8.451496569250594e-08\n",
            "loss: 2.335239  [ 6400/27455]\n",
            "gradient mean= -1.3472975297190715e-05\n",
            "loss: 2.322104  [12800/27455]\n",
            "gradient mean= 1.0401999261944184e-09\n",
            "loss: 2.322116  [19200/27455]\n",
            "gradient mean= -4.888499383071121e-09\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= -1.8138200941208993e-09\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 2.506820 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322331 \n",
            "\n",
            "Epoch 45\n",
            "-----------------------------\n",
            "loss: 2.322109  [    0/27455]\n",
            "gradient mean= -3.158959671623052e-08\n",
            "loss: 2.322103  [ 6400/27455]\n",
            "gradient mean= -9.146510215884973e-09\n",
            "loss: 2.322100  [12800/27455]\n",
            "gradient mean= 2.4692509370538573e-08\n",
            "loss: 2.322098  [19200/27455]\n",
            "gradient mean= -1.8752027486357292e-08\n",
            "loss: 2.322659  [25600/27455]\n",
            "gradient mean= -1.2792185088983388e-06\n",
            "Test Error: \n",
            " Accuracy: 69.6%, Avg loss: 2.630725 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 90.4%, Avg loss: 2.423657 \n",
            "\n",
            "Epoch 46\n",
            "-----------------------------\n",
            "loss: 2.322679  [    0/27455]\n",
            "gradient mean= -1.6381759451178368e-06\n",
            "loss: 2.327390  [ 6400/27455]\n",
            "gradient mean= -1.531250381958671e-05\n",
            "loss: 2.322287  [12800/27455]\n",
            "gradient mean= -8.082827207545051e-07\n",
            "loss: 2.337867  [19200/27455]\n",
            "gradient mean= 1.08276447008393e-06\n",
            "loss: 2.322100  [25600/27455]\n",
            "gradient mean= -1.5443692547023602e-08\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 2.517296 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325968 \n",
            "\n",
            "Epoch 47\n",
            "-----------------------------\n",
            "loss: 2.330206  [    0/27455]\n",
            "gradient mean= -1.121061450248817e-05\n",
            "loss: 2.322099  [ 6400/27455]\n",
            "gradient mean= -1.6639276623209298e-08\n",
            "loss: 2.322143  [12800/27455]\n",
            "gradient mean= -1.654064760714391e-07\n",
            "loss: 2.322104  [19200/27455]\n",
            "gradient mean= 1.792228920827199e-09\n",
            "loss: 2.352401  [25600/27455]\n",
            "gradient mean= 1.7281183772865916e-06\n",
            "Test Error: \n",
            " Accuracy: 65.5%, Avg loss: 2.665219 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 87.6%, Avg loss: 2.450982 \n",
            "\n",
            "Epoch 48\n",
            "-----------------------------\n",
            "loss: 2.347439  [    0/27455]\n",
            "gradient mean= -2.9649580028490163e-05\n",
            "loss: 2.334005  [ 6400/27455]\n",
            "gradient mean= 3.4029289963655174e-05\n",
            "loss: 2.322262  [12800/27455]\n",
            "gradient mean= -9.376621505907679e-07\n",
            "loss: 2.322158  [19200/27455]\n",
            "gradient mean= 6.051421053143713e-08\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= -6.61863286399722e-10\n",
            "Test Error: \n",
            " Accuracy: 80.4%, Avg loss: 2.524236 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.8%, Avg loss: 2.324528 \n",
            "\n",
            "Epoch 49\n",
            "-----------------------------\n",
            "loss: 2.322359  [    0/27455]\n",
            "gradient mean= -3.2056955205916893e-06\n",
            "loss: 2.322886  [ 6400/27455]\n",
            "gradient mean= -9.149243282990938e-07\n",
            "loss: 2.322099  [12800/27455]\n",
            "gradient mean= -1.552879602684243e-08\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -1.28190247306037e-09\n",
            "loss: 2.322100  [25600/27455]\n",
            "gradient mean= 3.591886610365691e-08\n",
            "Test Error: \n",
            " Accuracy: 74.6%, Avg loss: 2.575995 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 96.3%, Avg loss: 2.360601 \n",
            "\n",
            "Epoch 50\n",
            "-----------------------------\n",
            "loss: 2.322107  [    0/27455]\n",
            "gradient mean= -1.0415694617904592e-07\n",
            "loss: 2.322390  [ 6400/27455]\n",
            "gradient mean= -1.9275927343187504e-07\n",
            "loss: 2.322680  [12800/27455]\n",
            "gradient mean= -2.4473495159327285e-06\n",
            "loss: 2.322120  [19200/27455]\n",
            "gradient mean= -1.097375061931416e-07\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= 9.498303477073478e-09\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 2.487576 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.322847 \n",
            "\n",
            "Epoch 51\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 4.0663780676020167e-10\n",
            "loss: 2.322167  [ 6400/27455]\n",
            "gradient mean= -2.0744154483054444e-07\n",
            "loss: 2.337773  [12800/27455]\n",
            "gradient mean= 1.7364237692163442e-06\n",
            "loss: 2.322398  [19200/27455]\n",
            "gradient mean= -4.4035900259586924e-07\n",
            "loss: 2.322101  [25600/27455]\n",
            "gradient mean= 2.017160660727768e-09\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 2.489025 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322184 \n",
            "\n",
            "Epoch 52\n",
            "-----------------------------\n",
            "loss: 2.322134  [    0/27455]\n",
            "gradient mean= 1.4258732861094359e-08\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= -1.4338404907832114e-09\n",
            "loss: 2.322098  [12800/27455]\n",
            "gradient mean= 6.541933217363294e-09\n",
            "loss: 2.322094  [19200/27455]\n",
            "gradient mean= 3.025644179643905e-09\n",
            "loss: 2.322099  [25600/27455]\n",
            "gradient mean= 5.393882673843109e-08\n",
            "Test Error: \n",
            " Accuracy: 83.1%, Avg loss: 2.492385 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.323514 \n",
            "\n",
            "Epoch 53\n",
            "-----------------------------\n",
            "loss: 2.322095  [    0/27455]\n",
            "gradient mean= 1.0509094927613205e-08\n",
            "loss: 2.322099  [ 6400/27455]\n",
            "gradient mean= -1.3272130949815164e-08\n",
            "loss: 2.322104  [12800/27455]\n",
            "gradient mean= -5.3864525284552656e-08\n",
            "loss: 2.322205  [19200/27455]\n",
            "gradient mean= -5.915413225920929e-07\n",
            "loss: 2.326784  [25600/27455]\n",
            "gradient mean= -3.6197761801304296e-05\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 2.619072 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 96.9%, Avg loss: 2.358039 \n",
            "\n",
            "Epoch 54\n",
            "-----------------------------\n",
            "loss: 2.337977  [    0/27455]\n",
            "gradient mean= 9.061445211955288e-07\n",
            "loss: 2.322113  [ 6400/27455]\n",
            "gradient mean= 6.77038372032257e-08\n",
            "loss: 2.322213  [12800/27455]\n",
            "gradient mean= 3.49706795077509e-07\n",
            "loss: 2.322567  [19200/27455]\n",
            "gradient mean= 5.241648523224285e-06\n",
            "loss: 2.322148  [25600/27455]\n",
            "gradient mean= 3.887131327928728e-08\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 2.502811 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.322664 \n",
            "\n",
            "Epoch 55\n",
            "-----------------------------\n",
            "loss: 2.322097  [    0/27455]\n",
            "gradient mean= 7.95541943432454e-09\n",
            "loss: 2.326943  [ 6400/27455]\n",
            "gradient mean= 2.455398089296068e-06\n",
            "loss: 2.322297  [12800/27455]\n",
            "gradient mean= -1.623664047656348e-06\n",
            "loss: 2.322315  [19200/27455]\n",
            "gradient mean= 1.1167147704327363e-06\n",
            "loss: 2.322111  [25600/27455]\n",
            "gradient mean= 1.6595578244960052e-08\n",
            "Test Error: \n",
            " Accuracy: 68.1%, Avg loss: 2.640174 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 90.3%, Avg loss: 2.421415 \n",
            "\n",
            "Epoch 56\n",
            "-----------------------------\n",
            "loss: 2.328796  [    0/27455]\n",
            "gradient mean= -3.9503311199950986e-06\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 8.530245260152114e-11\n",
            "loss: 2.322094  [12800/27455]\n",
            "gradient mean= -2.1177877229661135e-09\n",
            "loss: 2.325125  [19200/27455]\n",
            "gradient mean= 4.782570613315329e-06\n",
            "loss: 2.322125  [25600/27455]\n",
            "gradient mean= -1.823675006562553e-07\n",
            "Test Error: \n",
            " Accuracy: 79.8%, Avg loss: 2.527304 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.8%, Avg loss: 2.324567 \n",
            "\n",
            "Epoch 57\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -9.142470669409875e-10\n",
            "loss: 2.322340  [ 6400/27455]\n",
            "gradient mean= 4.374848003863008e-07\n",
            "loss: 2.322117  [12800/27455]\n",
            "gradient mean= 2.1225618596076856e-08\n",
            "loss: 2.337674  [19200/27455]\n",
            "gradient mean= -1.2437443785984215e-07\n",
            "loss: 2.322116  [25600/27455]\n",
            "gradient mean= -1.392803916644425e-08\n",
            "Test Error: \n",
            " Accuracy: 60.7%, Avg loss: 2.717693 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 78.3%, Avg loss: 2.541005 \n",
            "\n",
            "Epoch 58\n",
            "-----------------------------\n",
            "loss: 2.337755  [    0/27455]\n",
            "gradient mean= -1.595996650394227e-07\n",
            "loss: 2.322129  [ 6400/27455]\n",
            "gradient mean= -7.752923636417108e-08\n",
            "loss: 2.322110  [12800/27455]\n",
            "gradient mean= -2.2904744767515695e-08\n",
            "loss: 2.322119  [19200/27455]\n",
            "gradient mean= -3.089103017828165e-08\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= 9.829530522864616e-10\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.468725 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322098 \n",
            "\n",
            "Epoch 59\n",
            "-----------------------------\n",
            "loss: 2.322189  [    0/27455]\n",
            "gradient mean= -2.3031654450278438e-07\n",
            "loss: 2.322275  [ 6400/27455]\n",
            "gradient mean= 4.3816766037707566e-07\n",
            "loss: 2.322152  [12800/27455]\n",
            "gradient mean= -5.79795823796303e-07\n",
            "loss: 2.322274  [19200/27455]\n",
            "gradient mean= 3.9143887420323153e-07\n",
            "loss: 2.322100  [25600/27455]\n",
            "gradient mean= 1.0622057011744346e-08\n",
            "Test Error: \n",
            " Accuracy: 81.4%, Avg loss: 2.510311 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.8%, Avg loss: 2.324845 \n",
            "\n",
            "Epoch 60\n",
            "-----------------------------\n",
            "loss: 2.322240  [    0/27455]\n",
            "gradient mean= -5.39935740562214e-07\n",
            "loss: 2.322095  [ 6400/27455]\n",
            "gradient mean= -6.643483096979708e-09\n",
            "loss: 2.323131  [12800/27455]\n",
            "gradient mean= 1.3763554306933656e-05\n",
            "loss: 2.322219  [19200/27455]\n",
            "gradient mean= -4.7225003640960495e-07\n",
            "loss: 2.322100  [25600/27455]\n",
            "gradient mean= 7.675268420825887e-09\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 2.485538 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324870 \n",
            "\n",
            "Epoch 61\n",
            "-----------------------------\n",
            "loss: 2.322097  [    0/27455]\n",
            "gradient mean= 2.938663756779647e-10\n",
            "loss: 2.322142  [ 6400/27455]\n",
            "gradient mean= 1.4173960494190396e-07\n",
            "loss: 2.322095  [12800/27455]\n",
            "gradient mean= 4.826796184964621e-10\n",
            "loss: 2.322101  [19200/27455]\n",
            "gradient mean= -7.660063516823357e-08\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= -1.90453142145941e-09\n",
            "Test Error: \n",
            " Accuracy: 77.6%, Avg loss: 2.545391 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.0%, Avg loss: 2.343665 \n",
            "\n",
            "Epoch 62\n",
            "-----------------------------\n",
            "loss: 2.322120  [    0/27455]\n",
            "gradient mean= 2.4478566729158047e-07\n",
            "loss: 2.322115  [ 6400/27455]\n",
            "gradient mean= 2.1358815160965605e-08\n",
            "loss: 2.322094  [12800/27455]\n",
            "gradient mean= -5.720081297511115e-09\n",
            "loss: 2.322097  [19200/27455]\n",
            "gradient mean= 4.05693922900241e-09\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= -2.5829083316608603e-10\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 2.465837 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322103 \n",
            "\n",
            "Epoch 63\n",
            "-----------------------------\n",
            "loss: 2.328908  [    0/27455]\n",
            "gradient mean= 5.954845619271509e-06\n",
            "loss: 2.322109  [ 6400/27455]\n",
            "gradient mean= 2.9345901708666133e-08\n",
            "loss: 2.323518  [12800/27455]\n",
            "gradient mean= -4.848897788178874e-06\n",
            "loss: 2.322213  [19200/27455]\n",
            "gradient mean= -6.867504112051392e-07\n",
            "loss: 2.322178  [25600/27455]\n",
            "gradient mean= 8.105986637474416e-08\n",
            "Test Error: \n",
            " Accuracy: 75.6%, Avg loss: 2.568346 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 96.7%, Avg loss: 2.356927 \n",
            "\n",
            "Epoch 64\n",
            "-----------------------------\n",
            "loss: 2.322094  [    0/27455]\n",
            "gradient mean= -5.680830472698517e-09\n",
            "loss: 2.322098  [ 6400/27455]\n",
            "gradient mean= -4.053649083068933e-10\n",
            "loss: 2.322239  [12800/27455]\n",
            "gradient mean= -8.945870035859116e-07\n",
            "loss: 2.322094  [19200/27455]\n",
            "gradient mean= -3.4662479553304593e-09\n",
            "loss: 2.323175  [25600/27455]\n",
            "gradient mean= -4.592030109051848e-06\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 2.478824 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322183 \n",
            "\n",
            "Epoch 65\n",
            "-----------------------------\n",
            "loss: 2.322112  [    0/27455]\n",
            "gradient mean= -4.1374985215725246e-08\n",
            "loss: 2.322097  [ 6400/27455]\n",
            "gradient mean= 2.117149122682349e-08\n",
            "loss: 2.322096  [12800/27455]\n",
            "gradient mean= -6.3103131608954754e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -1.8436996374049386e-10\n",
            "loss: 2.322104  [25600/27455]\n",
            "gradient mean= 9.001849821110852e-10\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 2.488710 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326843 \n",
            "\n",
            "Epoch 66\n",
            "-----------------------------\n",
            "loss: 2.322764  [    0/27455]\n",
            "gradient mean= -2.8174354156362824e-06\n",
            "loss: 2.322520  [ 6400/27455]\n",
            "gradient mean= 2.687208052520873e-06\n",
            "loss: 2.322099  [12800/27455]\n",
            "gradient mean= -4.580303425427701e-08\n",
            "loss: 2.322116  [19200/27455]\n",
            "gradient mean= 2.5093001454479236e-08\n",
            "loss: 2.322141  [25600/27455]\n",
            "gradient mean= 1.8706008120261686e-07\n",
            "Test Error: \n",
            " Accuracy: 52.0%, Avg loss: 2.808206 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 70.5%, Avg loss: 2.618797 \n",
            "\n",
            "Epoch 67\n",
            "-----------------------------\n",
            "loss: 2.322409  [    0/27455]\n",
            "gradient mean= 1.4491251931758597e-06\n",
            "loss: 2.322095  [ 6400/27455]\n",
            "gradient mean= -8.088838043818214e-09\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 6.238930205793025e-11\n",
            "loss: 2.322106  [19200/27455]\n",
            "gradient mean= 2.7126707990987597e-08\n",
            "loss: 2.322097  [25600/27455]\n",
            "gradient mean= 2.5022310889966093e-09\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 2.478433 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 68\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.2359963053043543e-09\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -6.529281559863875e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 2.7921553957810374e-10\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -1.658062798171045e-09\n",
            "loss: 2.337727  [25600/27455]\n",
            "gradient mean= -1.7855140299616323e-07\n",
            "Test Error: \n",
            " Accuracy: 69.5%, Avg loss: 2.625182 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 91.5%, Avg loss: 2.411079 \n",
            "\n",
            "Epoch 69\n",
            "-----------------------------\n",
            "loss: 2.323262  [    0/27455]\n",
            "gradient mean= 7.2076527430908754e-06\n",
            "loss: 2.337636  [ 6400/27455]\n",
            "gradient mean= -2.186680063687163e-07\n",
            "loss: 2.322094  [12800/27455]\n",
            "gradient mean= -6.294042176335779e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 1.880802596998521e-10\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -5.433587260683659e-11\n",
            "Test Error: \n",
            " Accuracy: 79.0%, Avg loss: 2.532582 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.9%, Avg loss: 2.333538 \n",
            "\n",
            "Epoch 70\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -3.664312464568553e-10\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 4.994922808698732e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 4.672083830925544e-10\n",
            "loss: 2.332025  [19200/27455]\n",
            "gradient mean= 4.183124110568315e-05\n",
            "loss: 2.322422  [25600/27455]\n",
            "gradient mean= -3.402636821192573e-06\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 2.503129 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322441 \n",
            "\n",
            "Epoch 71\n",
            "-----------------------------\n",
            "loss: 2.322130  [    0/27455]\n",
            "gradient mean= 5.8561305138482567e-08\n",
            "loss: 2.322187  [ 6400/27455]\n",
            "gradient mean= 6.994764021328592e-07\n",
            "loss: 2.336697  [12800/27455]\n",
            "gradient mean= 3.803053914452903e-06\n",
            "loss: 2.322138  [19200/27455]\n",
            "gradient mean= 1.9621947444647958e-07\n",
            "loss: 2.322101  [25600/27455]\n",
            "gradient mean= -6.606065738878897e-08\n",
            "Test Error: \n",
            " Accuracy: 69.9%, Avg loss: 2.624562 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 89.3%, Avg loss: 2.432926 \n",
            "\n",
            "Epoch 72\n",
            "-----------------------------\n",
            "loss: 2.322459  [    0/27455]\n",
            "gradient mean= -2.0075374322914286e-06\n",
            "loss: 2.322176  [ 6400/27455]\n",
            "gradient mean= 1.6006522685074742e-07\n",
            "loss: 2.332406  [12800/27455]\n",
            "gradient mean= 2.474152461218182e-05\n",
            "loss: 2.322489  [19200/27455]\n",
            "gradient mean= 1.4405864590116835e-07\n",
            "loss: 2.322162  [25600/27455]\n",
            "gradient mean= 2.697818217711756e-07\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 2.475402 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.322909 \n",
            "\n",
            "Epoch 73\n",
            "-----------------------------\n",
            "loss: 2.322205  [    0/27455]\n",
            "gradient mean= 4.2907802821900987e-07\n",
            "loss: 2.322255  [ 6400/27455]\n",
            "gradient mean= -9.861570333669079e-07\n",
            "loss: 2.322303  [12800/27455]\n",
            "gradient mean= -1.9450305899226805e-07\n",
            "loss: 2.322094  [19200/27455]\n",
            "gradient mean= -1.3340945015372085e-09\n",
            "loss: 2.322112  [25600/27455]\n",
            "gradient mean= 1.312840822720318e-07\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 2.478143 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322121 \n",
            "\n",
            "Epoch 74\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.0057431554244545e-09\n",
            "loss: 2.322112  [ 6400/27455]\n",
            "gradient mean= -2.5136344561360602e-08\n",
            "loss: 2.322096  [12800/27455]\n",
            "gradient mean= 9.264070399694901e-09\n",
            "loss: 2.322098  [19200/27455]\n",
            "gradient mean= -1.323174281253614e-08\n",
            "loss: 2.322443  [25600/27455]\n",
            "gradient mean= -3.2642262226545427e-07\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 2.487786 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.8%, Avg loss: 2.324514 \n",
            "\n",
            "Epoch 75\n",
            "-----------------------------\n",
            "loss: 2.322115  [    0/27455]\n",
            "gradient mean= 5.18632035095834e-08\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -1.755894180055506e-10\n",
            "loss: 2.322095  [12800/27455]\n",
            "gradient mean= 2.6380634565725813e-08\n",
            "loss: 2.326701  [19200/27455]\n",
            "gradient mean= 3.0277897167252377e-05\n",
            "loss: 2.322277  [25600/27455]\n",
            "gradient mean= -1.0477333489689045e-06\n",
            "Test Error: \n",
            " Accuracy: 69.8%, Avg loss: 2.624894 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 90.3%, Avg loss: 2.421944 \n",
            "\n",
            "Epoch 76\n",
            "-----------------------------\n",
            "loss: 2.322112  [    0/27455]\n",
            "gradient mean= -7.136268020957459e-09\n",
            "loss: 2.322135  [ 6400/27455]\n",
            "gradient mean= 1.047492617090029e-07\n",
            "loss: 2.322112  [12800/27455]\n",
            "gradient mean= 2.2554985434908303e-07\n",
            "loss: 2.322099  [19200/27455]\n",
            "gradient mean= 5.937111779985571e-08\n",
            "loss: 2.322104  [25600/27455]\n",
            "gradient mean= 1.089596746162158e-09\n",
            "Test Error: \n",
            " Accuracy: 81.7%, Avg loss: 2.506654 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322253 \n",
            "\n",
            "Epoch 77\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.0994403304431799e-10\n",
            "loss: 2.322095  [ 6400/27455]\n",
            "gradient mean= -2.4801345421820997e-09\n",
            "loss: 2.322101  [12800/27455]\n",
            "gradient mean= 3.4315462471568026e-08\n",
            "loss: 2.322442  [19200/27455]\n",
            "gradient mean= -5.757869985245634e-07\n",
            "loss: 2.322097  [25600/27455]\n",
            "gradient mean= 2.079531569165738e-08\n",
            "Test Error: \n",
            " Accuracy: 74.0%, Avg loss: 2.586914 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.0%, Avg loss: 2.386368 \n",
            "\n",
            "Epoch 78\n",
            "-----------------------------\n",
            "loss: 2.322097  [    0/27455]\n",
            "gradient mean= 1.8270923662910832e-09\n",
            "loss: 2.322119  [ 6400/27455]\n",
            "gradient mean= 2.956138267506958e-08\n",
            "loss: 2.326085  [12800/27455]\n",
            "gradient mean= 1.2044687537127174e-05\n",
            "loss: 2.322146  [19200/27455]\n",
            "gradient mean= -1.2830017794840387e-06\n",
            "loss: 2.326064  [25600/27455]\n",
            "gradient mean= -1.6804920051072259e-06\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 2.491423 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322112 \n",
            "\n",
            "Epoch 79\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 3.707884554948748e-10\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -1.4268326797850506e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 3.2955130291334456e-10\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 4.400038666751982e-10\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 9.52121936848016e-10\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 2.479604 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 80\n",
            "-----------------------------\n",
            "loss: 2.322094  [    0/27455]\n",
            "gradient mean= 4.820282395456843e-09\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= -6.578827704828427e-09\n",
            "loss: 2.322099  [12800/27455]\n",
            "gradient mean= -5.361427568573163e-08\n",
            "loss: 2.322094  [19200/27455]\n",
            "gradient mean= 1.7816573771867183e-09\n",
            "loss: 2.322096  [25600/27455]\n",
            "gradient mean= -1.1321552584320216e-08\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 2.478927 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 81\n",
            "-----------------------------\n",
            "loss: 2.322094  [    0/27455]\n",
            "gradient mean= 2.7718993766967515e-09\n",
            "loss: 2.322099  [ 6400/27455]\n",
            "gradient mean= -8.234448123367599e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 5.374992007034507e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 3.256294192621745e-11\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= -2.878594251853883e-09\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 2.472426 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 82\n",
            "-----------------------------\n",
            "loss: 2.322098  [    0/27455]\n",
            "gradient mean= 4.349629545430389e-09\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 9.54675005715444e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -1.9859683342282608e-10\n",
            "loss: 2.322141  [19200/27455]\n",
            "gradient mean= 7.687440728432193e-08\n",
            "loss: 2.322156  [25600/27455]\n",
            "gradient mean= 4.2753335094403155e-08\n",
            "Test Error: \n",
            " Accuracy: 59.0%, Avg loss: 2.731381 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 84.5%, Avg loss: 2.480285 \n",
            "\n",
            "Epoch 83\n",
            "-----------------------------\n",
            "loss: 2.336473  [    0/27455]\n",
            "gradient mean= -1.5176696024354897e-06\n",
            "loss: 2.322835  [ 6400/27455]\n",
            "gradient mean= 7.114025720511563e-06\n",
            "loss: 2.322193  [12800/27455]\n",
            "gradient mean= -4.476628419070039e-07\n",
            "loss: 2.322107  [19200/27455]\n",
            "gradient mean= 8.862564015998942e-08\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 5.576952233354859e-10\n",
            "Test Error: \n",
            " Accuracy: 79.3%, Avg loss: 2.529687 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.1%, Avg loss: 2.331954 \n",
            "\n",
            "Epoch 84\n",
            "-----------------------------\n",
            "loss: 2.322100  [    0/27455]\n",
            "gradient mean= 1.12319140654904e-08\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -1.2899997736681712e-09\n",
            "loss: 2.322212  [12800/27455]\n",
            "gradient mean= 9.494596611148154e-07\n",
            "loss: 2.322218  [19200/27455]\n",
            "gradient mean= -8.457001143824527e-08\n",
            "loss: 2.323500  [25600/27455]\n",
            "gradient mean= 8.223780127991631e-07\n",
            "Test Error: \n",
            " Accuracy: 68.4%, Avg loss: 2.642281 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 88.6%, Avg loss: 2.439684 \n",
            "\n",
            "Epoch 85\n",
            "-----------------------------\n",
            "loss: 2.322120  [    0/27455]\n",
            "gradient mean= -3.592980490907394e-08\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= -9.598794648013609e-09\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -3.8242833899637674e-10\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -5.402170377699633e-10\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= -8.9915861423151e-09\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 2.479838 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 86\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 5.079690557074912e-10\n",
            "loss: 2.322105  [ 6400/27455]\n",
            "gradient mean= 2.1543861805639608e-08\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 1.1379892583818219e-09\n",
            "loss: 2.322099  [19200/27455]\n",
            "gradient mean= -1.1066777716450815e-08\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -5.2321327825843866e-11\n",
            "Test Error: \n",
            " Accuracy: 81.3%, Avg loss: 2.510674 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.8%, Avg loss: 2.324138 \n",
            "\n",
            "Epoch 87\n",
            "-----------------------------\n",
            "loss: 2.322494  [    0/27455]\n",
            "gradient mean= -6.812033461756073e-07\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -1.356389556228521e-09\n",
            "loss: 2.325028  [12800/27455]\n",
            "gradient mean= 2.6269797217537416e-06\n",
            "loss: 2.322125  [19200/27455]\n",
            "gradient mean= 2.1542890138448456e-08\n",
            "loss: 2.322155  [25600/27455]\n",
            "gradient mean= 3.363394114330731e-07\n",
            "Test Error: \n",
            " Accuracy: 76.8%, Avg loss: 2.559133 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.0%, Avg loss: 2.344513 \n",
            "\n",
            "Epoch 88\n",
            "-----------------------------\n",
            "loss: 2.322150  [    0/27455]\n",
            "gradient mean= 1.9754800462123967e-08\n",
            "loss: 2.322155  [ 6400/27455]\n",
            "gradient mean= -3.0820370966466726e-07\n",
            "loss: 2.325634  [12800/27455]\n",
            "gradient mean= 1.4558647308149375e-05\n",
            "loss: 2.323551  [19200/27455]\n",
            "gradient mean= -2.7534331366041442e-06\n",
            "loss: 2.322153  [25600/27455]\n",
            "gradient mean= -6.316482199508755e-07\n",
            "Test Error: \n",
            " Accuracy: 82.7%, Avg loss: 2.498449 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325878 \n",
            "\n",
            "Epoch 89\n",
            "-----------------------------\n",
            "loss: 2.322105  [    0/27455]\n",
            "gradient mean= -5.926679147449931e-09\n",
            "loss: 2.322097  [ 6400/27455]\n",
            "gradient mean= 4.7966928207188175e-09\n",
            "loss: 2.322102  [12800/27455]\n",
            "gradient mean= -6.952338793553281e-08\n",
            "loss: 2.323095  [19200/27455]\n",
            "gradient mean= 6.6496395447757095e-06\n",
            "loss: 2.322106  [25600/27455]\n",
            "gradient mean= -3.422375272066347e-09\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 2.481988 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322246 \n",
            "\n",
            "Epoch 90\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -1.1634504124002909e-11\n",
            "loss: 2.322115  [ 6400/27455]\n",
            "gradient mean= 3.9778765170694896e-08\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -2.4736707127104296e-10\n",
            "loss: 2.322470  [19200/27455]\n",
            "gradient mean= -5.758328143201652e-07\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= -1.4621852617580089e-09\n",
            "Test Error: \n",
            " Accuracy: 80.1%, Avg loss: 2.526095 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.3%, Avg loss: 2.329674 \n",
            "\n",
            "Epoch 91\n",
            "-----------------------------\n",
            "loss: 2.322098  [    0/27455]\n",
            "gradient mean= 8.231573644934542e-09\n",
            "loss: 2.328270  [ 6400/27455]\n",
            "gradient mean= -1.2270353181520477e-05\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 2.78309930656917e-09\n",
            "loss: 2.331249  [19200/27455]\n",
            "gradient mean= 1.956491541932337e-05\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -1.260794663116016e-10\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 2.493176 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 92\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -1.5062586733449734e-09\n",
            "loss: 2.322098  [ 6400/27455]\n",
            "gradient mean= -1.0339435974060507e-08\n",
            "loss: 2.322116  [12800/27455]\n",
            "gradient mean= -6.192469470533979e-08\n",
            "loss: 2.322100  [19200/27455]\n",
            "gradient mean= 1.1325321125355003e-08\n",
            "loss: 2.322181  [25600/27455]\n",
            "gradient mean= -2.418492215383594e-07\n",
            "Test Error: \n",
            " Accuracy: 82.3%, Avg loss: 2.500212 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.323028 \n",
            "\n",
            "Epoch 93\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -9.987362048491377e-10\n",
            "loss: 2.322107  [ 6400/27455]\n",
            "gradient mean= -3.829493877560708e-08\n",
            "loss: 2.322107  [12800/27455]\n",
            "gradient mean= -4.8484000814141837e-08\n",
            "loss: 2.322130  [19200/27455]\n",
            "gradient mean= 1.776313673929053e-08\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= 5.348258280690743e-09\n",
            "Test Error: \n",
            " Accuracy: 78.0%, Avg loss: 2.543943 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 97.9%, Avg loss: 2.344818 \n",
            "\n",
            "Epoch 94\n",
            "-----------------------------\n",
            "loss: 2.322232  [    0/27455]\n",
            "gradient mean= 2.0009433683298994e-06\n",
            "loss: 2.322517  [ 6400/27455]\n",
            "gradient mean= 1.6858429034982692e-06\n",
            "loss: 2.322098  [12800/27455]\n",
            "gradient mean= -2.0706966807892968e-08\n",
            "loss: 2.322099  [19200/27455]\n",
            "gradient mean= -4.508073470077534e-09\n",
            "loss: 2.323390  [25600/27455]\n",
            "gradient mean= 1.6667063391651027e-05\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 2.485489 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322098 \n",
            "\n",
            "Epoch 95\n",
            "-----------------------------\n",
            "loss: 2.322108  [    0/27455]\n",
            "gradient mean= 2.6237850647703453e-07\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -6.49385337170294e-11\n",
            "loss: 2.322114  [12800/27455]\n",
            "gradient mean= 1.5168733824566516e-08\n",
            "loss: 2.322094  [19200/27455]\n",
            "gradient mean= -3.1166766945034396e-09\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= 2.030050794132876e-09\n",
            "Test Error: \n",
            " Accuracy: 84.1%, Avg loss: 2.480877 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 96\n",
            "-----------------------------\n",
            "loss: 2.322098  [    0/27455]\n",
            "gradient mean= -1.2669901572337494e-08\n",
            "loss: 2.322095  [ 6400/27455]\n",
            "gradient mean= -4.492839877912047e-09\n",
            "loss: 2.322101  [12800/27455]\n",
            "gradient mean= -1.6041996175886197e-08\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 2.5865696737237265e-11\n",
            "loss: 2.322100  [25600/27455]\n",
            "gradient mean= 5.98423088860045e-09\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 2.482366 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322136 \n",
            "\n",
            "Epoch 97\n",
            "-----------------------------\n",
            "loss: 2.322095  [    0/27455]\n",
            "gradient mean= 1.723983800161477e-08\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -1.8840928817098757e-11\n",
            "loss: 2.322290  [12800/27455]\n",
            "gradient mean= 7.579423026982113e-07\n",
            "loss: 2.322094  [19200/27455]\n",
            "gradient mean= -2.3608487387249966e-10\n",
            "loss: 2.322163  [25600/27455]\n",
            "gradient mean= -5.510660816554491e-09\n",
            "Test Error: \n",
            " Accuracy: 65.3%, Avg loss: 2.670743 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 89.5%, Avg loss: 2.429503 \n",
            "\n",
            "Epoch 98\n",
            "-----------------------------\n",
            "loss: 2.322174  [    0/27455]\n",
            "gradient mean= -2.6316786261304514e-07\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 4.067062311929881e-11\n",
            "loss: 2.325061  [12800/27455]\n",
            "gradient mean= -4.4411990529624745e-06\n",
            "loss: 2.322250  [19200/27455]\n",
            "gradient mean= 1.9861586224578787e-06\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -6.924241180428226e-10\n",
            "Test Error: \n",
            " Accuracy: 64.4%, Avg loss: 2.682042 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 82.9%, Avg loss: 2.495487 \n",
            "\n",
            "Epoch 99\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -2.9943409973753887e-09\n",
            "loss: 2.322366  [ 6400/27455]\n",
            "gradient mean= -3.6331332466943422e-06\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -3.766779776981366e-09\n",
            "loss: 2.322098  [19200/27455]\n",
            "gradient mean= 8.976118515136022e-09\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -9.081436123936637e-12\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 2.477494 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322306 \n",
            "\n",
            "Epoch 100\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 3.9967035236898596e-10\n",
            "loss: 2.322103  [ 6400/27455]\n",
            "gradient mean= -5.656708879087091e-08\n",
            "loss: 2.322178  [12800/27455]\n",
            "gradient mean= 4.360855232476979e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 1.1526623405755387e-11\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -1.177859698664463e-09\n",
            "Test Error: \n",
            " Accuracy: 80.7%, Avg loss: 2.521420 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.324264 \n",
            "\n",
            "Epoch 101\n",
            "-----------------------------\n",
            "loss: 2.322099  [    0/27455]\n",
            "gradient mean= 8.519313254851113e-09\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 1.5071057735127624e-09\n",
            "loss: 2.322114  [12800/27455]\n",
            "gradient mean= -4.844806866799445e-08\n",
            "loss: 2.322126  [19200/27455]\n",
            "gradient mean= -8.313767452250431e-09\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 1.8781096122744145e-10\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 2.459763 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 102\n",
            "-----------------------------\n",
            "loss: 2.322099  [    0/27455]\n",
            "gradient mean= 3.810621596045394e-09\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= -1.7055649947916862e-10\n",
            "loss: 2.322095  [12800/27455]\n",
            "gradient mean= -1.5490623894720557e-08\n",
            "loss: 2.322097  [19200/27455]\n",
            "gradient mean= -1.3546865851310486e-09\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -2.0473929496223064e-10\n",
            "Test Error: \n",
            " Accuracy: 79.0%, Avg loss: 2.534022 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.6%, Avg loss: 2.337149 \n",
            "\n",
            "Epoch 103\n",
            "-----------------------------\n",
            "loss: 2.322095  [    0/27455]\n",
            "gradient mean= -1.4685133109537674e-09\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -8.095575598776605e-11\n",
            "loss: 2.336899  [12800/27455]\n",
            "gradient mean= 6.300490895227995e-06\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 2.65762439832784e-10\n",
            "loss: 2.322229  [25600/27455]\n",
            "gradient mean= -4.3705711050279206e-07\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 2.485216 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322479 \n",
            "\n",
            "Epoch 104\n",
            "-----------------------------\n",
            "loss: 2.322234  [    0/27455]\n",
            "gradient mean= 1.9702167719515273e-07\n",
            "loss: 2.322117  [ 6400/27455]\n",
            "gradient mean= 1.0443112330449367e-07\n",
            "loss: 2.322097  [12800/27455]\n",
            "gradient mean= 1.939635563275033e-09\n",
            "loss: 2.322100  [19200/27455]\n",
            "gradient mean= 2.4971102519089072e-08\n",
            "loss: 2.322553  [25600/27455]\n",
            "gradient mean= -1.2477238442443195e-07\n",
            "Test Error: \n",
            " Accuracy: 83.1%, Avg loss: 2.487954 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322131 \n",
            "\n",
            "Epoch 105\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -1.423031722840029e-12\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 3.8067496377358623e-10\n",
            "loss: 2.322102  [12800/27455]\n",
            "gradient mean= -9.213443341593575e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -1.1220362312880372e-11\n",
            "loss: 2.322110  [25600/27455]\n",
            "gradient mean= -3.990884067661682e-08\n",
            "Test Error: \n",
            " Accuracy: 76.5%, Avg loss: 2.560774 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.1%, Avg loss: 2.343738 \n",
            "\n",
            "Epoch 106\n",
            "-----------------------------\n",
            "loss: 2.322221  [    0/27455]\n",
            "gradient mean= 1.1140269862153218e-06\n",
            "loss: 2.327888  [ 6400/27455]\n",
            "gradient mean= 3.924821794498712e-05\n",
            "loss: 2.337352  [12800/27455]\n",
            "gradient mean= 2.5924125068854664e-08\n",
            "loss: 2.322113  [19200/27455]\n",
            "gradient mean= -8.166879439386321e-08\n",
            "loss: 2.324287  [25600/27455]\n",
            "gradient mean= 1.3157951798348222e-05\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 2.497450 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.326059 \n",
            "\n",
            "Epoch 107\n",
            "-----------------------------\n",
            "loss: 2.322105  [    0/27455]\n",
            "gradient mean= -2.23701821511213e-08\n",
            "loss: 2.322180  [ 6400/27455]\n",
            "gradient mean= 3.4832623896363657e-07\n",
            "loss: 2.322328  [12800/27455]\n",
            "gradient mean= 1.4527832945532282e-06\n",
            "loss: 2.322370  [19200/27455]\n",
            "gradient mean= 2.0699800984402827e-07\n",
            "loss: 2.322101  [25600/27455]\n",
            "gradient mean= 5.736035646464188e-09\n",
            "Test Error: \n",
            " Accuracy: 78.1%, Avg loss: 2.540223 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 97.3%, Avg loss: 2.350475 \n",
            "\n",
            "Epoch 108\n",
            "-----------------------------\n",
            "loss: 2.322119  [    0/27455]\n",
            "gradient mean= -3.4275949190032406e-08\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 6.360145743400381e-10\n",
            "loss: 2.322104  [12800/27455]\n",
            "gradient mean= -2.6050233081775787e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -6.538063927058468e-12\n",
            "loss: 2.322181  [25600/27455]\n",
            "gradient mean= 5.396987035055645e-07\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 2.460946 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322109 \n",
            "\n",
            "Epoch 109\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 7.400783111344289e-12\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -4.614838511329822e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -2.7958197978961152e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -1.0493031443736811e-10\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -1.140568750557236e-09\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 2.462839 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 110\n",
            "-----------------------------\n",
            "loss: 2.322094  [    0/27455]\n",
            "gradient mean= 1.6607752950648091e-09\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -5.613398981751949e-11\n",
            "loss: 2.322207  [12800/27455]\n",
            "gradient mean= 4.1837395770016883e-07\n",
            "loss: 2.322111  [19200/27455]\n",
            "gradient mean= 1.9681780827340845e-07\n",
            "loss: 2.323548  [25600/27455]\n",
            "gradient mean= 8.555860404158011e-06\n",
            "Test Error: \n",
            " Accuracy: 75.5%, Avg loss: 2.566543 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 97.8%, Avg loss: 2.346227 \n",
            "\n",
            "Epoch 111\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -1.3717404989677107e-10\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -5.368165023611482e-09\n",
            "loss: 2.322097  [12800/27455]\n",
            "gradient mean= -4.029569122820931e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 1.988667674979183e-09\n",
            "loss: 2.322224  [25600/27455]\n",
            "gradient mean= 5.611314009001944e-07\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 2.521073 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.0%, Avg loss: 2.333395 \n",
            "\n",
            "Epoch 112\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 2.3095014789475954e-09\n",
            "loss: 2.322110  [ 6400/27455]\n",
            "gradient mean= -3.781873980646111e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 8.792440386873324e-11\n",
            "loss: 2.337718  [19200/27455]\n",
            "gradient mean= -6.871028745969454e-10\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 2.7653743739364245e-09\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 2.463529 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322095 \n",
            "\n",
            "Epoch 113\n",
            "-----------------------------\n",
            "loss: 2.322121  [    0/27455]\n",
            "gradient mean= 1.2498338719524327e-07\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= 2.9894076103431644e-09\n",
            "loss: 2.322100  [12800/27455]\n",
            "gradient mean= 2.835328771766399e-08\n",
            "loss: 2.322208  [19200/27455]\n",
            "gradient mean= 6.586149083886994e-07\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 4.7106679668118545e-11\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 2.490923 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.323234 \n",
            "\n",
            "Epoch 114\n",
            "-----------------------------\n",
            "loss: 2.322094  [    0/27455]\n",
            "gradient mean= 3.113681756872211e-09\n",
            "loss: 2.322100  [ 6400/27455]\n",
            "gradient mean= 2.4732338843591606e-08\n",
            "loss: 2.322098  [12800/27455]\n",
            "gradient mean= 1.9403120887773184e-08\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -3.0320135291361794e-09\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 4.858172197863553e-10\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 2.451745 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322208 \n",
            "\n",
            "Epoch 115\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -5.438749450803471e-10\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= -1.3689539279937435e-08\n",
            "loss: 2.322096  [12800/27455]\n",
            "gradient mean= 1.0380151183042585e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -2.8994970487083993e-12\n",
            "loss: 2.322096  [25600/27455]\n",
            "gradient mean= 3.7526241669638694e-08\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 2.479433 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.323517 \n",
            "\n",
            "Epoch 116\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -2.9541345064609814e-11\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= -1.669970717266267e-09\n",
            "loss: 2.322095  [12800/27455]\n",
            "gradient mean= -6.210193248534779e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -1.3755660673020476e-11\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -1.177520303485835e-10\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 2.495267 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322581 \n",
            "\n",
            "Epoch 117\n",
            "-----------------------------\n",
            "loss: 2.322098  [    0/27455]\n",
            "gradient mean= 1.4901088363217241e-08\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -2.955412303773386e-11\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -2.2661439391669091e-10\n",
            "loss: 2.322099  [19200/27455]\n",
            "gradient mean= 1.392928261623183e-08\n",
            "loss: 2.327167  [25600/27455]\n",
            "gradient mean= -1.1834255019493867e-05\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 2.477463 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322374 \n",
            "\n",
            "Epoch 118\n",
            "-----------------------------\n",
            "loss: 2.322141  [    0/27455]\n",
            "gradient mean= 6.468648621194006e-07\n",
            "loss: 2.322097  [ 6400/27455]\n",
            "gradient mean= 7.128396484201716e-11\n",
            "loss: 2.322100  [12800/27455]\n",
            "gradient mean= 2.627925788090124e-08\n",
            "loss: 2.322104  [19200/27455]\n",
            "gradient mean= -2.4759299055432393e-09\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 1.6106234401735975e-10\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.465845 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322095 \n",
            "\n",
            "Epoch 119\n",
            "-----------------------------\n",
            "loss: 2.322371  [    0/27455]\n",
            "gradient mean= 7.697279329477169e-07\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 3.94893562294385e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 2.7244822717320538e-11\n",
            "loss: 2.322095  [19200/27455]\n",
            "gradient mean= 3.3718503544832856e-09\n",
            "loss: 2.336356  [25600/27455]\n",
            "gradient mean= 1.2213232594149304e-06\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 2.469626 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 120\n",
            "-----------------------------\n",
            "loss: 2.323482  [    0/27455]\n",
            "gradient mean= -3.599318915803451e-06\n",
            "loss: 2.337898  [ 6400/27455]\n",
            "gradient mean= -9.60983129516535e-07\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 2.1507227943029505e-10\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -1.0063114924685479e-10\n",
            "loss: 2.322122  [25600/27455]\n",
            "gradient mean= 1.1306291725077244e-07\n",
            "Test Error: \n",
            " Accuracy: 85.8%, Avg loss: 2.467572 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322098 \n",
            "\n",
            "Epoch 121\n",
            "-----------------------------\n",
            "loss: 2.322095  [    0/27455]\n",
            "gradient mean= 1.3866748860280609e-09\n",
            "loss: 2.322160  [ 6400/27455]\n",
            "gradient mean= 8.382485106039894e-08\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 1.0165690511598768e-10\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 7.920591537247806e-14\n",
            "loss: 2.337778  [25600/27455]\n",
            "gradient mean= -2.976401276555407e-07\n",
            "Test Error: \n",
            " Accuracy: 75.4%, Avg loss: 2.566973 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.3%, Avg loss: 2.340817 \n",
            "\n",
            "Epoch 122\n",
            "-----------------------------\n",
            "loss: 2.322402  [    0/27455]\n",
            "gradient mean= -2.493173042239505e-06\n",
            "loss: 2.322423  [ 6400/27455]\n",
            "gradient mean= -7.769473597818433e-08\n",
            "loss: 2.322094  [12800/27455]\n",
            "gradient mean= 9.644868015357133e-09\n",
            "loss: 2.322654  [19200/27455]\n",
            "gradient mean= 6.441944606194738e-06\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= -8.134459328346111e-09\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 2.519876 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.2%, Avg loss: 2.330569 \n",
            "\n",
            "Epoch 123\n",
            "-----------------------------\n",
            "loss: 2.322103  [    0/27455]\n",
            "gradient mean= 1.93108462553937e-08\n",
            "loss: 2.322664  [ 6400/27455]\n",
            "gradient mean= -1.748683871483081e-06\n",
            "loss: 2.322322  [12800/27455]\n",
            "gradient mean= 5.562348519561056e-07\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 2.3588189179690744e-09\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= 1.3126368880733708e-09\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 2.476101 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322453 \n",
            "\n",
            "Epoch 124\n",
            "-----------------------------\n",
            "loss: 2.322097  [    0/27455]\n",
            "gradient mean= 1.1354454265699587e-08\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 8.395562717256055e-11\n",
            "loss: 2.322094  [12800/27455]\n",
            "gradient mean= 1.4923420832424483e-10\n",
            "loss: 2.322097  [19200/27455]\n",
            "gradient mean= 2.937529774982295e-09\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= 2.4994555314350464e-09\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 2.461180 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 125\n",
            "-----------------------------\n",
            "loss: 2.322094  [    0/27455]\n",
            "gradient mean= 4.236444084426694e-09\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 3.8794328860447536e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 1.5308897205468242e-10\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -1.0043307852036776e-10\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= 1.17498810681127e-09\n",
            "Test Error: \n",
            " Accuracy: 78.4%, Avg loss: 2.540290 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 97.5%, Avg loss: 2.347414 \n",
            "\n",
            "Epoch 126\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.258437354323405e-09\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -2.5724216159983548e-11\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 3.6693519334107805e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 2.584172598130152e-10\n",
            "loss: 2.322256  [25600/27455]\n",
            "gradient mean= 1.4082756649713701e-07\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 2.462216 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322109 \n",
            "\n",
            "Epoch 127\n",
            "-----------------------------\n",
            "loss: 2.322115  [    0/27455]\n",
            "gradient mean= -2.3917694491615293e-08\n",
            "loss: 2.322096  [ 6400/27455]\n",
            "gradient mean= -3.7127403373915513e-09\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -1.9911917600867746e-11\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 9.907077241910756e-11\n",
            "loss: 2.322117  [25600/27455]\n",
            "gradient mean= -9.15798281653224e-09\n",
            "Test Error: \n",
            " Accuracy: 85.0%, Avg loss: 2.473914 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322126 \n",
            "\n",
            "Epoch 128\n",
            "-----------------------------\n",
            "loss: 2.322094  [    0/27455]\n",
            "gradient mean= -6.378992445377207e-09\n",
            "loss: 2.322097  [ 6400/27455]\n",
            "gradient mean= 5.953376014389278e-09\n",
            "loss: 2.322102  [12800/27455]\n",
            "gradient mean= -5.108202927317507e-08\n",
            "loss: 2.335424  [19200/27455]\n",
            "gradient mean= 1.3701564057555515e-05\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 4.815255832957277e-11\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 2.476115 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322629 \n",
            "\n",
            "Epoch 129\n",
            "-----------------------------\n",
            "loss: 2.324726  [    0/27455]\n",
            "gradient mean= -1.0542729796725325e-05\n",
            "loss: 2.322095  [ 6400/27455]\n",
            "gradient mean= 3.3602134408283746e-09\n",
            "loss: 2.322096  [12800/27455]\n",
            "gradient mean= 2.263307541383597e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 2.3483318067896164e-10\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 4.6130088637852396e-10\n",
            "Test Error: \n",
            " Accuracy: 74.6%, Avg loss: 2.575809 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.5%, Avg loss: 2.378716 \n",
            "\n",
            "Epoch 130\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.6093709698239422e-10\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -3.250213986838446e-10\n",
            "loss: 2.322095  [12800/27455]\n",
            "gradient mean= 1.602181942672587e-09\n",
            "loss: 2.322095  [19200/27455]\n",
            "gradient mean= 1.0121527616036019e-08\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -1.1373619060450757e-12\n",
            "Test Error: \n",
            " Accuracy: 80.9%, Avg loss: 2.515748 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.0%, Avg loss: 2.332800 \n",
            "\n",
            "Epoch 131\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -2.0646790943601445e-09\n",
            "loss: 2.325602  [ 6400/27455]\n",
            "gradient mean= -3.505508720991202e-05\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -6.598376844912934e-10\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 6.18391782225558e-10\n",
            "loss: 2.337524  [25600/27455]\n",
            "gradient mean= -2.6629504645825364e-07\n",
            "Test Error: \n",
            " Accuracy: 80.4%, Avg loss: 2.517783 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326517 \n",
            "\n",
            "Epoch 132\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 5.602867614307172e-10\n",
            "loss: 2.322096  [ 6400/27455]\n",
            "gradient mean= -1.1683729539413434e-09\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -1.018117590234624e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 1.667765703317059e-09\n",
            "loss: 2.322100  [25600/27455]\n",
            "gradient mean= -1.2190966458547337e-08\n",
            "Test Error: \n",
            " Accuracy: 82.1%, Avg loss: 2.507085 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.5%, Avg loss: 2.337258 \n",
            "\n",
            "Epoch 133\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.3702963763684295e-10\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= -3.6547817550136585e-10\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 5.481552434183357e-10\n",
            "loss: 2.322342  [19200/27455]\n",
            "gradient mean= -2.2525939584738808e-06\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= -5.478365761035775e-09\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 2.469068 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 134\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -3.2740917615958764e-11\n",
            "loss: 2.322193  [ 6400/27455]\n",
            "gradient mean= -5.010768404645205e-07\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -1.2838897722744491e-09\n",
            "loss: 2.322598  [19200/27455]\n",
            "gradient mean= 1.2344156630206271e-06\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 5.767096245001824e-10\n",
            "Test Error: \n",
            " Accuracy: 76.6%, Avg loss: 2.555110 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.4%, Avg loss: 2.339810 \n",
            "\n",
            "Epoch 135\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -6.509007915989073e-11\n",
            "loss: 2.322094  [ 6400/27455]\n",
            "gradient mean= 3.4384888270011515e-09\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -6.809208058511373e-11\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 4.8104178418384436e-09\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 1.4843887230497899e-09\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 2.490498 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.323727 \n",
            "\n",
            "Epoch 136\n",
            "-----------------------------\n",
            "loss: 2.322124  [    0/27455]\n",
            "gradient mean= -3.098084278008173e-07\n",
            "loss: 2.322099  [ 6400/27455]\n",
            "gradient mean= -1.7901683690979553e-08\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 5.883060705258458e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 3.6050865070968996e-10\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 3.1080913398540133e-09\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 2.462128 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 137\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -1.924895833005369e-11\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 4.439231100772378e-12\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -3.6806939440747755e-11\n",
            "loss: 2.322137  [19200/27455]\n",
            "gradient mean= -2.828824960943166e-07\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= -9.562274305707774e-10\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 2.466986 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322110 \n",
            "\n",
            "Epoch 138\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -7.741925156512508e-11\n",
            "loss: 2.322095  [ 6400/27455]\n",
            "gradient mean= -5.771564115519823e-09\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 7.747682703729275e-13\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -4.031984190966398e-10\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= 6.663020135633246e-11\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 2.465656 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 139\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.8098139306643724e-11\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -2.853808335478991e-11\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -7.761156994856577e-11\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 1.9675108764438676e-11\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= 3.480234767039292e-09\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 2.478513 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322197 \n",
            "\n",
            "Epoch 140\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.217675266174112e-10\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 5.658323809498711e-10\n",
            "loss: 2.322095  [12800/27455]\n",
            "gradient mean= -6.328787716114448e-09\n",
            "loss: 2.322272  [19200/27455]\n",
            "gradient mean= -9.22790590607292e-08\n",
            "loss: 2.322094  [25600/27455]\n",
            "gradient mean= 1.8225998488219375e-09\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 2.499048 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.323737 \n",
            "\n",
            "Epoch 141\n",
            "-----------------------------\n",
            "loss: 2.322139  [    0/27455]\n",
            "gradient mean= -1.846886164003081e-07\n",
            "loss: 2.322334  [ 6400/27455]\n",
            "gradient mean= -1.4409985169550055e-06\n",
            "loss: 2.335871  [12800/27455]\n",
            "gradient mean= -2.8250369723537005e-06\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 1.248910141971038e-10\n",
            "loss: 2.322098  [25600/27455]\n",
            "gradient mean= -5.420933035793496e-09\n",
            "Test Error: \n",
            " Accuracy: 85.2%, Avg loss: 2.471065 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322258 \n",
            "\n",
            "Epoch 142\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -4.259555555496952e-11\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -5.1523264821273784e-11\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 1.0983623038862689e-10\n",
            "loss: 2.322096  [19200/27455]\n",
            "gradient mean= 8.116856520246074e-09\n",
            "loss: 2.322109  [25600/27455]\n",
            "gradient mean= 2.32183285930887e-08\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 2.461747 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322093 \n",
            "\n",
            "Epoch 143\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= 1.9732836198382842e-10\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -4.135603318133896e-11\n",
            "loss: 2.322116  [12800/27455]\n",
            "gradient mean= -4.540745734971097e-08\n",
            "loss: 2.322112  [19200/27455]\n",
            "gradient mean= -9.711581760996069e-09\n",
            "loss: 2.322134  [25600/27455]\n",
            "gradient mean= 1.0791396931608688e-07\n",
            "Test Error: \n",
            " Accuracy: 83.4%, Avg loss: 2.491527 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.323395 \n",
            "\n",
            "Epoch 144\n",
            "-----------------------------\n",
            "loss: 2.322095  [    0/27455]\n",
            "gradient mean= 1.5449497237085552e-09\n",
            "loss: 2.322096  [ 6400/27455]\n",
            "gradient mean= -2.0977005021904915e-08\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -3.6616282228507657e-10\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 1.1224078610982957e-10\n",
            "loss: 2.322190  [25600/27455]\n",
            "gradient mean= -2.553395859195007e-07\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 2.482189 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324767 \n",
            "\n",
            "Epoch 145\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -2.364397046206168e-11\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -4.1485048035694305e-11\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 2.5904867140269516e-10\n",
            "loss: 2.322117  [19200/27455]\n",
            "gradient mean= 2.0139911782734998e-07\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 1.4481659794951529e-11\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 2.479184 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322094 \n",
            "\n",
            "Epoch 146\n",
            "-----------------------------\n",
            "loss: 2.322276  [    0/27455]\n",
            "gradient mean= 5.579728394877748e-07\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -1.718644115911161e-09\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 1.2846157471102515e-09\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= 7.81219793716259e-12\n",
            "loss: 2.322096  [25600/27455]\n",
            "gradient mean= 7.473473395691599e-09\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 2.509968 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327206 \n",
            "\n",
            "Epoch 147\n",
            "-----------------------------\n",
            "loss: 2.322094  [    0/27455]\n",
            "gradient mean= 8.197042156155021e-09\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -8.571034854076842e-11\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= -1.0599624511442585e-09\n",
            "loss: 2.329277  [19200/27455]\n",
            "gradient mean= -2.6957746740663424e-05\n",
            "loss: 2.322109  [25600/27455]\n",
            "gradient mean= -4.8658932882972294e-08\n",
            "Test Error: \n",
            " Accuracy: 83.2%, Avg loss: 2.493203 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.8%, Avg loss: 2.323839 \n",
            "\n",
            "Epoch 148\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -5.4358774426166434e-12\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= 4.489684624076062e-09\n",
            "loss: 2.335106  [12800/27455]\n",
            "gradient mean= -2.531972677388694e-05\n",
            "loss: 2.322158  [19200/27455]\n",
            "gradient mean= 1.5218037674458174e-07\n",
            "loss: 2.322095  [25600/27455]\n",
            "gradient mean= 8.096773029819815e-09\n",
            "Test Error: \n",
            " Accuracy: 83.6%, Avg loss: 2.487134 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.9%, Avg loss: 2.322817 \n",
            "\n",
            "Epoch 149\n",
            "-----------------------------\n",
            "loss: 2.333521  [    0/27455]\n",
            "gradient mean= 2.3652279196539894e-05\n",
            "loss: 2.322114  [ 6400/27455]\n",
            "gradient mean= 4.050485724604869e-09\n",
            "loss: 2.322144  [12800/27455]\n",
            "gradient mean= 6.59484697962398e-08\n",
            "loss: 2.322204  [19200/27455]\n",
            "gradient mean= 7.639061436748307e-07\n",
            "loss: 2.322098  [25600/27455]\n",
            "gradient mean= -6.355031612059747e-09\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 2.464927 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322105 \n",
            "\n",
            "Epoch 150\n",
            "-----------------------------\n",
            "loss: 2.322093  [    0/27455]\n",
            "gradient mean= -1.3401162124448973e-10\n",
            "loss: 2.322093  [ 6400/27455]\n",
            "gradient mean= -1.5777266645922161e-12\n",
            "loss: 2.322093  [12800/27455]\n",
            "gradient mean= 7.696338011342618e-11\n",
            "loss: 2.322093  [19200/27455]\n",
            "gradient mean= -5.325297980363075e-10\n",
            "loss: 2.322093  [25600/27455]\n",
            "gradient mean= 7.98093049980686e-11\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 2.480905 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 100.0%, Avg loss: 2.322221 \n",
            "\n",
            "Done!\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 150\n",
        "optimizer = torch.optim.Adam(simple_model_Adam.parameters(), lr=5e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-----------------------------\")\n",
        "    train_loop(train_dataloader, simple_model_Adam, optimizer, loss_fn)\n",
        "    test_loop(simple_model_Adam, loss_fn, test_losses, train_losses)\n",
        "print(\"Done!\")\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adam algorithm uses a moving average of the gradient and the squared gradient, which are used to scale the learning rate for each weight. This is done to avoid the problem of the learning rate being too high for some weights and too low for others. The moving average of the gradient is used to scale the learning rate for the weights, while the moving average of the squared gradient is used to scale the momentum term. The momentum term is used to help the algorithm escape saddle points and other local minima in the loss function.\n",
        "it seems that the Adam algorithm is converging faster in the beginning, but then it starts to bounce up and down around the minimum.\n",
        "the final result of Adam is a little better than the result of SGD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Drop_NN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer_stack = nn.Sequential(\n",
        "            # nn.Dropout(),\n",
        "            nn.Linear(784, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 200),\n",
        "            nn.BatchNorm1d(200),\n",
        "            nn.Dropout(),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, 150),\n",
        "            nn.BatchNorm1d(150),\n",
        "            nn.Dropout(),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(150, 70),\n",
        "            nn.BatchNorm1d(70),\n",
        "            nn.Dropout(),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(70, 26)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.layer_stack(x)\n",
        "        x = torch.softmax(x, dim=1)\n",
        "        return x\n",
        "Dropout_model_Adam = Drop_NN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-----------------------------\n",
            "loss: 3.257494  [    0/27455]\n",
            "gradient mean= 2.2503883883473463e-05\n",
            "loss: 3.251421  [ 6400/27455]\n",
            "gradient mean= -1.6097237676149234e-05\n",
            "loss: 3.250025  [12800/27455]\n",
            "gradient mean= 1.2473223023334867e-06\n",
            "loss: 3.247589  [19200/27455]\n",
            "gradient mean= -3.686263517010957e-05\n",
            "loss: 3.222624  [25600/27455]\n",
            "gradient mean= 1.385139057674678e-05\n",
            "Test Error: \n",
            " Accuracy: 20.4%, Avg loss: 3.229450 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 20.0%, Avg loss: 3.218341 \n",
            "\n",
            "Epoch 2\n",
            "-----------------------------\n",
            "loss: 3.235989  [    0/27455]\n",
            "gradient mean= 4.543461909634061e-05\n",
            "loss: 3.235053  [ 6400/27455]\n",
            "gradient mean= -4.3778571125585586e-05\n",
            "loss: 3.202783  [12800/27455]\n",
            "gradient mean= -1.283835263166111e-05\n",
            "loss: 3.181334  [19200/27455]\n",
            "gradient mean= -2.5091150746447966e-05\n",
            "loss: 3.149372  [25600/27455]\n",
            "gradient mean= -4.584563794196583e-05\n",
            "Test Error: \n",
            " Accuracy: 24.4%, Avg loss: 3.139234 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 25.2%, Avg loss: 3.135283 \n",
            "\n",
            "Epoch 3\n",
            "-----------------------------\n",
            "loss: 3.133006  [    0/27455]\n",
            "gradient mean= -6.888378266012296e-05\n",
            "loss: 3.169253  [ 6400/27455]\n",
            "gradient mean= -3.2818530598888174e-05\n",
            "loss: 3.169955  [12800/27455]\n",
            "gradient mean= 1.3464170478982851e-05\n",
            "loss: 3.127767  [19200/27455]\n",
            "gradient mean= 4.152268957113847e-05\n",
            "loss: 3.153623  [25600/27455]\n",
            "gradient mean= 7.7196809797897e-06\n",
            "Test Error: \n",
            " Accuracy: 28.2%, Avg loss: 3.087740 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 27.4%, Avg loss: 3.075356 \n",
            "\n",
            "Epoch 4\n",
            "-----------------------------\n",
            "loss: 3.067000  [    0/27455]\n",
            "gradient mean= -5.404106104833772e-06\n",
            "loss: 3.095502  [ 6400/27455]\n",
            "gradient mean= -3.686410855152644e-05\n",
            "loss: 3.086186  [12800/27455]\n",
            "gradient mean= 1.2068187970726285e-05\n",
            "loss: 3.093891  [19200/27455]\n",
            "gradient mean= 4.239112058712635e-06\n",
            "loss: 3.100187  [25600/27455]\n",
            "gradient mean= 3.867143459501676e-05\n",
            "Test Error: \n",
            " Accuracy: 29.7%, Avg loss: 3.050459 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 30.4%, Avg loss: 3.041799 \n",
            "\n",
            "Epoch 5\n",
            "-----------------------------\n",
            "loss: 3.019930  [    0/27455]\n",
            "gradient mean= 9.972780389944091e-06\n",
            "loss: 3.077668  [ 6400/27455]\n",
            "gradient mean= 3.1889208912616596e-05\n",
            "loss: 3.121119  [12800/27455]\n",
            "gradient mean= -5.749931005993858e-05\n",
            "loss: 3.064281  [19200/27455]\n",
            "gradient mean= 1.9820916349999607e-05\n",
            "loss: 3.113067  [25600/27455]\n",
            "gradient mean= -1.9211402104701847e-06\n",
            "Test Error: \n",
            " Accuracy: 29.7%, Avg loss: 3.026878 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 32.2%, Avg loss: 3.025155 \n",
            "\n",
            "Epoch 6\n",
            "-----------------------------\n",
            "loss: 2.967029  [    0/27455]\n",
            "gradient mean= -1.2128034541092347e-05\n",
            "loss: 3.080688  [ 6400/27455]\n",
            "gradient mean= 3.5235418636148097e-06\n",
            "loss: 2.989216  [12800/27455]\n",
            "gradient mean= 6.67837230139412e-05\n",
            "loss: 2.968154  [19200/27455]\n",
            "gradient mean= -2.3348249669652432e-05\n",
            "loss: 3.045012  [25600/27455]\n",
            "gradient mean= 4.7160858230199665e-05\n",
            "Test Error: \n",
            " Accuracy: 30.8%, Avg loss: 3.018909 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 34.1%, Avg loss: 2.996240 \n",
            "\n",
            "Epoch 7\n",
            "-----------------------------\n",
            "loss: 3.061045  [    0/27455]\n",
            "gradient mean= 1.1477883163024671e-05\n",
            "loss: 3.048203  [ 6400/27455]\n",
            "gradient mean= 2.2904525394551456e-05\n",
            "loss: 2.999266  [12800/27455]\n",
            "gradient mean= -5.9094640164403245e-05\n",
            "loss: 2.984134  [19200/27455]\n",
            "gradient mean= -9.239207429345697e-06\n",
            "loss: 3.042122  [25600/27455]\n",
            "gradient mean= -2.8748887416440994e-05\n",
            "Test Error: \n",
            " Accuracy: 34.2%, Avg loss: 2.982254 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 41.4%, Avg loss: 2.925027 \n",
            "\n",
            "Epoch 8\n",
            "-----------------------------\n",
            "loss: 2.912190  [    0/27455]\n",
            "gradient mean= -8.233205153374001e-05\n",
            "loss: 2.966455  [ 6400/27455]\n",
            "gradient mean= 0.00012596377928275615\n",
            "loss: 2.991364  [12800/27455]\n",
            "gradient mean= -6.07550646236632e-06\n",
            "loss: 3.013885  [19200/27455]\n",
            "gradient mean= -6.290020246524364e-05\n",
            "loss: 3.008833  [25600/27455]\n",
            "gradient mean= 5.242251791059971e-05\n",
            "Test Error: \n",
            " Accuracy: 35.3%, Avg loss: 2.969859 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 42.4%, Avg loss: 2.890137 \n",
            "\n",
            "Epoch 9\n",
            "-----------------------------\n",
            "loss: 2.966162  [    0/27455]\n",
            "gradient mean= 5.824058098369278e-05\n",
            "loss: 2.983294  [ 6400/27455]\n",
            "gradient mean= 0.00010558485519140959\n",
            "loss: 2.890404  [12800/27455]\n",
            "gradient mean= -9.100372699322179e-05\n",
            "loss: 2.885628  [19200/27455]\n",
            "gradient mean= 4.870874545304105e-05\n",
            "loss: 2.865142  [25600/27455]\n",
            "gradient mean= -5.9698424593079835e-05\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 2.936149 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 46.5%, Avg loss: 2.851201 \n",
            "\n",
            "Epoch 10\n",
            "-----------------------------\n",
            "loss: 2.852045  [    0/27455]\n",
            "gradient mean= 3.5508739983924897e-06\n",
            "loss: 2.843924  [ 6400/27455]\n",
            "gradient mean= 5.876355498912744e-05\n",
            "loss: 2.896867  [12800/27455]\n",
            "gradient mean= -2.5637171347625554e-05\n",
            "loss: 2.816243  [19200/27455]\n",
            "gradient mean= 1.0834334716491867e-05\n",
            "loss: 2.875169  [25600/27455]\n",
            "gradient mean= 9.099040471483022e-05\n",
            "Test Error: \n",
            " Accuracy: 38.1%, Avg loss: 2.948456 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 47.0%, Avg loss: 2.855183 \n",
            "\n",
            "Epoch 11\n",
            "-----------------------------\n",
            "loss: 2.894096  [    0/27455]\n",
            "gradient mean= 0.00011418444046285003\n",
            "loss: 2.890396  [ 6400/27455]\n",
            "gradient mean= -4.8437828809255734e-05\n",
            "loss: 2.925236  [12800/27455]\n",
            "gradient mean= -8.434027222392615e-06\n",
            "loss: 2.892117  [19200/27455]\n",
            "gradient mean= 5.8130284742219374e-05\n",
            "loss: 2.877580  [25600/27455]\n",
            "gradient mean= 5.8789282775251195e-05\n",
            "Test Error: \n",
            " Accuracy: 41.2%, Avg loss: 2.911065 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 51.4%, Avg loss: 2.799822 \n",
            "\n",
            "Epoch 12\n",
            "-----------------------------\n",
            "loss: 2.892894  [    0/27455]\n",
            "gradient mean= -7.85012889537029e-05\n",
            "loss: 2.841179  [ 6400/27455]\n",
            "gradient mean= 3.4162621886935085e-06\n",
            "loss: 2.892488  [12800/27455]\n",
            "gradient mean= 5.517221870832145e-05\n",
            "loss: 2.908716  [19200/27455]\n",
            "gradient mean= 3.987002492067404e-05\n",
            "loss: 2.776320  [25600/27455]\n",
            "gradient mean= 2.173551001760643e-05\n",
            "Test Error: \n",
            " Accuracy: 40.2%, Avg loss: 2.925992 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 53.5%, Avg loss: 2.787348 \n",
            "\n",
            "Epoch 13\n",
            "-----------------------------\n",
            "loss: 2.865081  [    0/27455]\n",
            "gradient mean= -9.366044650960248e-06\n",
            "loss: 2.734224  [ 6400/27455]\n",
            "gradient mean= 1.9888826500391588e-05\n",
            "loss: 2.892112  [12800/27455]\n",
            "gradient mean= 4.030454147141427e-05\n",
            "loss: 2.811498  [19200/27455]\n",
            "gradient mean= 6.70970039209351e-05\n",
            "loss: 2.788374  [25600/27455]\n",
            "gradient mean= -5.124908420839347e-05\n",
            "Test Error: \n",
            " Accuracy: 45.6%, Avg loss: 2.877733 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 57.0%, Avg loss: 2.756457 \n",
            "\n",
            "Epoch 14\n",
            "-----------------------------\n",
            "loss: 2.754911  [    0/27455]\n",
            "gradient mean= 3.7346100725699216e-05\n",
            "loss: 2.903112  [ 6400/27455]\n",
            "gradient mean= 0.0002302218199474737\n",
            "loss: 2.759245  [12800/27455]\n",
            "gradient mean= 3.634186896306346e-06\n",
            "loss: 2.763924  [19200/27455]\n",
            "gradient mean= 6.988888344494626e-05\n",
            "loss: 2.832509  [25600/27455]\n",
            "gradient mean= 1.1102013559138868e-05\n",
            "Test Error: \n",
            " Accuracy: 50.4%, Avg loss: 2.851529 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 60.6%, Avg loss: 2.726537 \n",
            "\n",
            "Epoch 15\n",
            "-----------------------------\n",
            "loss: 2.805850  [    0/27455]\n",
            "gradient mean= -4.129259104956873e-05\n",
            "loss: 2.819766  [ 6400/27455]\n",
            "gradient mean= -2.7455787858343683e-05\n",
            "loss: 2.814756  [12800/27455]\n",
            "gradient mean= 5.012787369196303e-05\n",
            "loss: 2.776994  [19200/27455]\n",
            "gradient mean= -4.189311948721297e-05\n",
            "loss: 2.691613  [25600/27455]\n",
            "gradient mean= 0.00015944770711939782\n",
            "Test Error: \n",
            " Accuracy: 50.2%, Avg loss: 2.832937 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 63.5%, Avg loss: 2.697603 \n",
            "\n",
            "Epoch 16\n",
            "-----------------------------\n",
            "loss: 2.746993  [    0/27455]\n",
            "gradient mean= -8.198799332603812e-05\n",
            "loss: 2.753222  [ 6400/27455]\n",
            "gradient mean= 0.00010958078928524628\n",
            "loss: 2.805381  [12800/27455]\n",
            "gradient mean= -3.258609285694547e-05\n",
            "loss: 2.876584  [19200/27455]\n",
            "gradient mean= 0.0001413197023794055\n",
            "loss: 2.747964  [25600/27455]\n",
            "gradient mean= 3.585634840419516e-05\n",
            "Test Error: \n",
            " Accuracy: 52.7%, Avg loss: 2.800841 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 65.3%, Avg loss: 2.673104 \n",
            "\n",
            "Epoch 17\n",
            "-----------------------------\n",
            "loss: 2.766110  [    0/27455]\n",
            "gradient mean= -1.8408942196401767e-05\n",
            "loss: 2.797824  [ 6400/27455]\n",
            "gradient mean= -0.00020429491996765137\n",
            "loss: 2.692098  [12800/27455]\n",
            "gradient mean= 7.392549014184624e-05\n",
            "loss: 2.717977  [19200/27455]\n",
            "gradient mean= 7.52221531001851e-05\n",
            "loss: 2.877528  [25600/27455]\n",
            "gradient mean= -0.00018715430633164942\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 2.808768 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 65.1%, Avg loss: 2.674594 \n",
            "\n",
            "Epoch 18\n",
            "-----------------------------\n",
            "loss: 2.717803  [    0/27455]\n",
            "gradient mean= -8.72602904564701e-05\n",
            "loss: 2.656025  [ 6400/27455]\n",
            "gradient mean= -0.00012726949353236705\n",
            "loss: 2.664830  [12800/27455]\n",
            "gradient mean= -0.00011969752085860819\n",
            "loss: 2.724155  [19200/27455]\n",
            "gradient mean= -4.9638965720077977e-05\n",
            "loss: 2.687588  [25600/27455]\n",
            "gradient mean= 0.0001383888884447515\n",
            "Test Error: \n",
            " Accuracy: 52.6%, Avg loss: 2.798949 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 66.8%, Avg loss: 2.652987 \n",
            "\n",
            "Epoch 19\n",
            "-----------------------------\n",
            "loss: 2.639123  [    0/27455]\n",
            "gradient mean= -3.718699372257106e-05\n",
            "loss: 2.809815  [ 6400/27455]\n",
            "gradient mean= -6.776089867344126e-05\n",
            "loss: 2.703544  [12800/27455]\n",
            "gradient mean= -0.00013154120824765414\n",
            "loss: 2.661710  [19200/27455]\n",
            "gradient mean= 1.2149554095230997e-05\n",
            "loss: 2.744639  [25600/27455]\n",
            "gradient mean= -6.718182703480124e-05\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 2.806265 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 66.9%, Avg loss: 2.647386 \n",
            "\n",
            "Epoch 20\n",
            "-----------------------------\n",
            "loss: 2.634587  [    0/27455]\n",
            "gradient mean= -0.00012107739166822284\n",
            "loss: 2.611243  [ 6400/27455]\n",
            "gradient mean= -1.6378618965973146e-05\n",
            "loss: 2.625127  [12800/27455]\n",
            "gradient mean= 7.49218015698716e-05\n",
            "loss: 2.777447  [19200/27455]\n",
            "gradient mean= 8.136397082125768e-05\n",
            "loss: 2.787760  [25600/27455]\n",
            "gradient mean= 5.5720534874126315e-05\n",
            "Test Error: \n",
            " Accuracy: 53.5%, Avg loss: 2.789034 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 69.0%, Avg loss: 2.629567 \n",
            "\n",
            "Epoch 21\n",
            "-----------------------------\n",
            "loss: 2.704746  [    0/27455]\n",
            "gradient mean= -3.366276723681949e-05\n",
            "loss: 2.776984  [ 6400/27455]\n",
            "gradient mean= 0.00016067660180851817\n",
            "loss: 2.666768  [12800/27455]\n",
            "gradient mean= 0.00010701001156121492\n",
            "loss: 2.774369  [19200/27455]\n",
            "gradient mean= 3.367963290656917e-05\n",
            "loss: 2.669424  [25600/27455]\n",
            "gradient mean= -1.4940039363864344e-05\n",
            "Test Error: \n",
            " Accuracy: 53.8%, Avg loss: 2.785682 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 69.7%, Avg loss: 2.622701 \n",
            "\n",
            "Epoch 22\n",
            "-----------------------------\n",
            "loss: 2.680384  [    0/27455]\n",
            "gradient mean= 0.00016860161849763244\n",
            "loss: 2.653613  [ 6400/27455]\n",
            "gradient mean= 5.658507870975882e-05\n",
            "loss: 2.735928  [12800/27455]\n",
            "gradient mean= 6.399164703907445e-06\n",
            "loss: 2.593649  [19200/27455]\n",
            "gradient mean= -0.0001374610874336213\n",
            "loss: 2.729332  [25600/27455]\n",
            "gradient mean= -0.00010507344995858148\n",
            "Test Error: \n",
            " Accuracy: 55.1%, Avg loss: 2.777932 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 72.2%, Avg loss: 2.608905 \n",
            "\n",
            "Epoch 23\n",
            "-----------------------------\n",
            "loss: 2.661240  [    0/27455]\n",
            "gradient mean= -7.198313141998369e-06\n",
            "loss: 2.676735  [ 6400/27455]\n",
            "gradient mean= -7.026708772173151e-05\n",
            "loss: 2.659487  [12800/27455]\n",
            "gradient mean= 9.402730938745663e-05\n",
            "loss: 2.682390  [19200/27455]\n",
            "gradient mean= -1.05510271168896e-05\n",
            "loss: 2.671635  [25600/27455]\n",
            "gradient mean= 0.0001283965539187193\n",
            "Test Error: \n",
            " Accuracy: 55.3%, Avg loss: 2.772442 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 73.7%, Avg loss: 2.591830 \n",
            "\n",
            "Epoch 24\n",
            "-----------------------------\n",
            "loss: 2.660650  [    0/27455]\n",
            "gradient mean= 2.0511186448857188e-05\n",
            "loss: 2.641376  [ 6400/27455]\n",
            "gradient mean= -3.0267850888776593e-05\n",
            "loss: 2.741956  [12800/27455]\n",
            "gradient mean= -1.298327788390452e-05\n",
            "loss: 2.574300  [19200/27455]\n",
            "gradient mean= -6.338843377307057e-05\n",
            "loss: 2.690009  [25600/27455]\n",
            "gradient mean= -6.446847692131996e-05\n",
            "Test Error: \n",
            " Accuracy: 55.4%, Avg loss: 2.767505 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 74.5%, Avg loss: 2.579120 \n",
            "\n",
            "Epoch 25\n",
            "-----------------------------\n",
            "loss: 2.641243  [    0/27455]\n",
            "gradient mean= 5.042680277256295e-05\n",
            "loss: 2.678800  [ 6400/27455]\n",
            "gradient mean= -2.1795925931655802e-05\n",
            "loss: 2.725331  [12800/27455]\n",
            "gradient mean= -1.1224589798075613e-05\n",
            "loss: 2.577669  [19200/27455]\n",
            "gradient mean= 2.1602407684895297e-07\n",
            "loss: 2.646827  [25600/27455]\n",
            "gradient mean= -0.00014672253746539354\n",
            "Test Error: \n",
            " Accuracy: 55.4%, Avg loss: 2.774947 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 76.6%, Avg loss: 2.573800 \n",
            "\n",
            "Epoch 26\n",
            "-----------------------------\n",
            "loss: 2.660794  [    0/27455]\n",
            "gradient mean= -0.0001354759733658284\n",
            "loss: 2.543402  [ 6400/27455]\n",
            "gradient mean= 1.76380890479777e-05\n",
            "loss: 2.539936  [12800/27455]\n",
            "gradient mean= -2.8851962269982323e-05\n",
            "loss: 2.554721  [19200/27455]\n",
            "gradient mean= 5.04321133121266e-06\n",
            "loss: 2.662786  [25600/27455]\n",
            "gradient mean= 0.00014262614422477782\n",
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 2.730726 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 81.4%, Avg loss: 2.523504 \n",
            "\n",
            "Epoch 27\n",
            "-----------------------------\n",
            "loss: 2.632386  [    0/27455]\n",
            "gradient mean= 2.7738891731132753e-05\n",
            "loss: 2.596055  [ 6400/27455]\n",
            "gradient mean= -2.861011125787627e-05\n",
            "loss: 2.670020  [12800/27455]\n",
            "gradient mean= -1.946390693774447e-05\n",
            "loss: 2.648454  [19200/27455]\n",
            "gradient mean= -9.509371739113703e-05\n",
            "loss: 2.665852  [25600/27455]\n",
            "gradient mean= 0.00012452044757083058\n",
            "Test Error: \n",
            " Accuracy: 60.2%, Avg loss: 2.731389 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 81.3%, Avg loss: 2.519972 \n",
            "\n",
            "Epoch 28\n",
            "-----------------------------\n",
            "loss: 2.547795  [    0/27455]\n",
            "gradient mean= -3.721491520991549e-05\n",
            "loss: 2.577206  [ 6400/27455]\n",
            "gradient mean= -8.456231444142759e-05\n",
            "loss: 2.572218  [12800/27455]\n",
            "gradient mean= -0.00013575947377830744\n",
            "loss: 2.537386  [19200/27455]\n",
            "gradient mean= -7.323471072595567e-05\n",
            "loss: 2.599006  [25600/27455]\n",
            "gradient mean= 3.06991751131136e-05\n",
            "Test Error: \n",
            " Accuracy: 61.9%, Avg loss: 2.709992 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 82.7%, Avg loss: 2.501007 \n",
            "\n",
            "Epoch 29\n",
            "-----------------------------\n",
            "loss: 2.574692  [    0/27455]\n",
            "gradient mean= -0.00016476046585012227\n",
            "loss: 2.609343  [ 6400/27455]\n",
            "gradient mean= -0.00015149264072533697\n",
            "loss: 2.534190  [12800/27455]\n",
            "gradient mean= 6.289148586802185e-05\n",
            "loss: 2.617859  [19200/27455]\n",
            "gradient mean= 6.385375309037045e-05\n",
            "loss: 2.548286  [25600/27455]\n",
            "gradient mean= -7.408185774693266e-05\n",
            "Test Error: \n",
            " Accuracy: 57.8%, Avg loss: 2.750822 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 80.7%, Avg loss: 2.524856 \n",
            "\n",
            "Epoch 30\n",
            "-----------------------------\n",
            "loss: 2.682166  [    0/27455]\n",
            "gradient mean= -6.971635593799874e-05\n",
            "loss: 2.588603  [ 6400/27455]\n",
            "gradient mean= 0.00019398245785851032\n",
            "loss: 2.610118  [12800/27455]\n",
            "gradient mean= 7.40428949939087e-05\n",
            "loss: 2.508968  [19200/27455]\n",
            "gradient mean= 3.153447323711589e-05\n",
            "loss: 2.580335  [25600/27455]\n",
            "gradient mean= -0.00010036996536655352\n",
            "Test Error: \n",
            " Accuracy: 60.3%, Avg loss: 2.723002 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 82.8%, Avg loss: 2.497767 \n",
            "\n",
            "Epoch 31\n",
            "-----------------------------\n",
            "loss: 2.581145  [    0/27455]\n",
            "gradient mean= -7.486790855182335e-05\n",
            "loss: 2.612042  [ 6400/27455]\n",
            "gradient mean= 9.172260615741834e-05\n",
            "loss: 2.501746  [12800/27455]\n",
            "gradient mean= 0.00025175069458782673\n",
            "loss: 2.577329  [19200/27455]\n",
            "gradient mean= 5.100169437355362e-05\n",
            "loss: 2.570535  [25600/27455]\n",
            "gradient mean= -0.00011385915422579274\n",
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 2.714112 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 83.2%, Avg loss: 2.489343 \n",
            "\n",
            "Epoch 32\n",
            "-----------------------------\n",
            "loss: 2.589495  [    0/27455]\n",
            "gradient mean= -0.00022398728469852358\n",
            "loss: 2.607383  [ 6400/27455]\n",
            "gradient mean= 0.0002966428000945598\n",
            "loss: 2.587460  [12800/27455]\n",
            "gradient mean= -3.2936513889580965e-05\n",
            "loss: 2.610049  [19200/27455]\n",
            "gradient mean= -0.0001274313690373674\n",
            "loss: 2.576030  [25600/27455]\n",
            "gradient mean= -0.00010718870180426165\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 2.714723 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 82.9%, Avg loss: 2.496832 \n",
            "\n",
            "Epoch 33\n",
            "-----------------------------\n",
            "loss: 2.469889  [    0/27455]\n",
            "gradient mean= 0.0002909089089371264\n",
            "loss: 2.557053  [ 6400/27455]\n",
            "gradient mean= -0.000121867167763412\n",
            "loss: 2.495460  [12800/27455]\n",
            "gradient mean= -1.1456742868176661e-05\n",
            "loss: 2.559249  [19200/27455]\n",
            "gradient mean= -1.5645468010916375e-05\n",
            "loss: 2.634587  [25600/27455]\n",
            "gradient mean= -0.00016598986985627562\n",
            "Test Error: \n",
            " Accuracy: 62.7%, Avg loss: 2.694274 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 84.1%, Avg loss: 2.486031 \n",
            "\n",
            "Epoch 34\n",
            "-----------------------------\n",
            "loss: 2.567046  [    0/27455]\n",
            "gradient mean= -0.00018550269305706024\n",
            "loss: 2.582515  [ 6400/27455]\n",
            "gradient mean= 4.1864717786666006e-05\n",
            "loss: 2.499095  [12800/27455]\n",
            "gradient mean= -0.000210336220334284\n",
            "loss: 2.517165  [19200/27455]\n",
            "gradient mean= 0.0001323035394307226\n",
            "loss: 2.594747  [25600/27455]\n",
            "gradient mean= 0.00017299334285780787\n",
            "Test Error: \n",
            " Accuracy: 62.0%, Avg loss: 2.706105 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 84.9%, Avg loss: 2.479911 \n",
            "\n",
            "Epoch 35\n",
            "-----------------------------\n",
            "loss: 2.565674  [    0/27455]\n",
            "gradient mean= -0.00019933872681576759\n",
            "loss: 2.559429  [ 6400/27455]\n",
            "gradient mean= 5.143594989931444e-06\n",
            "loss: 2.529001  [12800/27455]\n",
            "gradient mean= -5.61334854864981e-05\n",
            "loss: 2.551204  [19200/27455]\n",
            "gradient mean= 0.00032749646925367415\n",
            "loss: 2.617092  [25600/27455]\n",
            "gradient mean= 0.0003716405190061778\n",
            "Test Error: \n",
            " Accuracy: 57.6%, Avg loss: 2.753840 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 83.6%, Avg loss: 2.492692 \n",
            "\n",
            "Epoch 36\n",
            "-----------------------------\n",
            "loss: 2.496239  [    0/27455]\n",
            "gradient mean= -3.408891643630341e-05\n",
            "loss: 2.553461  [ 6400/27455]\n",
            "gradient mean= -2.816480991896242e-05\n",
            "loss: 2.558020  [12800/27455]\n",
            "gradient mean= 8.153820090228692e-05\n",
            "loss: 2.506980  [19200/27455]\n",
            "gradient mean= -3.2463496609125286e-05\n",
            "loss: 2.508657  [25600/27455]\n",
            "gradient mean= -8.495241490891203e-05\n",
            "Test Error: \n",
            " Accuracy: 63.8%, Avg loss: 2.690752 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 86.2%, Avg loss: 2.462405 \n",
            "\n",
            "Epoch 37\n",
            "-----------------------------\n",
            "loss: 2.503089  [    0/27455]\n",
            "gradient mean= -0.00026950277970172465\n",
            "loss: 2.539712  [ 6400/27455]\n",
            "gradient mean= -0.00014830543659627438\n",
            "loss: 2.632153  [12800/27455]\n",
            "gradient mean= -0.00018932868260890245\n",
            "loss: 2.538454  [19200/27455]\n",
            "gradient mean= 8.23268637759611e-05\n",
            "loss: 2.461248  [25600/27455]\n",
            "gradient mean= 0.0001331112434854731\n",
            "Test Error: \n",
            " Accuracy: 66.6%, Avg loss: 2.661625 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 88.6%, Avg loss: 2.439130 \n",
            "\n",
            "Epoch 38\n",
            "-----------------------------\n",
            "loss: 2.476755  [    0/27455]\n",
            "gradient mean= -4.974881812813692e-05\n",
            "loss: 2.452739  [ 6400/27455]\n",
            "gradient mean= 2.653253250173293e-05\n",
            "loss: 2.518614  [12800/27455]\n",
            "gradient mean= 9.193864570988808e-06\n",
            "loss: 2.513667  [19200/27455]\n",
            "gradient mean= 5.970056736259721e-05\n",
            "loss: 2.466383  [25600/27455]\n",
            "gradient mean= 0.00019805760530289263\n",
            "Test Error: \n",
            " Accuracy: 62.5%, Avg loss: 2.700716 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 87.3%, Avg loss: 2.452543 \n",
            "\n",
            "Epoch 39\n",
            "-----------------------------\n",
            "loss: 2.607013  [    0/27455]\n",
            "gradient mean= -0.00015198618348222226\n",
            "loss: 2.487139  [ 6400/27455]\n",
            "gradient mean= -0.00025659200036898255\n",
            "loss: 2.458350  [12800/27455]\n",
            "gradient mean= 4.7397377784363925e-05\n",
            "loss: 2.427743  [19200/27455]\n",
            "gradient mean= 5.808275818708353e-05\n",
            "loss: 2.477089  [25600/27455]\n",
            "gradient mean= -8.385774708585814e-05\n",
            "Test Error: \n",
            " Accuracy: 66.7%, Avg loss: 2.657657 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 89.9%, Avg loss: 2.425681 \n",
            "\n",
            "Epoch 40\n",
            "-----------------------------\n",
            "loss: 2.507259  [    0/27455]\n",
            "gradient mean= 5.2216724725440145e-05\n",
            "loss: 2.446692  [ 6400/27455]\n",
            "gradient mean= -3.917260983143933e-05\n",
            "loss: 2.446774  [12800/27455]\n",
            "gradient mean= 1.0206551451119594e-05\n",
            "loss: 2.528141  [19200/27455]\n",
            "gradient mean= -6.33754680166021e-05\n",
            "loss: 2.553192  [25600/27455]\n",
            "gradient mean= 0.00013330054935067892\n",
            "Test Error: \n",
            " Accuracy: 65.1%, Avg loss: 2.678539 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 88.0%, Avg loss: 2.443949 \n",
            "\n",
            "Epoch 41\n",
            "-----------------------------\n",
            "loss: 2.527838  [    0/27455]\n",
            "gradient mean= 2.1304267647792585e-05\n",
            "loss: 2.439408  [ 6400/27455]\n",
            "gradient mean= 6.299916276475415e-05\n",
            "loss: 2.520030  [12800/27455]\n",
            "gradient mean= -6.604418740607798e-05\n",
            "loss: 2.538286  [19200/27455]\n",
            "gradient mean= 0.0005640912568196654\n",
            "loss: 2.512624  [25600/27455]\n",
            "gradient mean= 5.685622454620898e-05\n",
            "Test Error: \n",
            " Accuracy: 67.1%, Avg loss: 2.658492 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 90.3%, Avg loss: 2.418842 \n",
            "\n",
            "Epoch 42\n",
            "-----------------------------\n",
            "loss: 2.472309  [    0/27455]\n",
            "gradient mean= -3.081631439272314e-05\n",
            "loss: 2.538632  [ 6400/27455]\n",
            "gradient mean= -0.00013276070239953697\n",
            "loss: 2.490513  [12800/27455]\n",
            "gradient mean= -2.8227650545886718e-05\n",
            "loss: 2.434366  [19200/27455]\n",
            "gradient mean= -0.00011893439659615979\n",
            "loss: 2.513579  [25600/27455]\n",
            "gradient mean= -2.412880894553382e-05\n",
            "Test Error: \n",
            " Accuracy: 65.0%, Avg loss: 2.686876 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 89.9%, Avg loss: 2.426513 \n",
            "\n",
            "Epoch 43\n",
            "-----------------------------\n",
            "loss: 2.531440  [    0/27455]\n",
            "gradient mean= -0.00017216228297911584\n",
            "loss: 2.489028  [ 6400/27455]\n",
            "gradient mean= 0.0001109806471504271\n",
            "loss: 2.508267  [12800/27455]\n",
            "gradient mean= 0.00013508943084161729\n",
            "loss: 2.511388  [19200/27455]\n",
            "gradient mean= 9.506142669124529e-05\n",
            "loss: 2.416549  [25600/27455]\n",
            "gradient mean= -0.00010990270675392821\n",
            "Test Error: \n",
            " Accuracy: 61.3%, Avg loss: 2.707304 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 89.8%, Avg loss: 2.427452 \n",
            "\n",
            "Epoch 44\n",
            "-----------------------------\n",
            "loss: 2.485204  [    0/27455]\n",
            "gradient mean= 0.0001255847600987181\n",
            "loss: 2.438937  [ 6400/27455]\n",
            "gradient mean= -5.110841084388085e-05\n",
            "loss: 2.466532  [12800/27455]\n",
            "gradient mean= 0.0003210839058738202\n",
            "loss: 2.522821  [19200/27455]\n",
            "gradient mean= -6.929400842636824e-05\n",
            "loss: 2.445117  [25600/27455]\n",
            "gradient mean= -0.000586369656957686\n",
            "Test Error: \n",
            " Accuracy: 68.4%, Avg loss: 2.642691 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 92.8%, Avg loss: 2.396020 \n",
            "\n",
            "Epoch 45\n",
            "-----------------------------\n",
            "loss: 2.595600  [    0/27455]\n",
            "gradient mean= 0.00010288434714311734\n",
            "loss: 2.517547  [ 6400/27455]\n",
            "gradient mean= -5.7182463933713734e-05\n",
            "loss: 2.468817  [12800/27455]\n",
            "gradient mean= -5.268463155516656e-06\n",
            "loss: 2.559502  [19200/27455]\n",
            "gradient mean= -8.47508417791687e-05\n",
            "loss: 2.397088  [25600/27455]\n",
            "gradient mean= -1.891488500405103e-05\n",
            "Test Error: \n",
            " Accuracy: 68.5%, Avg loss: 2.641607 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 93.4%, Avg loss: 2.391403 \n",
            "\n",
            "Epoch 46\n",
            "-----------------------------\n",
            "loss: 2.479968  [    0/27455]\n",
            "gradient mean= 0.0001557216892251745\n",
            "loss: 2.489241  [ 6400/27455]\n",
            "gradient mean= 0.00021764311532024294\n",
            "loss: 2.496322  [12800/27455]\n",
            "gradient mean= -2.7016736567020416e-05\n",
            "loss: 2.479122  [19200/27455]\n",
            "gradient mean= 0.00024177278100978583\n",
            "loss: 2.461257  [25600/27455]\n",
            "gradient mean= 0.0005848126020282507\n",
            "Test Error: \n",
            " Accuracy: 64.6%, Avg loss: 2.684632 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 93.6%, Avg loss: 2.390319 \n",
            "\n",
            "Epoch 47\n",
            "-----------------------------\n",
            "loss: 2.480161  [    0/27455]\n",
            "gradient mean= -1.736499325488694e-05\n",
            "loss: 2.449262  [ 6400/27455]\n",
            "gradient mean= 0.00013353834219742566\n",
            "loss: 2.491627  [12800/27455]\n",
            "gradient mean= 0.00011303334758849815\n",
            "loss: 2.503262  [19200/27455]\n",
            "gradient mean= -0.00011972417996730655\n",
            "loss: 2.476550  [25600/27455]\n",
            "gradient mean= 1.646269447519444e-05\n",
            "Test Error: \n",
            " Accuracy: 69.5%, Avg loss: 2.631701 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.9%, Avg loss: 2.374482 \n",
            "\n",
            "Epoch 48\n",
            "-----------------------------\n",
            "loss: 2.456810  [    0/27455]\n",
            "gradient mean= 9.848627814790234e-05\n",
            "loss: 2.435042  [ 6400/27455]\n",
            "gradient mean= -9.695288463262841e-05\n",
            "loss: 2.457709  [12800/27455]\n",
            "gradient mean= -0.0002431153698125854\n",
            "loss: 2.440330  [19200/27455]\n",
            "gradient mean= -8.204123878385872e-05\n",
            "loss: 2.439891  [25600/27455]\n",
            "gradient mean= 6.884193135192618e-05\n",
            "Test Error: \n",
            " Accuracy: 66.0%, Avg loss: 2.666238 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.9%, Avg loss: 2.373081 \n",
            "\n",
            "Epoch 49\n",
            "-----------------------------\n",
            "loss: 2.437802  [    0/27455]\n",
            "gradient mean= 0.0001291288062930107\n",
            "loss: 2.522872  [ 6400/27455]\n",
            "gradient mean= -0.00013609611778520048\n",
            "loss: 2.507243  [12800/27455]\n",
            "gradient mean= -0.00018975847342517227\n",
            "loss: 2.466799  [19200/27455]\n",
            "gradient mean= 6.800923438277096e-05\n",
            "loss: 2.426227  [25600/27455]\n",
            "gradient mean= 3.3826967410277575e-05\n",
            "Test Error: \n",
            " Accuracy: 67.5%, Avg loss: 2.651188 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.6%, Avg loss: 2.376890 \n",
            "\n",
            "Epoch 50\n",
            "-----------------------------\n",
            "loss: 2.496062  [    0/27455]\n",
            "gradient mean= 0.0002456584479659796\n",
            "loss: 2.462902  [ 6400/27455]\n",
            "gradient mean= -0.0003086939686909318\n",
            "loss: 2.449380  [12800/27455]\n",
            "gradient mean= 9.603128273738548e-05\n",
            "loss: 2.429451  [19200/27455]\n",
            "gradient mean= -0.00011204396287212148\n",
            "loss: 2.415529  [25600/27455]\n",
            "gradient mean= 7.332652603508905e-05\n",
            "Test Error: \n",
            " Accuracy: 70.3%, Avg loss: 2.626489 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 95.3%, Avg loss: 2.368264 \n",
            "\n",
            "Epoch 51\n",
            "-----------------------------\n",
            "loss: 2.449359  [    0/27455]\n",
            "gradient mean= -7.505587564082816e-05\n",
            "loss: 2.462763  [ 6400/27455]\n",
            "gradient mean= 6.609466800000519e-05\n",
            "loss: 2.470623  [12800/27455]\n",
            "gradient mean= -4.808088306162972e-06\n",
            "loss: 2.405361  [19200/27455]\n",
            "gradient mean= -4.191825064481236e-05\n",
            "loss: 2.429328  [25600/27455]\n",
            "gradient mean= -3.8753514672862366e-05\n",
            "Test Error: \n",
            " Accuracy: 66.0%, Avg loss: 2.660486 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 94.4%, Avg loss: 2.379257 \n",
            "\n",
            "Epoch 52\n",
            "-----------------------------\n",
            "loss: 2.454315  [    0/27455]\n",
            "gradient mean= -0.00011452780017862096\n",
            "loss: 2.417953  [ 6400/27455]\n",
            "gradient mean= 0.00016918499022722244\n",
            "loss: 2.455967  [12800/27455]\n",
            "gradient mean= -3.522177576087415e-05\n",
            "loss: 2.459219  [19200/27455]\n",
            "gradient mean= 0.00015815292135812342\n",
            "loss: 2.462524  [25600/27455]\n",
            "gradient mean= -8.388547576032579e-05\n",
            "Test Error: \n",
            " Accuracy: 66.6%, Avg loss: 2.655330 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 95.2%, Avg loss: 2.371621 \n",
            "\n",
            "Epoch 53\n",
            "-----------------------------\n",
            "loss: 2.473112  [    0/27455]\n",
            "gradient mean= 0.00016182611580006778\n",
            "loss: 2.417768  [ 6400/27455]\n",
            "gradient mean= -9.26875236473279e-06\n",
            "loss: 2.470381  [12800/27455]\n",
            "gradient mean= 5.660190072376281e-05\n",
            "loss: 2.405447  [19200/27455]\n",
            "gradient mean= 3.381905844435096e-05\n",
            "loss: 2.386737  [25600/27455]\n",
            "gradient mean= -0.00014683361223433167\n",
            "Test Error: \n",
            " Accuracy: 68.0%, Avg loss: 2.638465 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 95.6%, Avg loss: 2.364808 \n",
            "\n",
            "Epoch 54\n",
            "-----------------------------\n",
            "loss: 2.441743  [    0/27455]\n",
            "gradient mean= 0.0002249814715469256\n",
            "loss: 2.413099  [ 6400/27455]\n",
            "gradient mean= 2.2993928723735735e-05\n",
            "loss: 2.447498  [12800/27455]\n",
            "gradient mean= -3.9939095586305484e-05\n",
            "loss: 2.543036  [19200/27455]\n",
            "gradient mean= -3.646592449513264e-05\n",
            "loss: 2.424900  [25600/27455]\n",
            "gradient mean= 0.00032498451764695346\n",
            "Test Error: \n",
            " Accuracy: 70.4%, Avg loss: 2.619355 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 97.3%, Avg loss: 2.351515 \n",
            "\n",
            "Epoch 55\n",
            "-----------------------------\n",
            "loss: 2.436302  [    0/27455]\n",
            "gradient mean= -1.3739417227043305e-05\n",
            "loss: 2.435581  [ 6400/27455]\n",
            "gradient mean= -0.00011012679169652984\n",
            "loss: 2.382481  [12800/27455]\n",
            "gradient mean= 0.00019782071467489004\n",
            "loss: 2.429799  [19200/27455]\n",
            "gradient mean= -0.0001407302770530805\n",
            "loss: 2.410032  [25600/27455]\n",
            "gradient mean= 8.446777064818889e-05\n",
            "Test Error: \n",
            " Accuracy: 70.5%, Avg loss: 2.624942 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.0%, Avg loss: 2.345920 \n",
            "\n",
            "Epoch 56\n",
            "-----------------------------\n",
            "loss: 2.448885  [    0/27455]\n",
            "gradient mean= 3.3384636481059715e-05\n",
            "loss: 2.434996  [ 6400/27455]\n",
            "gradient mean= 0.00011871676542796195\n",
            "loss: 2.437013  [12800/27455]\n",
            "gradient mean= 0.00013937850599177182\n",
            "loss: 2.393987  [19200/27455]\n",
            "gradient mean= 9.54322240431793e-05\n",
            "loss: 2.406138  [25600/27455]\n",
            "gradient mean= 0.0001924889365909621\n",
            "Test Error: \n",
            " Accuracy: 70.0%, Avg loss: 2.626844 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 96.9%, Avg loss: 2.354900 \n",
            "\n",
            "Epoch 57\n",
            "-----------------------------\n",
            "loss: 2.396452  [    0/27455]\n",
            "gradient mean= 0.0003936738066840917\n",
            "loss: 2.432328  [ 6400/27455]\n",
            "gradient mean= 5.519260230357759e-05\n",
            "loss: 2.389862  [12800/27455]\n",
            "gradient mean= -0.00012206680548842996\n",
            "loss: 2.417042  [19200/27455]\n",
            "gradient mean= 0.00012279808288440108\n",
            "loss: 2.448250  [25600/27455]\n",
            "gradient mean= -1.2300186426728033e-05\n",
            "Test Error: \n",
            " Accuracy: 68.6%, Avg loss: 2.641489 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 97.6%, Avg loss: 2.349477 \n",
            "\n",
            "Epoch 58\n",
            "-----------------------------\n",
            "loss: 2.407837  [    0/27455]\n",
            "gradient mean= -0.00036064672167412937\n",
            "loss: 2.406090  [ 6400/27455]\n",
            "gradient mean= 0.0001285767648369074\n",
            "loss: 2.446224  [12800/27455]\n",
            "gradient mean= -0.00013884152576792985\n",
            "loss: 2.432030  [19200/27455]\n",
            "gradient mean= -0.00016442048945464194\n",
            "loss: 2.349950  [25600/27455]\n",
            "gradient mean= -4.166147482465021e-05\n",
            "Test Error: \n",
            " Accuracy: 72.8%, Avg loss: 2.602504 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.8%, Avg loss: 2.336803 \n",
            "\n",
            "Epoch 59\n",
            "-----------------------------\n",
            "loss: 2.427395  [    0/27455]\n",
            "gradient mean= -0.0004455583402886987\n",
            "loss: 2.374737  [ 6400/27455]\n",
            "gradient mean= -0.00015196160529740155\n",
            "loss: 2.448044  [12800/27455]\n",
            "gradient mean= 2.8846927307313308e-05\n",
            "loss: 2.416109  [19200/27455]\n",
            "gradient mean= -3.769242175621912e-05\n",
            "loss: 2.419151  [25600/27455]\n",
            "gradient mean= 0.00038141640834510326\n",
            "Test Error: \n",
            " Accuracy: 71.0%, Avg loss: 2.617607 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.7%, Avg loss: 2.337119 \n",
            "\n",
            "Epoch 60\n",
            "-----------------------------\n",
            "loss: 2.400878  [    0/27455]\n",
            "gradient mean= 1.707022420305293e-05\n",
            "loss: 2.423045  [ 6400/27455]\n",
            "gradient mean= -6.852068327134475e-05\n",
            "loss: 2.432376  [12800/27455]\n",
            "gradient mean= 6.038033825461753e-05\n",
            "loss: 2.383099  [19200/27455]\n",
            "gradient mean= -7.260419806698337e-05\n",
            "loss: 2.382183  [25600/27455]\n",
            "gradient mean= 0.00048166417400352657\n",
            "Test Error: \n",
            " Accuracy: 66.0%, Avg loss: 2.667360 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 97.7%, Avg loss: 2.349026 \n",
            "\n",
            "Epoch 61\n",
            "-----------------------------\n",
            "loss: 2.445519  [    0/27455]\n",
            "gradient mean= -0.00025578885106369853\n",
            "loss: 2.456697  [ 6400/27455]\n",
            "gradient mean= -0.00022906559752300382\n",
            "loss: 2.379167  [12800/27455]\n",
            "gradient mean= -3.3769276342354715e-05\n",
            "loss: 2.463096  [19200/27455]\n",
            "gradient mean= -0.00037835759576410055\n",
            "loss: 2.350464  [25600/27455]\n",
            "gradient mean= 9.452793165110052e-06\n",
            "Test Error: \n",
            " Accuracy: 69.7%, Avg loss: 2.627550 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.8%, Avg loss: 2.336547 \n",
            "\n",
            "Epoch 62\n",
            "-----------------------------\n",
            "loss: 2.430817  [    0/27455]\n",
            "gradient mean= 0.00042268697870895267\n",
            "loss: 2.398834  [ 6400/27455]\n",
            "gradient mean= -0.0001829161192290485\n",
            "loss: 2.396801  [12800/27455]\n",
            "gradient mean= 0.00011760920460801572\n",
            "loss: 2.368778  [19200/27455]\n",
            "gradient mean= 1.9846776922349818e-05\n",
            "loss: 2.421318  [25600/27455]\n",
            "gradient mean= 0.00022182997781783342\n",
            "Test Error: \n",
            " Accuracy: 67.2%, Avg loss: 2.653810 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 96.9%, Avg loss: 2.355132 \n",
            "\n",
            "Epoch 63\n",
            "-----------------------------\n",
            "loss: 2.433166  [    0/27455]\n",
            "gradient mean= -8.910689757613e-06\n",
            "loss: 2.375402  [ 6400/27455]\n",
            "gradient mean= 6.093602223700145e-06\n",
            "loss: 2.420817  [12800/27455]\n",
            "gradient mean= -0.00017424076213501394\n",
            "loss: 2.411860  [19200/27455]\n",
            "gradient mean= 0.00016229439643211663\n",
            "loss: 2.454902  [25600/27455]\n",
            "gradient mean= -0.000123125733807683\n",
            "Test Error: \n",
            " Accuracy: 68.6%, Avg loss: 2.633409 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.4%, Avg loss: 2.341311 \n",
            "\n",
            "Epoch 64\n",
            "-----------------------------\n",
            "loss: 2.414252  [    0/27455]\n",
            "gradient mean= -0.0003743930137716234\n",
            "loss: 2.419577  [ 6400/27455]\n",
            "gradient mean= 0.00010814065171871334\n",
            "loss: 2.358299  [12800/27455]\n",
            "gradient mean= -0.0005715219303965569\n",
            "loss: 2.378741  [19200/27455]\n",
            "gradient mean= -2.6548796085990034e-05\n",
            "loss: 2.390353  [25600/27455]\n",
            "gradient mean= 0.00012786497245542705\n",
            "Test Error: \n",
            " Accuracy: 73.6%, Avg loss: 2.594850 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.3%, Avg loss: 2.329700 \n",
            "\n",
            "Epoch 65\n",
            "-----------------------------\n",
            "loss: 2.389830  [    0/27455]\n",
            "gradient mean= -0.00010197640949627385\n",
            "loss: 2.391180  [ 6400/27455]\n",
            "gradient mean= -2.520239468140062e-05\n",
            "loss: 2.379660  [12800/27455]\n",
            "gradient mean= -7.046543760225177e-05\n",
            "loss: 2.396325  [19200/27455]\n",
            "gradient mean= 0.00012256650370545685\n",
            "loss: 2.386955  [25600/27455]\n",
            "gradient mean= 1.341598704129865e-06\n",
            "Test Error: \n",
            " Accuracy: 69.5%, Avg loss: 2.631161 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.4%, Avg loss: 2.339678 \n",
            "\n",
            "Epoch 66\n",
            "-----------------------------\n",
            "loss: 2.422461  [    0/27455]\n",
            "gradient mean= -0.0003212034935131669\n",
            "loss: 2.390602  [ 6400/27455]\n",
            "gradient mean= 0.00021659665799234062\n",
            "loss: 2.346239  [12800/27455]\n",
            "gradient mean= -0.00022216563229449093\n",
            "loss: 2.424102  [19200/27455]\n",
            "gradient mean= -0.0002726214879658073\n",
            "loss: 2.380779  [25600/27455]\n",
            "gradient mean= 6.453035166487098e-05\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 2.615474 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.4%, Avg loss: 2.328520 \n",
            "\n",
            "Epoch 67\n",
            "-----------------------------\n",
            "loss: 2.411766  [    0/27455]\n",
            "gradient mean= -0.00023612030781805515\n",
            "loss: 2.348451  [ 6400/27455]\n",
            "gradient mean= 2.0366076114441967e-06\n",
            "loss: 2.414732  [12800/27455]\n",
            "gradient mean= -9.194038284476846e-05\n",
            "loss: 2.394737  [19200/27455]\n",
            "gradient mean= -0.0001096842170227319\n",
            "loss: 2.408827  [25600/27455]\n",
            "gradient mean= -1.82179719558917e-05\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 2.590487 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327732 \n",
            "\n",
            "Epoch 68\n",
            "-----------------------------\n",
            "loss: 2.375725  [    0/27455]\n",
            "gradient mean= 4.202234777039848e-05\n",
            "loss: 2.386966  [ 6400/27455]\n",
            "gradient mean= -0.0003725293790921569\n",
            "loss: 2.387146  [12800/27455]\n",
            "gradient mean= -9.279549703933299e-05\n",
            "loss: 2.373855  [19200/27455]\n",
            "gradient mean= -0.00029527139849960804\n",
            "loss: 2.415796  [25600/27455]\n",
            "gradient mean= -0.00024187883536797017\n",
            "Test Error: \n",
            " Accuracy: 70.4%, Avg loss: 2.615519 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.4%, Avg loss: 2.328936 \n",
            "\n",
            "Epoch 69\n",
            "-----------------------------\n",
            "loss: 2.394452  [    0/27455]\n",
            "gradient mean= 0.0004553249746095389\n",
            "loss: 2.426399  [ 6400/27455]\n",
            "gradient mean= -0.00013119330105837435\n",
            "loss: 2.374673  [12800/27455]\n",
            "gradient mean= -2.19662888412131e-05\n",
            "loss: 2.351933  [19200/27455]\n",
            "gradient mean= -7.747760537313297e-05\n",
            "loss: 2.389103  [25600/27455]\n",
            "gradient mean= -2.4947637484729057e-06\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 2.614769 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.4%, Avg loss: 2.327946 \n",
            "\n",
            "Epoch 70\n",
            "-----------------------------\n",
            "loss: 2.397288  [    0/27455]\n",
            "gradient mean= -4.68605212518014e-05\n",
            "loss: 2.370605  [ 6400/27455]\n",
            "gradient mean= 0.00015850791533011943\n",
            "loss: 2.410551  [12800/27455]\n",
            "gradient mean= -7.666686724405736e-05\n",
            "loss: 2.383193  [19200/27455]\n",
            "gradient mean= -0.00012171907292213291\n",
            "loss: 2.426199  [25600/27455]\n",
            "gradient mean= -5.9711105677706655e-06\n",
            "Test Error: \n",
            " Accuracy: 70.6%, Avg loss: 2.618714 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.4%, Avg loss: 2.329003 \n",
            "\n",
            "Epoch 71\n",
            "-----------------------------\n",
            "loss: 2.351920  [    0/27455]\n",
            "gradient mean= -2.778995258267969e-05\n",
            "loss: 2.372707  [ 6400/27455]\n",
            "gradient mean= 2.6857365810428746e-05\n",
            "loss: 2.368911  [12800/27455]\n",
            "gradient mean= -6.565618241438642e-05\n",
            "loss: 2.398185  [19200/27455]\n",
            "gradient mean= -5.313286601449363e-05\n",
            "loss: 2.343202  [25600/27455]\n",
            "gradient mean= 2.2020305550540797e-05\n",
            "Test Error: \n",
            " Accuracy: 69.7%, Avg loss: 2.623036 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.6%, Avg loss: 2.336470 \n",
            "\n",
            "Epoch 72\n",
            "-----------------------------\n",
            "loss: 2.350219  [    0/27455]\n",
            "gradient mean= -2.517766461096471e-06\n",
            "loss: 2.429197  [ 6400/27455]\n",
            "gradient mean= 0.0005852699396200478\n",
            "loss: 2.351715  [12800/27455]\n",
            "gradient mean= -2.1847299649380147e-05\n",
            "loss: 2.340584  [19200/27455]\n",
            "gradient mean= -4.764219556818716e-05\n",
            "loss: 2.336162  [25600/27455]\n",
            "gradient mean= -0.00025224091950803995\n",
            "Test Error: \n",
            " Accuracy: 73.1%, Avg loss: 2.592611 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327300 \n",
            "\n",
            "Epoch 73\n",
            "-----------------------------\n",
            "loss: 2.409693  [    0/27455]\n",
            "gradient mean= -0.00018667535914573818\n",
            "loss: 2.375040  [ 6400/27455]\n",
            "gradient mean= 0.0004928882699459791\n",
            "loss: 2.376842  [12800/27455]\n",
            "gradient mean= 0.00019844160124193877\n",
            "loss: 2.367841  [19200/27455]\n",
            "gradient mean= -6.435631075873971e-05\n",
            "loss: 2.334533  [25600/27455]\n",
            "gradient mean= -0.00015009022899903357\n",
            "Test Error: \n",
            " Accuracy: 71.5%, Avg loss: 2.604365 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.4%, Avg loss: 2.328191 \n",
            "\n",
            "Epoch 74\n",
            "-----------------------------\n",
            "loss: 2.418291  [    0/27455]\n",
            "gradient mean= 0.0003506748762447387\n",
            "loss: 2.350963  [ 6400/27455]\n",
            "gradient mean= 9.492458775639534e-05\n",
            "loss: 2.391512  [12800/27455]\n",
            "gradient mean= -0.00014246502541936934\n",
            "loss: 2.359443  [19200/27455]\n",
            "gradient mean= 1.6966274415608495e-05\n",
            "loss: 2.357975  [25600/27455]\n",
            "gradient mean= 4.8931069613900036e-05\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 2.592149 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327322 \n",
            "\n",
            "Epoch 75\n",
            "-----------------------------\n",
            "loss: 2.380452  [    0/27455]\n",
            "gradient mean= -0.0001963636022992432\n",
            "loss: 2.384863  [ 6400/27455]\n",
            "gradient mean= 4.11504770454485e-05\n",
            "loss: 2.364473  [12800/27455]\n",
            "gradient mean= 0.00030389727908186615\n",
            "loss: 2.375035  [19200/27455]\n",
            "gradient mean= -0.000280760636087507\n",
            "loss: 2.365032  [25600/27455]\n",
            "gradient mean= -0.00014049453602638096\n",
            "Test Error: \n",
            " Accuracy: 69.1%, Avg loss: 2.629662 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.326672 \n",
            "\n",
            "Epoch 76\n",
            "-----------------------------\n",
            "loss: 2.412252  [    0/27455]\n",
            "gradient mean= 1.798344419512432e-05\n",
            "loss: 2.424337  [ 6400/27455]\n",
            "gradient mean= -0.00012324753333814442\n",
            "loss: 2.369663  [12800/27455]\n",
            "gradient mean= -0.00029524724232032895\n",
            "loss: 2.412267  [19200/27455]\n",
            "gradient mean= -6.63701503071934e-05\n",
            "loss: 2.375295  [25600/27455]\n",
            "gradient mean= 2.2572983652935363e-05\n",
            "Test Error: \n",
            " Accuracy: 70.2%, Avg loss: 2.619417 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327297 \n",
            "\n",
            "Epoch 77\n",
            "-----------------------------\n",
            "loss: 2.368507  [    0/27455]\n",
            "gradient mean= 0.00018488315981812775\n",
            "loss: 2.359486  [ 6400/27455]\n",
            "gradient mean= 4.450809501577169e-05\n",
            "loss: 2.363562  [12800/27455]\n",
            "gradient mean= -1.0711853974498808e-05\n",
            "loss: 2.388775  [19200/27455]\n",
            "gradient mean= -1.1237691069254652e-05\n",
            "loss: 2.399034  [25600/27455]\n",
            "gradient mean= -6.648995622526854e-05\n",
            "Test Error: \n",
            " Accuracy: 68.8%, Avg loss: 2.635213 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 98.7%, Avg loss: 2.335941 \n",
            "\n",
            "Epoch 78\n",
            "-----------------------------\n",
            "loss: 2.406910  [    0/27455]\n",
            "gradient mean= 7.457274477928877e-05\n",
            "loss: 2.388054  [ 6400/27455]\n",
            "gradient mean= -3.281244426034391e-05\n",
            "loss: 2.381751  [12800/27455]\n",
            "gradient mean= -1.5129712664929684e-05\n",
            "loss: 2.374025  [19200/27455]\n",
            "gradient mean= 8.001349488040432e-05\n",
            "loss: 2.394192  [25600/27455]\n",
            "gradient mean= 8.659595914650708e-05\n",
            "Test Error: \n",
            " Accuracy: 71.3%, Avg loss: 2.606867 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326091 \n",
            "\n",
            "Epoch 79\n",
            "-----------------------------\n",
            "loss: 2.359671  [    0/27455]\n",
            "gradient mean= 6.071986717870459e-05\n",
            "loss: 2.370137  [ 6400/27455]\n",
            "gradient mean= 7.64839060138911e-05\n",
            "loss: 2.358460  [12800/27455]\n",
            "gradient mean= -0.00014354742597788572\n",
            "loss: 2.370060  [19200/27455]\n",
            "gradient mean= 4.1975774365710095e-05\n",
            "loss: 2.350780  [25600/27455]\n",
            "gradient mean= 0.00010595679486868903\n",
            "Test Error: \n",
            " Accuracy: 71.7%, Avg loss: 2.609714 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326474 \n",
            "\n",
            "Epoch 80\n",
            "-----------------------------\n",
            "loss: 2.421861  [    0/27455]\n",
            "gradient mean= 0.0007591378525830805\n",
            "loss: 2.390911  [ 6400/27455]\n",
            "gradient mean= -0.0002797497727442533\n",
            "loss: 2.346895  [12800/27455]\n",
            "gradient mean= -2.346459950786084e-05\n",
            "loss: 2.364300  [19200/27455]\n",
            "gradient mean= 0.00010395199933554977\n",
            "loss: 2.352130  [25600/27455]\n",
            "gradient mean= -0.00013383578334469348\n",
            "Test Error: \n",
            " Accuracy: 72.3%, Avg loss: 2.605444 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325799 \n",
            "\n",
            "Epoch 81\n",
            "-----------------------------\n",
            "loss: 2.391201  [    0/27455]\n",
            "gradient mean= -0.00039861752884462476\n",
            "loss: 2.341911  [ 6400/27455]\n",
            "gradient mean= -2.6382784199086018e-05\n",
            "loss: 2.415440  [12800/27455]\n",
            "gradient mean= 0.00010407075751572847\n",
            "loss: 2.352275  [19200/27455]\n",
            "gradient mean= -6.29622036285582e-06\n",
            "loss: 2.345976  [25600/27455]\n",
            "gradient mean= 7.722252485109493e-05\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 2.607047 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327385 \n",
            "\n",
            "Epoch 82\n",
            "-----------------------------\n",
            "loss: 2.380424  [    0/27455]\n",
            "gradient mean= -5.328999122866662e-06\n",
            "loss: 2.369539  [ 6400/27455]\n",
            "gradient mean= 8.047449955483899e-05\n",
            "loss: 2.367687  [12800/27455]\n",
            "gradient mean= 0.00011735974112525582\n",
            "loss: 2.339769  [19200/27455]\n",
            "gradient mean= 3.128631942672655e-05\n",
            "loss: 2.349673  [25600/27455]\n",
            "gradient mean= -6.691506132483482e-05\n",
            "Test Error: \n",
            " Accuracy: 72.7%, Avg loss: 2.595726 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.326911 \n",
            "\n",
            "Epoch 83\n",
            "-----------------------------\n",
            "loss: 2.352842  [    0/27455]\n",
            "gradient mean= 3.9846701838541776e-05\n",
            "loss: 2.388769  [ 6400/27455]\n",
            "gradient mean= 3.175384335918352e-05\n",
            "loss: 2.336275  [12800/27455]\n",
            "gradient mean= -0.00021887973707634956\n",
            "loss: 2.360563  [19200/27455]\n",
            "gradient mean= -2.9954937417642213e-05\n",
            "loss: 2.348839  [25600/27455]\n",
            "gradient mean= 1.7960115656023845e-05\n",
            "Test Error: \n",
            " Accuracy: 70.8%, Avg loss: 2.612040 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.326896 \n",
            "\n",
            "Epoch 84\n",
            "-----------------------------\n",
            "loss: 2.380097  [    0/27455]\n",
            "gradient mean= 0.00011743475624825805\n",
            "loss: 2.347949  [ 6400/27455]\n",
            "gradient mean= -3.9374299376504496e-05\n",
            "loss: 2.368046  [12800/27455]\n",
            "gradient mean= 0.0002363538515055552\n",
            "loss: 2.417282  [19200/27455]\n",
            "gradient mean= -2.606341331556905e-05\n",
            "loss: 2.372605  [25600/27455]\n",
            "gradient mean= 6.30133508821018e-05\n",
            "Test Error: \n",
            " Accuracy: 71.1%, Avg loss: 2.613385 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326440 \n",
            "\n",
            "Epoch 85\n",
            "-----------------------------\n",
            "loss: 2.349083  [    0/27455]\n",
            "gradient mean= 9.974962449632585e-05\n",
            "loss: 2.332525  [ 6400/27455]\n",
            "gradient mean= -1.5029983842396177e-05\n",
            "loss: 2.367659  [12800/27455]\n",
            "gradient mean= 2.2392468963516876e-05\n",
            "loss: 2.361594  [19200/27455]\n",
            "gradient mean= 3.4506731026340276e-05\n",
            "loss: 2.379756  [25600/27455]\n",
            "gradient mean= 7.837892917450517e-05\n",
            "Test Error: \n",
            " Accuracy: 70.8%, Avg loss: 2.615868 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326383 \n",
            "\n",
            "Epoch 86\n",
            "-----------------------------\n",
            "loss: 2.335826  [    0/27455]\n",
            "gradient mean= -0.00011100558185717091\n",
            "loss: 2.377104  [ 6400/27455]\n",
            "gradient mean= 0.00018351209291722625\n",
            "loss: 2.362850  [12800/27455]\n",
            "gradient mean= -2.956766911665909e-05\n",
            "loss: 2.346061  [19200/27455]\n",
            "gradient mean= 5.617799979518168e-05\n",
            "loss: 2.353260  [25600/27455]\n",
            "gradient mean= 8.844297553878278e-05\n",
            "Test Error: \n",
            " Accuracy: 72.7%, Avg loss: 2.597640 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325831 \n",
            "\n",
            "Epoch 87\n",
            "-----------------------------\n",
            "loss: 2.371685  [    0/27455]\n",
            "gradient mean= -4.919773346045986e-05\n",
            "loss: 2.399164  [ 6400/27455]\n",
            "gradient mean= 5.107447213958949e-05\n",
            "loss: 2.334229  [12800/27455]\n",
            "gradient mean= -7.937615009723231e-06\n",
            "loss: 2.338658  [19200/27455]\n",
            "gradient mean= 4.1387949750060216e-05\n",
            "loss: 2.357081  [25600/27455]\n",
            "gradient mean= -0.00010106764239026234\n",
            "Test Error: \n",
            " Accuracy: 72.6%, Avg loss: 2.597295 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326104 \n",
            "\n",
            "Epoch 88\n",
            "-----------------------------\n",
            "loss: 2.387955  [    0/27455]\n",
            "gradient mean= 0.0001260137651115656\n",
            "loss: 2.338918  [ 6400/27455]\n",
            "gradient mean= -0.0001033564331009984\n",
            "loss: 2.378273  [12800/27455]\n",
            "gradient mean= 0.00020398330525495112\n",
            "loss: 2.342094  [19200/27455]\n",
            "gradient mean= -1.0523486707825214e-05\n",
            "loss: 2.358137  [25600/27455]\n",
            "gradient mean= -5.945008888375014e-05\n",
            "Test Error: \n",
            " Accuracy: 73.7%, Avg loss: 2.585798 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325780 \n",
            "\n",
            "Epoch 89\n",
            "-----------------------------\n",
            "loss: 2.375389  [    0/27455]\n",
            "gradient mean= -6.422586739063263e-05\n",
            "loss: 2.347570  [ 6400/27455]\n",
            "gradient mean= -6.840052083134651e-05\n",
            "loss: 2.365937  [12800/27455]\n",
            "gradient mean= -0.00023313687415793538\n",
            "loss: 2.362028  [19200/27455]\n",
            "gradient mean= -0.00016924778174143285\n",
            "loss: 2.348013  [25600/27455]\n",
            "gradient mean= -1.0956538062600885e-05\n",
            "Test Error: \n",
            " Accuracy: 72.7%, Avg loss: 2.595217 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326112 \n",
            "\n",
            "Epoch 90\n",
            "-----------------------------\n",
            "loss: 2.330729  [    0/27455]\n",
            "gradient mean= -1.6372743630199693e-05\n",
            "loss: 2.362292  [ 6400/27455]\n",
            "gradient mean= 4.106572305317968e-06\n",
            "loss: 2.364420  [12800/27455]\n",
            "gradient mean= 1.8014083025263972e-07\n",
            "loss: 2.349871  [19200/27455]\n",
            "gradient mean= -0.00011410459410399199\n",
            "loss: 2.406408  [25600/27455]\n",
            "gradient mean= 8.313670696225017e-05\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 2.613372 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327290 \n",
            "\n",
            "Epoch 91\n",
            "-----------------------------\n",
            "loss: 2.368799  [    0/27455]\n",
            "gradient mean= 7.829033711459488e-05\n",
            "loss: 2.339966  [ 6400/27455]\n",
            "gradient mean= -3.845710671157576e-05\n",
            "loss: 2.345522  [12800/27455]\n",
            "gradient mean= -2.2978701963438652e-05\n",
            "loss: 2.351948  [19200/27455]\n",
            "gradient mean= 1.0873885003093164e-05\n",
            "loss: 2.372694  [25600/27455]\n",
            "gradient mean= -0.00017296297301072627\n",
            "Test Error: \n",
            " Accuracy: 71.3%, Avg loss: 2.612832 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327082 \n",
            "\n",
            "Epoch 92\n",
            "-----------------------------\n",
            "loss: 2.365011  [    0/27455]\n",
            "gradient mean= -2.9830454877810553e-05\n",
            "loss: 2.338256  [ 6400/27455]\n",
            "gradient mean= -5.738318941439502e-05\n",
            "loss: 2.344987  [12800/27455]\n",
            "gradient mean= -7.542358798673376e-05\n",
            "loss: 2.366117  [19200/27455]\n",
            "gradient mean= 1.7407539417035878e-05\n",
            "loss: 2.369430  [25600/27455]\n",
            "gradient mean= 0.0001723825844237581\n",
            "Test Error: \n",
            " Accuracy: 72.8%, Avg loss: 2.594743 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325795 \n",
            "\n",
            "Epoch 93\n",
            "-----------------------------\n",
            "loss: 2.331333  [    0/27455]\n",
            "gradient mean= -0.0001316071575274691\n",
            "loss: 2.351235  [ 6400/27455]\n",
            "gradient mean= 0.00043374422239139676\n",
            "loss: 2.395280  [12800/27455]\n",
            "gradient mean= -0.0001652438222663477\n",
            "loss: 2.342167  [19200/27455]\n",
            "gradient mean= -0.00032748031662777066\n",
            "loss: 2.354480  [25600/27455]\n",
            "gradient mean= 1.3357993339013774e-05\n",
            "Test Error: \n",
            " Accuracy: 71.6%, Avg loss: 2.608192 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325862 \n",
            "\n",
            "Epoch 94\n",
            "-----------------------------\n",
            "loss: 2.355170  [    0/27455]\n",
            "gradient mean= 1.4436224091696204e-06\n",
            "loss: 2.355678  [ 6400/27455]\n",
            "gradient mean= -1.1194420949323103e-05\n",
            "loss: 2.342226  [12800/27455]\n",
            "gradient mean= -0.00025865345378406346\n",
            "loss: 2.357145  [19200/27455]\n",
            "gradient mean= -8.422633254667744e-05\n",
            "loss: 2.346193  [25600/27455]\n",
            "gradient mean= 2.1475831090356223e-05\n",
            "Test Error: \n",
            " Accuracy: 71.1%, Avg loss: 2.610988 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.326781 \n",
            "\n",
            "Epoch 95\n",
            "-----------------------------\n",
            "loss: 2.349145  [    0/27455]\n",
            "gradient mean= -9.791602496989071e-05\n",
            "loss: 2.340777  [ 6400/27455]\n",
            "gradient mean= -3.505993663566187e-05\n",
            "loss: 2.377944  [12800/27455]\n",
            "gradient mean= 4.486466059461236e-05\n",
            "loss: 2.383657  [19200/27455]\n",
            "gradient mean= -0.00033735475153662264\n",
            "loss: 2.348380  [25600/27455]\n",
            "gradient mean= -4.760332376463339e-05\n",
            "Test Error: \n",
            " Accuracy: 70.2%, Avg loss: 2.621110 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.4%, Avg loss: 2.328737 \n",
            "\n",
            "Epoch 96\n",
            "-----------------------------\n",
            "loss: 2.383065  [    0/27455]\n",
            "gradient mean= -2.2398849978344515e-05\n",
            "loss: 2.343971  [ 6400/27455]\n",
            "gradient mean= -0.00015436604735441506\n",
            "loss: 2.391611  [12800/27455]\n",
            "gradient mean= -9.609188418835402e-05\n",
            "loss: 2.330909  [19200/27455]\n",
            "gradient mean= -5.574820897891186e-05\n",
            "loss: 2.336264  [25600/27455]\n",
            "gradient mean= -7.203119821497239e-06\n",
            "Test Error: \n",
            " Accuracy: 74.0%, Avg loss: 2.584407 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325789 \n",
            "\n",
            "Epoch 97\n",
            "-----------------------------\n",
            "loss: 2.378685  [    0/27455]\n",
            "gradient mean= -4.6789540647296235e-05\n",
            "loss: 2.336823  [ 6400/27455]\n",
            "gradient mean= 7.59436734369956e-05\n",
            "loss: 2.390441  [12800/27455]\n",
            "gradient mean= -6.441908044507727e-05\n",
            "loss: 2.362556  [19200/27455]\n",
            "gradient mean= -2.652044167916756e-05\n",
            "loss: 2.349167  [25600/27455]\n",
            "gradient mean= 0.0001262909354409203\n",
            "Test Error: \n",
            " Accuracy: 73.1%, Avg loss: 2.590428 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325267 \n",
            "\n",
            "Epoch 98\n",
            "-----------------------------\n",
            "loss: 2.327646  [    0/27455]\n",
            "gradient mean= 3.682165697682649e-05\n",
            "loss: 2.373599  [ 6400/27455]\n",
            "gradient mean= 3.8796435546828434e-05\n",
            "loss: 2.379798  [12800/27455]\n",
            "gradient mean= -1.0219791874988005e-05\n",
            "loss: 2.365547  [19200/27455]\n",
            "gradient mean= 0.00031272604246623814\n",
            "loss: 2.380584  [25600/27455]\n",
            "gradient mean= -7.691785867791623e-05\n",
            "Test Error: \n",
            " Accuracy: 72.6%, Avg loss: 2.597123 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325632 \n",
            "\n",
            "Epoch 99\n",
            "-----------------------------\n",
            "loss: 2.326929  [    0/27455]\n",
            "gradient mean= -1.9555998733267188e-05\n",
            "loss: 2.353979  [ 6400/27455]\n",
            "gradient mean= 0.00010804907651618123\n",
            "loss: 2.372121  [12800/27455]\n",
            "gradient mean= 0.0002495735534466803\n",
            "loss: 2.433743  [19200/27455]\n",
            "gradient mean= -5.166004120837897e-05\n",
            "loss: 2.323893  [25600/27455]\n",
            "gradient mean= 1.2180620615254156e-05\n",
            "Test Error: \n",
            " Accuracy: 73.3%, Avg loss: 2.585491 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325423 \n",
            "\n",
            "Epoch 100\n",
            "-----------------------------\n",
            "loss: 2.373418  [    0/27455]\n",
            "gradient mean= -0.00010826750076375902\n",
            "loss: 2.356666  [ 6400/27455]\n",
            "gradient mean= 0.0002637176075950265\n",
            "loss: 2.382894  [12800/27455]\n",
            "gradient mean= 0.00018161447951570153\n",
            "loss: 2.368009  [19200/27455]\n",
            "gradient mean= -1.1054718015657272e-05\n",
            "loss: 2.354005  [25600/27455]\n",
            "gradient mean= 1.1061627446906641e-05\n",
            "Test Error: \n",
            " Accuracy: 73.3%, Avg loss: 2.589941 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325360 \n",
            "\n",
            "Epoch 101\n",
            "-----------------------------\n",
            "loss: 2.402879  [    0/27455]\n",
            "gradient mean= -2.0372046492411755e-05\n",
            "loss: 2.385681  [ 6400/27455]\n",
            "gradient mean= -1.921646253322251e-05\n",
            "loss: 2.352895  [12800/27455]\n",
            "gradient mean= -3.0196997613529675e-06\n",
            "loss: 2.370592  [19200/27455]\n",
            "gradient mean= -0.001519298180937767\n",
            "loss: 2.345364  [25600/27455]\n",
            "gradient mean= 1.2323369446676224e-05\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 2.597226 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324996 \n",
            "\n",
            "Epoch 102\n",
            "-----------------------------\n",
            "loss: 2.373981  [    0/27455]\n",
            "gradient mean= -0.000111373134132009\n",
            "loss: 2.343976  [ 6400/27455]\n",
            "gradient mean= -6.913147808518261e-05\n",
            "loss: 2.346840  [12800/27455]\n",
            "gradient mean= -1.8526421627029777e-05\n",
            "loss: 2.327276  [19200/27455]\n",
            "gradient mean= 1.3541191037802491e-05\n",
            "loss: 2.344672  [25600/27455]\n",
            "gradient mean= -0.0001027011385303922\n",
            "Test Error: \n",
            " Accuracy: 72.6%, Avg loss: 2.599740 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325116 \n",
            "\n",
            "Epoch 103\n",
            "-----------------------------\n",
            "loss: 2.340018  [    0/27455]\n",
            "gradient mean= 6.757165101589635e-05\n",
            "loss: 2.354688  [ 6400/27455]\n",
            "gradient mean= -8.102482752292417e-06\n",
            "loss: 2.353344  [12800/27455]\n",
            "gradient mean= 0.00026048821746371686\n",
            "loss: 2.350436  [19200/27455]\n",
            "gradient mean= -3.0425524073507404e-06\n",
            "loss: 2.348863  [25600/27455]\n",
            "gradient mean= 3.914506669389084e-05\n",
            "Test Error: \n",
            " Accuracy: 73.8%, Avg loss: 2.585080 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325075 \n",
            "\n",
            "Epoch 104\n",
            "-----------------------------\n",
            "loss: 2.351509  [    0/27455]\n",
            "gradient mean= -0.0003167435643263161\n",
            "loss: 2.350696  [ 6400/27455]\n",
            "gradient mean= 0.00016605373821221292\n",
            "loss: 2.397092  [12800/27455]\n",
            "gradient mean= -0.00011765392264351249\n",
            "loss: 2.348408  [19200/27455]\n",
            "gradient mean= 4.807036748388782e-05\n",
            "loss: 2.333210  [25600/27455]\n",
            "gradient mean= -3.755165380425751e-05\n",
            "Test Error: \n",
            " Accuracy: 69.5%, Avg loss: 2.626630 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326520 \n",
            "\n",
            "Epoch 105\n",
            "-----------------------------\n",
            "loss: 2.340099  [    0/27455]\n",
            "gradient mean= -4.929985152557492e-05\n",
            "loss: 2.371817  [ 6400/27455]\n",
            "gradient mean= 3.751734402612783e-05\n",
            "loss: 2.386661  [12800/27455]\n",
            "gradient mean= 5.884281199541874e-05\n",
            "loss: 2.357495  [19200/27455]\n",
            "gradient mean= -1.5551922842860222e-05\n",
            "loss: 2.362855  [25600/27455]\n",
            "gradient mean= -9.434989806322847e-06\n",
            "Test Error: \n",
            " Accuracy: 73.8%, Avg loss: 2.588493 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325722 \n",
            "\n",
            "Epoch 106\n",
            "-----------------------------\n",
            "loss: 2.359116  [    0/27455]\n",
            "gradient mean= -5.6581429817015305e-05\n",
            "loss: 2.344893  [ 6400/27455]\n",
            "gradient mean= -2.7168236556462944e-05\n",
            "loss: 2.362326  [12800/27455]\n",
            "gradient mean= -0.00030799052910879254\n",
            "loss: 2.379926  [19200/27455]\n",
            "gradient mean= -3.740966349141672e-05\n",
            "loss: 2.348570  [25600/27455]\n",
            "gradient mean= 4.429882392287254e-05\n",
            "Test Error: \n",
            " Accuracy: 73.3%, Avg loss: 2.590184 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325022 \n",
            "\n",
            "Epoch 107\n",
            "-----------------------------\n",
            "loss: 2.324514  [    0/27455]\n",
            "gradient mean= 5.461507043946767e-06\n",
            "loss: 2.349700  [ 6400/27455]\n",
            "gradient mean= 0.00013570905139204115\n",
            "loss: 2.344903  [12800/27455]\n",
            "gradient mean= -3.6309331335360184e-05\n",
            "loss: 2.364317  [19200/27455]\n",
            "gradient mean= 7.575841300422326e-05\n",
            "loss: 2.342083  [25600/27455]\n",
            "gradient mean= -2.118380507454276e-06\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 2.590509 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324989 \n",
            "\n",
            "Epoch 108\n",
            "-----------------------------\n",
            "loss: 2.368352  [    0/27455]\n",
            "gradient mean= 0.00042708058026619256\n",
            "loss: 2.342009  [ 6400/27455]\n",
            "gradient mean= -3.885828846250661e-05\n",
            "loss: 2.368933  [12800/27455]\n",
            "gradient mean= 8.326118404511362e-06\n",
            "loss: 2.376332  [19200/27455]\n",
            "gradient mean= 0.00012334244092926383\n",
            "loss: 2.340481  [25600/27455]\n",
            "gradient mean= -0.0003404140006750822\n",
            "Test Error: \n",
            " Accuracy: 73.1%, Avg loss: 2.591316 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326471 \n",
            "\n",
            "Epoch 109\n",
            "-----------------------------\n",
            "loss: 2.359465  [    0/27455]\n",
            "gradient mean= 0.00013591961760539562\n",
            "loss: 2.386335  [ 6400/27455]\n",
            "gradient mean= 5.688238888978958e-05\n",
            "loss: 2.335082  [12800/27455]\n",
            "gradient mean= -0.00014771116548217833\n",
            "loss: 2.397665  [19200/27455]\n",
            "gradient mean= -5.116981628816575e-05\n",
            "loss: 2.334789  [25600/27455]\n",
            "gradient mean= 2.3407743356074207e-05\n",
            "Test Error: \n",
            " Accuracy: 72.9%, Avg loss: 2.592883 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325177 \n",
            "\n",
            "Epoch 110\n",
            "-----------------------------\n",
            "loss: 2.342612  [    0/27455]\n",
            "gradient mean= -1.3326476619113237e-05\n",
            "loss: 2.335397  [ 6400/27455]\n",
            "gradient mean= -1.347934448858723e-05\n",
            "loss: 2.352734  [12800/27455]\n",
            "gradient mean= -0.00017307022062595934\n",
            "loss: 2.347522  [19200/27455]\n",
            "gradient mean= 1.8821416233549826e-05\n",
            "loss: 2.353163  [25600/27455]\n",
            "gradient mean= 8.74162360560149e-05\n",
            "Test Error: \n",
            " Accuracy: 74.5%, Avg loss: 2.574893 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324983 \n",
            "\n",
            "Epoch 111\n",
            "-----------------------------\n",
            "loss: 2.376147  [    0/27455]\n",
            "gradient mean= 3.4945973311550915e-05\n",
            "loss: 2.352421  [ 6400/27455]\n",
            "gradient mean= 0.00021438224939629436\n",
            "loss: 2.330266  [12800/27455]\n",
            "gradient mean= -0.000266986433416605\n",
            "loss: 2.343728  [19200/27455]\n",
            "gradient mean= -5.642487394652562e-06\n",
            "loss: 2.361159  [25600/27455]\n",
            "gradient mean= -0.00022646761499345303\n",
            "Test Error: \n",
            " Accuracy: 72.5%, Avg loss: 2.595894 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325018 \n",
            "\n",
            "Epoch 112\n",
            "-----------------------------\n",
            "loss: 2.333997  [    0/27455]\n",
            "gradient mean= 0.00020345108350738883\n",
            "loss: 2.367609  [ 6400/27455]\n",
            "gradient mean= 1.278568379348144e-05\n",
            "loss: 2.336479  [12800/27455]\n",
            "gradient mean= 5.558080010814592e-05\n",
            "loss: 2.351170  [19200/27455]\n",
            "gradient mean= 0.00015071150846779346\n",
            "loss: 2.350983  [25600/27455]\n",
            "gradient mean= -0.00018416246166452765\n",
            "Test Error: \n",
            " Accuracy: 70.1%, Avg loss: 2.624150 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326394 \n",
            "\n",
            "Epoch 113\n",
            "-----------------------------\n",
            "loss: 2.327159  [    0/27455]\n",
            "gradient mean= 1.1707651538017672e-05\n",
            "loss: 2.346606  [ 6400/27455]\n",
            "gradient mean= 2.3790587874827906e-05\n",
            "loss: 2.339620  [12800/27455]\n",
            "gradient mean= 0.00012312929902691394\n",
            "loss: 2.358427  [19200/27455]\n",
            "gradient mean= 3.9595382986590266e-05\n",
            "loss: 2.361728  [25600/27455]\n",
            "gradient mean= 0.00017978907271753997\n",
            "Test Error: \n",
            " Accuracy: 71.3%, Avg loss: 2.611080 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325809 \n",
            "\n",
            "Epoch 114\n",
            "-----------------------------\n",
            "loss: 2.401304  [    0/27455]\n",
            "gradient mean= -2.522953764128033e-05\n",
            "loss: 2.332559  [ 6400/27455]\n",
            "gradient mean= -3.558147909643594e-06\n",
            "loss: 2.349357  [12800/27455]\n",
            "gradient mean= -0.00010219887917628512\n",
            "loss: 2.336120  [19200/27455]\n",
            "gradient mean= -6.36124677839689e-05\n",
            "loss: 2.383937  [25600/27455]\n",
            "gradient mean= 0.00016220085672102869\n",
            "Test Error: \n",
            " Accuracy: 75.3%, Avg loss: 2.567613 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324989 \n",
            "\n",
            "Epoch 115\n",
            "-----------------------------\n",
            "loss: 2.325996  [    0/27455]\n",
            "gradient mean= 9.579738616594113e-06\n",
            "loss: 2.363792  [ 6400/27455]\n",
            "gradient mean= -2.5908077077474445e-05\n",
            "loss: 2.359863  [12800/27455]\n",
            "gradient mean= -0.00030802105902694166\n",
            "loss: 2.373368  [19200/27455]\n",
            "gradient mean= -1.194533979287371e-05\n",
            "loss: 2.368951  [25600/27455]\n",
            "gradient mean= 0.00013044192746747285\n",
            "Test Error: \n",
            " Accuracy: 72.6%, Avg loss: 2.594436 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324983 \n",
            "\n",
            "Epoch 116\n",
            "-----------------------------\n",
            "loss: 2.371472  [    0/27455]\n",
            "gradient mean= 1.3709448467125185e-05\n",
            "loss: 2.339940  [ 6400/27455]\n",
            "gradient mean= -2.306926489836769e-06\n",
            "loss: 2.339788  [12800/27455]\n",
            "gradient mean= 2.4400223992415704e-06\n",
            "loss: 2.371406  [19200/27455]\n",
            "gradient mean= 3.6700903365272097e-06\n",
            "loss: 2.372729  [25600/27455]\n",
            "gradient mean= -4.161537435720675e-05\n",
            "Test Error: \n",
            " Accuracy: 74.3%, Avg loss: 2.579611 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325031 \n",
            "\n",
            "Epoch 117\n",
            "-----------------------------\n",
            "loss: 2.340735  [    0/27455]\n",
            "gradient mean= -2.507192584744189e-05\n",
            "loss: 2.358525  [ 6400/27455]\n",
            "gradient mean= -0.0002677937736734748\n",
            "loss: 2.346187  [12800/27455]\n",
            "gradient mean= -3.22651831083931e-05\n",
            "loss: 2.370814  [19200/27455]\n",
            "gradient mean= -3.131074845441617e-05\n",
            "loss: 2.322690  [25600/27455]\n",
            "gradient mean= 4.63346032120171e-06\n",
            "Test Error: \n",
            " Accuracy: 71.8%, Avg loss: 2.601815 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325739 \n",
            "\n",
            "Epoch 118\n",
            "-----------------------------\n",
            "loss: 2.330750  [    0/27455]\n",
            "gradient mean= 2.605446570669301e-05\n",
            "loss: 2.370831  [ 6400/27455]\n",
            "gradient mean= 1.1105653356935363e-05\n",
            "loss: 2.363672  [12800/27455]\n",
            "gradient mean= 0.00018037141126114875\n",
            "loss: 2.348863  [19200/27455]\n",
            "gradient mean= -0.0002381431550020352\n",
            "loss: 2.374223  [25600/27455]\n",
            "gradient mean= 0.0002935383818112314\n",
            "Test Error: \n",
            " Accuracy: 74.5%, Avg loss: 2.578177 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325024 \n",
            "\n",
            "Epoch 119\n",
            "-----------------------------\n",
            "loss: 2.326483  [    0/27455]\n",
            "gradient mean= -8.406203960475978e-06\n",
            "loss: 2.349517  [ 6400/27455]\n",
            "gradient mean= -0.00013273741933517158\n",
            "loss: 2.335752  [12800/27455]\n",
            "gradient mean= -4.1592898924136534e-05\n",
            "loss: 2.325448  [19200/27455]\n",
            "gradient mean= -5.357582722353982e-06\n",
            "loss: 2.356983  [25600/27455]\n",
            "gradient mean= -8.025977876968682e-06\n",
            "Test Error: \n",
            " Accuracy: 72.8%, Avg loss: 2.595484 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325356 \n",
            "\n",
            "Epoch 120\n",
            "-----------------------------\n",
            "loss: 2.323960  [    0/27455]\n",
            "gradient mean= -3.644128128144075e-06\n",
            "loss: 2.369596  [ 6400/27455]\n",
            "gradient mean= -1.6569057379456353e-06\n",
            "loss: 2.347493  [12800/27455]\n",
            "gradient mean= 1.8700751752476208e-05\n",
            "loss: 2.330377  [19200/27455]\n",
            "gradient mean= 0.00013759842840954661\n",
            "loss: 2.358953  [25600/27455]\n",
            "gradient mean= 0.0001303698227275163\n",
            "Test Error: \n",
            " Accuracy: 70.3%, Avg loss: 2.618294 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325734 \n",
            "\n",
            "Epoch 121\n",
            "-----------------------------\n",
            "loss: 2.407224  [    0/27455]\n",
            "gradient mean= 8.345722017111257e-05\n",
            "loss: 2.353562  [ 6400/27455]\n",
            "gradient mean= 6.982440390856937e-05\n",
            "loss: 2.377460  [12800/27455]\n",
            "gradient mean= -7.394528074655682e-05\n",
            "loss: 2.368071  [19200/27455]\n",
            "gradient mean= 0.00021398664102889597\n",
            "loss: 2.349526  [25600/27455]\n",
            "gradient mean= -1.889206214400474e-05\n",
            "Test Error: \n",
            " Accuracy: 71.7%, Avg loss: 2.601856 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325362 \n",
            "\n",
            "Epoch 122\n",
            "-----------------------------\n",
            "loss: 2.345660  [    0/27455]\n",
            "gradient mean= -8.107275061774999e-05\n",
            "loss: 2.359309  [ 6400/27455]\n",
            "gradient mean= 0.00011924895807169378\n",
            "loss: 2.360878  [12800/27455]\n",
            "gradient mean= 0.0002111855283146724\n",
            "loss: 2.397085  [19200/27455]\n",
            "gradient mean= 0.00018969632219523191\n",
            "loss: 2.324586  [25600/27455]\n",
            "gradient mean= -3.265661871409975e-05\n",
            "Test Error: \n",
            " Accuracy: 70.8%, Avg loss: 2.612192 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.325855 \n",
            "\n",
            "Epoch 123\n",
            "-----------------------------\n",
            "loss: 2.341621  [    0/27455]\n",
            "gradient mean= -0.0003338887181598693\n",
            "loss: 2.378149  [ 6400/27455]\n",
            "gradient mean= 5.669236088579055e-06\n",
            "loss: 2.341961  [12800/27455]\n",
            "gradient mean= 1.8874992747441866e-05\n",
            "loss: 2.341452  [19200/27455]\n",
            "gradient mean= 2.798515561153181e-05\n",
            "loss: 2.394225  [25600/27455]\n",
            "gradient mean= 3.4042961488012224e-05\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 2.615919 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.0%, Avg loss: 2.331927 \n",
            "\n",
            "Epoch 124\n",
            "-----------------------------\n",
            "loss: 2.373844  [    0/27455]\n",
            "gradient mean= 4.187434387858957e-05\n",
            "loss: 2.357372  [ 6400/27455]\n",
            "gradient mean= 2.3489894374506548e-05\n",
            "loss: 2.351353  [12800/27455]\n",
            "gradient mean= 8.545881428290159e-05\n",
            "loss: 2.332145  [19200/27455]\n",
            "gradient mean= 1.7978389223571867e-05\n",
            "loss: 2.371570  [25600/27455]\n",
            "gradient mean= 6.825971649959683e-05\n",
            "Test Error: \n",
            " Accuracy: 72.1%, Avg loss: 2.602267 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325060 \n",
            "\n",
            "Epoch 125\n",
            "-----------------------------\n",
            "loss: 2.331090  [    0/27455]\n",
            "gradient mean= -8.218182483687997e-05\n",
            "loss: 2.365151  [ 6400/27455]\n",
            "gradient mean= -0.00022373411047738045\n",
            "loss: 2.329546  [12800/27455]\n",
            "gradient mean= -0.0003134429280180484\n",
            "loss: 2.355394  [19200/27455]\n",
            "gradient mean= 1.259270720765926e-05\n",
            "loss: 2.336632  [25600/27455]\n",
            "gradient mean= 5.36022889718879e-05\n",
            "Test Error: \n",
            " Accuracy: 73.4%, Avg loss: 2.584839 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324988 \n",
            "\n",
            "Epoch 126\n",
            "-----------------------------\n",
            "loss: 2.363988  [    0/27455]\n",
            "gradient mean= 0.00019686095765791833\n",
            "loss: 2.336070  [ 6400/27455]\n",
            "gradient mean= 0.00018391269259154797\n",
            "loss: 2.334831  [12800/27455]\n",
            "gradient mean= -1.7127440514741465e-05\n",
            "loss: 2.337028  [19200/27455]\n",
            "gradient mean= 0.00012142701598349959\n",
            "loss: 2.353718  [25600/27455]\n",
            "gradient mean= -5.164100002730265e-05\n",
            "Test Error: \n",
            " Accuracy: 72.6%, Avg loss: 2.591863 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325002 \n",
            "\n",
            "Epoch 127\n",
            "-----------------------------\n",
            "loss: 2.360272  [    0/27455]\n",
            "gradient mean= -2.635020973684732e-05\n",
            "loss: 2.349921  [ 6400/27455]\n",
            "gradient mean= -2.9842696676496416e-05\n",
            "loss: 2.363896  [12800/27455]\n",
            "gradient mean= 0.00020001307711936533\n",
            "loss: 2.332585  [19200/27455]\n",
            "gradient mean= -2.6919426545646274e-06\n",
            "loss: 2.349189  [25600/27455]\n",
            "gradient mean= -0.0007771961390972137\n",
            "Test Error: \n",
            " Accuracy: 73.8%, Avg loss: 2.586830 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325025 \n",
            "\n",
            "Epoch 128\n",
            "-----------------------------\n",
            "loss: 2.330492  [    0/27455]\n",
            "gradient mean= -3.91369394492358e-05\n",
            "loss: 2.361540  [ 6400/27455]\n",
            "gradient mean= 6.87005594954826e-05\n",
            "loss: 2.338025  [12800/27455]\n",
            "gradient mean= -2.3989074179553427e-05\n",
            "loss: 2.338613  [19200/27455]\n",
            "gradient mean= 5.023090125177987e-05\n",
            "loss: 2.340001  [25600/27455]\n",
            "gradient mean= -0.00015667917614337057\n",
            "Test Error: \n",
            " Accuracy: 72.5%, Avg loss: 2.594766 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326236 \n",
            "\n",
            "Epoch 129\n",
            "-----------------------------\n",
            "loss: 2.358180  [    0/27455]\n",
            "gradient mean= 2.4459552150801755e-05\n",
            "loss: 2.379738  [ 6400/27455]\n",
            "gradient mean= -1.0199315738645964e-06\n",
            "loss: 2.354958  [12800/27455]\n",
            "gradient mean= -6.999297966103768e-06\n",
            "loss: 2.392220  [19200/27455]\n",
            "gradient mean= 6.29775968263857e-05\n",
            "loss: 2.335239  [25600/27455]\n",
            "gradient mean= 4.601292857842054e-06\n",
            "Test Error: \n",
            " Accuracy: 72.4%, Avg loss: 2.600001 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.4%, Avg loss: 2.328198 \n",
            "\n",
            "Epoch 130\n",
            "-----------------------------\n",
            "loss: 2.339349  [    0/27455]\n",
            "gradient mean= -0.00019853281264659017\n",
            "loss: 2.328299  [ 6400/27455]\n",
            "gradient mean= 3.692041900649201e-06\n",
            "loss: 2.366552  [12800/27455]\n",
            "gradient mean= -8.369573333766311e-05\n",
            "loss: 2.349720  [19200/27455]\n",
            "gradient mean= -0.0001337262656306848\n",
            "loss: 2.368060  [25600/27455]\n",
            "gradient mean= -8.586558578826953e-06\n",
            "Test Error: \n",
            " Accuracy: 74.9%, Avg loss: 2.572711 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324981 \n",
            "\n",
            "Epoch 131\n",
            "-----------------------------\n",
            "loss: 2.355981  [    0/27455]\n",
            "gradient mean= -7.38122034817934e-05\n",
            "loss: 2.357490  [ 6400/27455]\n",
            "gradient mean= -8.78216542332666e-06\n",
            "loss: 2.325173  [12800/27455]\n",
            "gradient mean= 1.2178075849078596e-05\n",
            "loss: 2.326962  [19200/27455]\n",
            "gradient mean= 2.4808694433886558e-05\n",
            "loss: 2.369805  [25600/27455]\n",
            "gradient mean= -1.7179190763272345e-05\n",
            "Test Error: \n",
            " Accuracy: 74.0%, Avg loss: 2.584912 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325055 \n",
            "\n",
            "Epoch 132\n",
            "-----------------------------\n",
            "loss: 2.380243  [    0/27455]\n",
            "gradient mean= -1.8523327526054345e-05\n",
            "loss: 2.337002  [ 6400/27455]\n",
            "gradient mean= -0.0001641542767174542\n",
            "loss: 2.371409  [12800/27455]\n",
            "gradient mean= 3.662731251097284e-05\n",
            "loss: 2.361837  [19200/27455]\n",
            "gradient mean= -3.780307815759443e-05\n",
            "loss: 2.328028  [25600/27455]\n",
            "gradient mean= -3.907087739207782e-05\n",
            "Test Error: \n",
            " Accuracy: 71.8%, Avg loss: 2.605866 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325147 \n",
            "\n",
            "Epoch 133\n",
            "-----------------------------\n",
            "loss: 2.331845  [    0/27455]\n",
            "gradient mean= 6.660519284196198e-05\n",
            "loss: 2.338894  [ 6400/27455]\n",
            "gradient mean= -1.243033602804644e-05\n",
            "loss: 2.324295  [12800/27455]\n",
            "gradient mean= 8.546771823603194e-06\n",
            "loss: 2.336977  [19200/27455]\n",
            "gradient mean= -1.9687680833158083e-05\n",
            "loss: 2.338212  [25600/27455]\n",
            "gradient mean= 7.336013823078247e-06\n",
            "Test Error: \n",
            " Accuracy: 70.7%, Avg loss: 2.615171 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325193 \n",
            "\n",
            "Epoch 134\n",
            "-----------------------------\n",
            "loss: 2.329260  [    0/27455]\n",
            "gradient mean= -4.103860555915162e-05\n",
            "loss: 2.381708  [ 6400/27455]\n",
            "gradient mean= 2.658279481693171e-05\n",
            "loss: 2.380126  [12800/27455]\n",
            "gradient mean= -5.696886091755005e-06\n",
            "loss: 2.329694  [19200/27455]\n",
            "gradient mean= 5.4296838243317325e-06\n",
            "loss: 2.349421  [25600/27455]\n",
            "gradient mean= 0.0002482579729985446\n",
            "Test Error: \n",
            " Accuracy: 73.9%, Avg loss: 2.586006 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325009 \n",
            "\n",
            "Epoch 135\n",
            "-----------------------------\n",
            "loss: 2.351533  [    0/27455]\n",
            "gradient mean= -1.0140754511667183e-06\n",
            "loss: 2.381803  [ 6400/27455]\n",
            "gradient mean= -0.00011038177035516128\n",
            "loss: 2.331899  [12800/27455]\n",
            "gradient mean= 8.439261000603437e-05\n",
            "loss: 2.371622  [19200/27455]\n",
            "gradient mean= -1.4750495211046655e-05\n",
            "loss: 2.325886  [25600/27455]\n",
            "gradient mean= -4.688390617957339e-06\n",
            "Test Error: \n",
            " Accuracy: 75.4%, Avg loss: 2.570184 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324990 \n",
            "\n",
            "Epoch 136\n",
            "-----------------------------\n",
            "loss: 2.356940  [    0/27455]\n",
            "gradient mean= -2.9264259865158238e-05\n",
            "loss: 2.386410  [ 6400/27455]\n",
            "gradient mean= -7.424891919072252e-06\n",
            "loss: 2.367088  [12800/27455]\n",
            "gradient mean= -0.0001846312079578638\n",
            "loss: 2.393785  [19200/27455]\n",
            "gradient mean= 5.363555465009995e-05\n",
            "loss: 2.336890  [25600/27455]\n",
            "gradient mean= 9.233262971974909e-05\n",
            "Test Error: \n",
            " Accuracy: 73.1%, Avg loss: 2.591166 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324988 \n",
            "\n",
            "Epoch 137\n",
            "-----------------------------\n",
            "loss: 2.327637  [    0/27455]\n",
            "gradient mean= -7.4776553447009064e-06\n",
            "loss: 2.339689  [ 6400/27455]\n",
            "gradient mean= 7.617512164870277e-05\n",
            "loss: 2.325392  [12800/27455]\n",
            "gradient mean= 2.489812504791189e-05\n",
            "loss: 2.354126  [19200/27455]\n",
            "gradient mean= 7.499581897718599e-06\n",
            "loss: 2.376833  [25600/27455]\n",
            "gradient mean= -9.75061411736533e-05\n",
            "Test Error: \n",
            " Accuracy: 75.8%, Avg loss: 2.562173 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324985 \n",
            "\n",
            "Epoch 138\n",
            "-----------------------------\n",
            "loss: 2.323420  [    0/27455]\n",
            "gradient mean= -9.688276804808993e-06\n",
            "loss: 2.347060  [ 6400/27455]\n",
            "gradient mean= -0.0005882149562239647\n",
            "loss: 2.334051  [12800/27455]\n",
            "gradient mean= -0.0004908121773041785\n",
            "loss: 2.328723  [19200/27455]\n",
            "gradient mean= 1.1456529136921745e-05\n",
            "loss: 2.395020  [25600/27455]\n",
            "gradient mean= 9.221371328749228e-06\n",
            "Test Error: \n",
            " Accuracy: 74.5%, Avg loss: 2.575652 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324989 \n",
            "\n",
            "Epoch 139\n",
            "-----------------------------\n",
            "loss: 2.325671  [    0/27455]\n",
            "gradient mean= -7.183440175140277e-05\n",
            "loss: 2.324439  [ 6400/27455]\n",
            "gradient mean= -1.2496147974161431e-05\n",
            "loss: 2.344454  [12800/27455]\n",
            "gradient mean= -6.642320840910543e-06\n",
            "loss: 2.347872  [19200/27455]\n",
            "gradient mean= -1.4581468349206261e-05\n",
            "loss: 2.370546  [25600/27455]\n",
            "gradient mean= 6.562910130014643e-05\n",
            "Test Error: \n",
            " Accuracy: 71.8%, Avg loss: 2.600419 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326027 \n",
            "\n",
            "Epoch 140\n",
            "-----------------------------\n",
            "loss: 2.351978  [    0/27455]\n",
            "gradient mean= -7.362332689808682e-05\n",
            "loss: 2.368437  [ 6400/27455]\n",
            "gradient mean= -0.00016329569916706532\n",
            "loss: 2.326369  [12800/27455]\n",
            "gradient mean= 3.3189146506629186e-06\n",
            "loss: 2.337438  [19200/27455]\n",
            "gradient mean= 0.00011317682947264984\n",
            "loss: 2.322965  [25600/27455]\n",
            "gradient mean= 4.4639537577495503e-07\n",
            "Test Error: \n",
            " Accuracy: 74.6%, Avg loss: 2.579392 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.6%, Avg loss: 2.326071 \n",
            "\n",
            "Epoch 141\n",
            "-----------------------------\n",
            "loss: 2.403556  [    0/27455]\n",
            "gradient mean= 6.547032535308972e-05\n",
            "loss: 2.338704  [ 6400/27455]\n",
            "gradient mean= 8.821827577776276e-06\n",
            "loss: 2.332316  [12800/27455]\n",
            "gradient mean= 2.6541614715824835e-05\n",
            "loss: 2.326632  [19200/27455]\n",
            "gradient mean= -1.2989334209123626e-05\n",
            "loss: 2.365620  [25600/27455]\n",
            "gradient mean= 8.173970854841173e-06\n",
            "Test Error: \n",
            " Accuracy: 70.3%, Avg loss: 2.618518 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.5%, Avg loss: 2.327113 \n",
            "\n",
            "Epoch 142\n",
            "-----------------------------\n",
            "loss: 2.337934  [    0/27455]\n",
            "gradient mean= -0.0002904173161368817\n",
            "loss: 2.323735  [ 6400/27455]\n",
            "gradient mean= 8.628365321783349e-05\n",
            "loss: 2.362306  [12800/27455]\n",
            "gradient mean= 5.0012308747682255e-06\n",
            "loss: 2.401103  [19200/27455]\n",
            "gradient mean= 6.935620331205428e-05\n",
            "loss: 2.333409  [25600/27455]\n",
            "gradient mean= 3.720754830283113e-05\n",
            "Test Error: \n",
            " Accuracy: 75.0%, Avg loss: 2.574870 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325265 \n",
            "\n",
            "Epoch 143\n",
            "-----------------------------\n",
            "loss: 2.358975  [    0/27455]\n",
            "gradient mean= -7.534219912486151e-05\n",
            "loss: 2.344769  [ 6400/27455]\n",
            "gradient mean= 7.973546598805115e-05\n",
            "loss: 2.354199  [12800/27455]\n",
            "gradient mean= 4.092759809282143e-06\n",
            "loss: 2.330116  [19200/27455]\n",
            "gradient mean= -4.320928201195784e-05\n",
            "loss: 2.354159  [25600/27455]\n",
            "gradient mean= -0.0005221481551416218\n",
            "Test Error: \n",
            " Accuracy: 75.2%, Avg loss: 2.571454 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325037 \n",
            "\n",
            "Epoch 144\n",
            "-----------------------------\n",
            "loss: 2.373971  [    0/27455]\n",
            "gradient mean= 2.0343601136119105e-05\n",
            "loss: 2.345945  [ 6400/27455]\n",
            "gradient mean= -0.0004005355585832149\n",
            "loss: 2.367834  [12800/27455]\n",
            "gradient mean= -1.4854359505989123e-05\n",
            "loss: 2.345071  [19200/27455]\n",
            "gradient mean= -1.4354206541611347e-05\n",
            "loss: 2.329229  [25600/27455]\n",
            "gradient mean= 9.890876526696957e-07\n",
            "Test Error: \n",
            " Accuracy: 73.2%, Avg loss: 2.591000 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325215 \n",
            "\n",
            "Epoch 145\n",
            "-----------------------------\n",
            "loss: 2.327001  [    0/27455]\n",
            "gradient mean= -3.514914226343535e-07\n",
            "loss: 2.378628  [ 6400/27455]\n",
            "gradient mean= -1.977093779714778e-05\n",
            "loss: 2.322879  [12800/27455]\n",
            "gradient mean= -1.6102887911983998e-06\n",
            "loss: 2.346388  [19200/27455]\n",
            "gradient mean= 0.00018178796744905412\n",
            "loss: 2.350965  [25600/27455]\n",
            "gradient mean= 7.884240403654985e-06\n",
            "Test Error: \n",
            " Accuracy: 74.9%, Avg loss: 2.574008 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325186 \n",
            "\n",
            "Epoch 146\n",
            "-----------------------------\n",
            "loss: 2.389613  [    0/27455]\n",
            "gradient mean= 0.0003214690659660846\n",
            "loss: 2.343133  [ 6400/27455]\n",
            "gradient mean= 9.600137127563357e-05\n",
            "loss: 2.332207  [12800/27455]\n",
            "gradient mean= 0.00012240841169841588\n",
            "loss: 2.370089  [19200/27455]\n",
            "gradient mean= 0.000140746749821119\n",
            "loss: 2.325071  [25600/27455]\n",
            "gradient mean= 4.6735625801375136e-05\n",
            "Test Error: \n",
            " Accuracy: 75.2%, Avg loss: 2.569038 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.324992 \n",
            "\n",
            "Epoch 147\n",
            "-----------------------------\n",
            "loss: 2.330612  [    0/27455]\n",
            "gradient mean= 2.2406047719414346e-06\n",
            "loss: 2.339870  [ 6400/27455]\n",
            "gradient mean= -1.418839383404702e-05\n",
            "loss: 2.356174  [12800/27455]\n",
            "gradient mean= -7.391799044853542e-06\n",
            "loss: 2.374576  [19200/27455]\n",
            "gradient mean= -8.669360977364704e-05\n",
            "loss: 2.332502  [25600/27455]\n",
            "gradient mean= -0.00033736927434802055\n",
            "Test Error: \n",
            " Accuracy: 73.6%, Avg loss: 2.586124 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325218 \n",
            "\n",
            "Epoch 148\n",
            "-----------------------------\n",
            "loss: 2.428404  [    0/27455]\n",
            "gradient mean= 4.3404339521657676e-05\n",
            "loss: 2.354587  [ 6400/27455]\n",
            "gradient mean= -6.902407039888203e-05\n",
            "loss: 2.415949  [12800/27455]\n",
            "gradient mean= -0.00032415628083981574\n",
            "loss: 2.342495  [19200/27455]\n",
            "gradient mean= 3.78157346858643e-05\n",
            "loss: 2.344947  [25600/27455]\n",
            "gradient mean= -3.302639379398897e-05\n",
            "Test Error: \n",
            " Accuracy: 75.4%, Avg loss: 2.566658 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325048 \n",
            "\n",
            "Epoch 149\n",
            "-----------------------------\n",
            "loss: 2.365303  [    0/27455]\n",
            "gradient mean= 1.8784874555421993e-05\n",
            "loss: 2.358980  [ 6400/27455]\n",
            "gradient mean= 0.0001014642184600234\n",
            "loss: 2.327504  [12800/27455]\n",
            "gradient mean= 2.071354629151756e-06\n",
            "loss: 2.348405  [19200/27455]\n",
            "gradient mean= 5.471310032589827e-06\n",
            "loss: 2.356869  [25600/27455]\n",
            "gradient mean= 3.327985177747905e-05\n",
            "Test Error: \n",
            " Accuracy: 74.1%, Avg loss: 2.581293 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325001 \n",
            "\n",
            "Epoch 150\n",
            "-----------------------------\n",
            "loss: 2.322843  [    0/27455]\n",
            "gradient mean= 7.178563805609883e-07\n",
            "loss: 2.340724  [ 6400/27455]\n",
            "gradient mean= 0.00014557625399902463\n",
            "loss: 2.333294  [12800/27455]\n",
            "gradient mean= -1.1283139428996947e-05\n",
            "loss: 2.356642  [19200/27455]\n",
            "gradient mean= 0.00016632277402095497\n",
            "loss: 2.349509  [25600/27455]\n",
            "gradient mean= -0.00011118714610347524\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 2.590845 \n",
            "\n",
            "Train Error: \n",
            " Accuracy: 99.7%, Avg loss: 2.325483 \n",
            "\n",
            "Done!\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 150\n",
        "optimizer = torch.optim.Adam(Dropout_model_Adam.parameters(), lr=1e-4)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "train_losses=[]\n",
        "test_losses=[]\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-----------------------------\")\n",
        "    train_loop(train_dataloader, Dropout_model_Adam, optimizer, loss_fn)\n",
        "    test_loop(Dropout_model_Adam, loss_fn, test_losses, train_losses)\n",
        "print(\"Done!\")\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the droput technique is supposed to help the model generalize better, but it seems that it is making the model worse and it is exacerbating the problem of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "for i in range(530,540):\n",
        "    x , y=test_images[i] , test_labels[i]\n",
        "    plt.subplot(2,5,i-529)\n",
        "    plt.imshow(x.reshape(28,28),cmap='gray')\n",
        "    x=x.reshape(1,784)\n",
        "    pred = simple_model_Adam(x.float())\n",
        "    plt.title(\"pred: \"+str( alphabet[ torch.argmax(pred) ])+\"  true: \"+str( alphabet[ y.item() ] ) )\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADXCAYAAAC51IK9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAC/rUlEQVR4nOy9d5Rkd3km/NxbOeeu6hwmz0gaSSOhgASSMJaEkTBaL8FggwO2P4ezweyu8/mw1/jA8XeMj9dmvd61wWJhYUlCBgEySALFURhJo2lN6O7pWF0553S/P3qed24NXTViLXqGs/c5Zw6ip6fqd3/hDc/7vL+raJoGAwYMGDCwM1Av9QAMGDBg4P8mGEbXgAEDBnYQhtE1YMCAgR2EYXQNGDBgYAdhGF0DBgwY2EEYRteAAQMGdhCG0TVgwICBHYRhdC8DKIrys4qiPKcoSkVRlE1FUR5SFOWWSz0uA68diqIsK4pSP7eG/DN2qcdFnBvfT1zqcRCX23gIRVE+qCjKcUVRaoqiJBRF+aSiKP7X8zt+JEZ3m4H/jaIovh/Fd/24j0tRlH8P4BMAPgogCmAKwN8AeMclHBaAy3O+LudxAbhH0zS37k/8Ug/IwGuHoii/DeBjAP4DAB+AGwFMA3hYURTr6/ZFmqa9rn8A/DaAJIC7AFgAzAD4BoBnAFhe7+/7cR7XuYWtAPjXl2pefpzm6zIf1zKAn7jU6/bjMr7LcDzec2fxXRf83A0gDeAXX7fv2uGBf+AyndBLNa67AHQAmC/F9/8YztdlOa5zY7isjMjlPr7LcDwDzyKATwP43Ov1Xa83vXAzADuAL+t/qGlaBVvRyE++zt/3WnG5jisEIKNpWucSff8gXK7zdbmOi/iqoiiFc3++eonHYuCHQxiDz+Lmub9/XfB6G92LDTzyOn/fa8XlOq4sgLCiKOZL9P2DcLnO1+U6LuKnNU3zn/vz05d4LAZ+OGQw+CyOnvv71wWvt9HdsYH/kLhcx/UUgCaAn75E3z8Il+t8Xa7jMvDjD57F+/Q/VBTFDeBuAN95vb7o9Ta6Fxv4o6/z971WXJbj0jStCOCPAPy1oig/rSiKU1EUi6IodyuK8vFLMaZzuCznC5fvuAz8n8GiKIpd9+eSZXznzuJHAPyVoih3nTuHMwC+AGAdwP2v55e93oT0f8T21eV5AK5LSJRfluM6N7b3AXgOQBVAAsDXAdx8icd0Wc7XZTyuZVxGhaHLfXznxqNd8Oc/Xwbj+iUArwCon9tnfwsg8Hp+h3Lui15XKIrySwD+HYDdAGwAHgPws9ol1i1eruO6XHG5ztflOi4DBl4LfiTNEZqm/Q9N067QNM0O4BcB7AJwyYtFl+u4LldcrvN1uY7LgIHXgh9JpPsDX6IoPwegrWna//qRf9kPgct1XJcrLtf5ulzHZcDAdtgRo2vAgAEDBrZgXHhjwIABAzsIw+gaMGDAwA5iaPGhVCpp3W4XmqZBVVX0ej10u110u110Oh2YTCbUajUoigJVVaEoCgDIf5tMJqiqimazCbvdDpvNBgDy+8CWZM1ms0FVVflsAHA4HFD4gduMi5/b6XTQ7XbR6/Xke4vFItxuN5rNJpxOJwDIOD0eDx5++GG86U1vgtfrhaZpqNfraLfb8Pv96PV6MJlMMJlMaDQaaDabWxNlNsNms8FsNsPhcGw7rlOnTmkjIyOwWCwAgF6vB0VRYDabUSgU0O12YTKZUK/X0ev1YLVaYbfb5Xfq9TpMJpP8nclkgqZpMJu3lslut6NUKiGfz8NsNsPtdsPlcsFkMqHb7Q4cVyqV0hRFgcvlgtlsRqfTQavVgqIo6PV6sFgsyGazaLVaMJlMsFgsMJlMAIBGo4F4PI54PI5OpwO73Y6RkRGMj48jEAjA4XCg0WigWq2i1WrBbrfD4XDAbrfDarVyT2w7rnw+r1FGo98/3W4XuVwOmUwGHo8HIyMjcDqd6Ha7qNVqaDQaaDQasFqt8Hq9cDgcqFarKJfLMJlMiEajAACTyYR8Po9GowGz2Qy73S7PpqoqnE7ntuP64he/qLndbvR6PbjdbjidTvR6PdTrdfh8PmxubmJ0dBTpdBomkwlWq1XW76Mf/SgymQw+9rGPwWq1otVqoVwuo1qtwufzodvtwul0IpPJoNPp9J2XZrOJzc1N/OEf/uG24/rud7+ruVwu9Ho9mTOTyYR2uw1g61y5XC40Gg3U63WoqgqbzYZWqwVN01Cr1WCz2eRsdjodVCoVdLtdNJtNhEIhKIqC06dPw263IxgMwm63o9VqIZ/P4+d+7ue2HdfnPvc5ze12y5pbrVaoqopCoQCXywVVVeHxeNBut1Gr1QAAFosFhUIBNpsN9XodDocD+XwerVZL1iiXy8mYVlZWEI1G4XK50O12Ua/XZR9/8IMf/IFxfeYzn9FcLhe8Xi+azSbK5bKcce4xr9fbZz96vV7f/+92u3JO+EyVSgVms1nOZLPZRLfblbXgf3/gAx/Ydq6AixhdPd/b6XTQ6XTQbrfFMGqaJl+iqio0TUOn09nSop0zJFarVX7GB1EURf7QyKyuriKVSkFVVUSjUczOzg4cl6qq8tAcByeNm7HZbKLdbqPZbKLVamFzcxPJZBKKoiCZTOJrX/sa7rjjDrjdbnS7XVgsFhkTn6PRaKDdbsNms8FutwOAGKPt4HQ6YbFYZJPT+GazWXEsXBjOZ7VahdlsxsrKCoCtzahf0Gq1ina7jT179qBYLMLr9cJqtcLj8cBms/XN57B1dLvdMJvNaLVa4gxqtRq63S4KhQIcDgd6vZ58Nw1br9eD3+/H2bNnUSgU5DNjsRisVqv8HgC43W6YTKa+sXAvbId2uy1OjoZH0zS0220kEgkoigKn0wmTyYRKpYJyuYxSqYRarYZCoYBQKASv14tWq4VisYherwev1wtFUfqMnc1mk/XlGjIA2A6xWAxmsxmJRAKtVgvNZhO5XA4Oh0MCg1qtBlVV0W63sb6+jlwuh71798LtdqNWq6FarYphcDgcCAQCSCaTaLVaaLVa8Hg86Ha7aLfbcqYURRGHsR2CwaDsZ+7RXq8Hn88nz6WqKoLBIMrlsqyL1WqFpmlotVowm81ot9t9+9jhcKBcLsNms8l8ORwOqKoqjsHlcg0cF38/lUrBZrOJc+cfTdOQy+XQbrdlHWq1Gux2u9iPUqmEZrMpZ8RkMsker1arcLvd8n3c79zPg8bE72m1WlBVte8zVFXFV77yFZRKJRw5cgS7du2Sz2aAabVa5XfNZrMYYZ7lXq8nZ5BnSn9+B2Ho39JI8iDwv2l0aTj0C9hoNJDP56EoCjqdDqxWKyKRCBRFQbVaRTqdRrPZhKIo2LdvH1RVxcLCAtLpNFqtFnw+HwKBwNBBN5tNGQc3Hj03PTOAPu+0sbGBbDYLq9WKZrOJM2fOwO/3Y//+/QgEAnLgOZncbDS4nMherzdwXE6nE+l0Gj6fT6I8TdPkMFgsFlQqFXEIPJgejwelUgnlclm+02w2S/RfKBRQLpdRLpdx/fXXi2Fh5Kw38INAD841Y5Tjdrvh8XgkKiLORfRQFAV2u13muNFooNPpwGw2o9frybM4nU4xnHTCNCSDHBUNmD7aZeZRrVYRjUahqipWVlbQ6XRQr9clmq1WqwCA2dlZrK6uIp/PQ9M0VKtV7N27F7VaDfV6vS9w4BpYLBbJtLaDw+GAx+OR6LDVaskB9Hg8aDabqNfrssalUgkvvPACXnzxRdjtdvh8PhSLRbhcLthsNvR6PRSLRXFINDjcU5wrAEOdp9lsRqPREMetj8D4961WS/YuDSz3ks1mg6Zp4mC5b/TZHY0dP5M/G7bvOQ+BQECei0aIZ7HT6YgR53ozUHI6najX67KHbTabRMBOp1OeQW/M+N+DnAHPHOeCmWO73YaiKEgkEshkMigUCqjVavJ8NOicF+5p2kJmNdxX3LMmk0me+3Uxur1eD+12Ww4uF7zZbIoBBCBpSrlcFgNjMpkQiURQLpeRz+eRy+VQKpUAAPv27cPGxgaWl5clzVVVVdKwYYeVxpaLxwnjRNAwAECr1UK9Xke325UIIJPJ4NSpUzKO6elp+XxulnMpe19KxlRuO1itVpTLZYRCIUnjOQ5GNfV6Hc1mE/F4HNVqVSgD/j0zA4633W4jl8uhUCigUqlgZGQEgUCgb7EZHVxsLflv6LCsVissFgucTmefIdWnWPTqdAh6CoDPp3dWPKT8//zZoHXUj4/OvVQqCdWSy+WwuroqTqJUKmFmZga9Xg+FQgEPP/xw37ir1SrGx8dlvPxuRiv6PUFDeiHq9TqCwaBEkBaLRSJq0mGNRkOymkqlgmQyiUQigcOHD8Nut0PTNFitVrhcLrTbbVQqFTF4zWZT9iwdFOeLGdWg+ep0OmKcTCaT0FNcUwY0eoqL2YbNZkOlUhEnSqPNCJOfyXmxWCwSJQ8DjRAphl6vJ1QVP5vOh3uIa82x0rhxTHa7XaguZip0HvxO0jfbodFowO12y7Pzszie06dPiwHVOzo97akfK+ee66M/S1w/fcY2dL6G/SUNLY1vvV5Ho9GQL6vVasIJcaLb7TbcbncfR5vNZsXYMAJutVpYWlrCmTNnAGxFF9yc/CyHw7HtuLhBAUiEq+dLgfMblIaSk1ir1aBpGgqFAkqlEhYWFuByubB7924ZGz+Ti8vIgp87COTUaLR5SLnxGeXWajWsr6+j3W5jbGwMuVwOwWAQHo8HdrsdtVpNPDG5ymKxiEqlAq/Xi9nZWfHc/DNsofXRJ42O2Wzui3L0KRSfkweVc0UDTONG3pORQLvdlu/h9w6LkOgICO6xTCaDRqOBUqmEzc1NlEoltNttJJNJFItFjIyMCI/80EMP4fbbb4fH4xHqJJFIoNPpwO12C8fI7IEpoj59vBC5XE64P7fbLfvLYrFIhM313djYQCKRgMlkgsPhkIPscrmEblIURVJ4Rr/8DO4vcvfDsjw6OK4f6ww0PKw/6A0CP5/GmueB606jwnVkus/98VoyKX4H55fZj9vtFmPr9XqFhyf9x/Gz5sP5oBF2OBzyvFw//R4l174dePb4fABkjBaLBfF4HF6vV/YfqaJ0Og1N09BsNsWx0kGYzWZMTk5KgHhhPYLfN8xGABcxuul0+gc2a6FQ6EuNaRz1PCojBEZPDz/8MHbt2oWpqSnxgKqq4hOf+ARuuukmxGIxMVRM3RhlbgdyQ4yk9AdXn9bSgOfzeSmoTE5Ool6vI51Ow+FwSJRXLpeF8yE57vF4AJw3tI1GQ1Ly7dDpdBAOh6WopPfGLOSQHxwZGZECBVOyRqOB5eVlpFIpnD59Gvl8HlarFd1uF4uLi3C73VhaWpLNyw2sX/DtwPSPm4iRITchU1Ya02q1Ck3TEIlExGky2mD0zbSb82S1WiVt1ke2w6IkOjY6hU6ng0KhgHg8DkVRsLi4iM3NTTEYNBapVEoizLGxMTkw3H8LCwsYGxsTasTj8YhDZfF1GKfbarVQKpWk0FosFpHP5xEKhRCNRnHy5ElZgxMnTuDs2bPweDwol8tiLFjApaPtdrsIhULodDoSzbGoxIyD1Mqw+eIacI75zASNm76Iq89OvF4vKpWKzDsNar1eFwdLakX/O8Pg9XrR6/UQCoVQq9XE+ANb6X+xWISqqpiYmJB0HgCKxSKi0Si63S4CgQCKxaJ8p75oz7qKPjLVO/ntMDIyIv+On0W+Wp9xAJAgL5lM4oEHHpCM9NSpU5ibm5OzE4vF8N73vhc+n68vQ+GYyLPrn387DDW6jGT5QYx0Gfk1Gg0ZvL4qzCjD7/eLt+31elJVZZh//PhxXH311VLIsdvtcLlcQnwPQrPZFCPBB2f0zAPIAscrr7wCTdMQi8UkWisUCggEAhJZclI5eTTE+tRUnyoNwsrKCpxOp3hTFnj8fr/wiVRVlEolMQp2ux2nTp1CMplEMplEvV7H0aNHsbq6CpfLhUAgAE3TsH//fkmVGL2RbyPBvx2oKuBm5f82Gg3hs4LBIEqlErLZLCwWC6LRqBQdyakyqm42m0in04hEIvK8hUJBIhR99bdUKmFsbPv3M+Zyub7UkVFSs9mEz+dDPp9HNpsVY8u9SGfcaDRw8uRJmUez2Sz1A6/Xi1gsBpPJJBmYvgA8KC0FgEAgAJPJhOXlZVG9sNZQrVYxOTmJl19+GY8++igWFhZkj/Czga2oyu/3i8Pyer2o1WpiXLvdrmSENCAmkwnJZHLguJLJJEZHR4XqoHHVKyg4Fj4v14NrV6/X4Xa7JVKnQeba6VN9/i/Xc9i4er0eqtUqLBaL8Nr1eh2rq6vyzIVCQYy83W5HNBpFp9NBKpXCyMiI0HjAlrNqNBoSjTLD0Ef6dru9r7irB1UiPMMMEhjp33TTTThz5gzsdjs6nQ6eeOIJPPfcc7Db7QgEAvD5fHLeGcknk0l8/OMfx5//+Z9LEVo/Zj0NOwwX5XQ56cViEc1mU1JMi8WCXC6HyclJKezw35TLZYkkbTYb4vG4pE2KoqDdbqPRaOCqq65Co9Ho+xkj3otVS/UVQ716otFooNVqYW1tTRaOfJ9eJqOqqkhc+G8ZtTP65EFi8Uif3m2H0dFRZDKZbaVgrHi//PLLfWmtpmk4deoUnnnmGXQ6HSwuLqJcLsPhcODQoUN9z/ynf/qnUpikgWXkVKlUBhpdi8Ui49cfIJL+Pp8PjUZDqJZAICCe/9ixY5KOcz6YkTCSp1FklMv/z00+CHSOTOFJLVAepFcgXH311QgGg1hZWcHq6ioikQgWFxcRiUTwkz/5kwgGg9jc3EShUMDk5KTQNIwCeXD4DIOoBQCIRqNSNKQxdzgcYtwymQweffRRKfR4PB74/X50u11MTU2J5Coej6Ner0vqTGfH4MDv9/cZx0qlglAoNHBckUhEjADpJUqYVFUF5WTcE3R8DoejT5UCQBwV1QHRaFQictYKaIAvVDtcCNJMlC+SQqGRjUajyGazqNVq8Hg8ktHw58FgUJ6PgQrpHDo90je0EQ6HA/V6HSMjI9uOifPDqNpms8k4GQEze3r22WelnpJIJLB//35RZCwtLYnTrNfrWF9fl2CPWYeeMjWbzUJNDcJQo8uNaTKZEI/HpUDGhaeh1OsNmY7Z7XYxNnv27IHL5ZKoqlKpIJFI4NChQ4hEIj9Q4LgYGa2XSPG7uSjNZhMulwuFQgHJZBKvvPIKrFYrwuEwSqUSQqEQ3G63cIY0WHw2GiQ9Z6rnsIcVOri4rK6zgMCNr2kaAoEAEomEpPzpdFrkSAsLCwiHw3A6nYhEIgiFQpKqjo+PI5fLYc+ePWLUAEixa5gz4EblmPQ8FQ/q008/LdHAiRMnAPRTA9S4MnPh/NBYUN4DbBWiWK3ngdoO3W63T/ZD+qZYLGL37t0i3VpYWJBnpmxqenoak5OTOHr0qCgSaChXVlbQbDbh9/tFvsSIkM80LBphmu/z+RCNRmG1WpHNZkVCRqkTjTFVFYqi4KWXXkKpVILZbEYsFhO+1+PxoFgswmw2w+l0olaryRhoHIPB4MDIDQAOHDgg9RE+Lw8+C4+kJ7hWzBzK5TL+7u/+Dq1Wq09pwnnXNA1PPPEE/uqv/kr+ng5a76y2A2WXwJYNqNVqSKfTyOfzss42m02cOyPIRCIBi8WCf/zHf8Tx48fxsz/7s9izZw/8fj98Ph82Njb6CvJ6bpkOcFDGQhvh9XqFpqAhZ+Z69uxZ+Hw+yRy4X81mM5rNJmKxGJ577jn4/X54vV4A6CtCcix0cjwjF8NQo8u0rNVqIZfLIZfLodVqIRwOi6culUp9xLumaSiXy7KRAAj3woiJvN0NN9wgE9DpdODz+TAxMSEeYxDy+bzwToxguYEYebndblSrVezbt0+qzyxwVKtVXHvttfB6vX2Vdo5VHwXptb6UsgwCVRmFQkG8bLlcFo1mNptFPp8XKVapVEI8HkcikcBzzz2HaDQqht3tdsPn84mxpuzNbDYjGo3KwWB0P2y+mPoz2uIhI5dXKpWQTqeFq+Z6MaLQy35YdGFhQa9Q6HQ6ItWyWq3w+XxDnRSjJ0ZXnGdVVXHmzBmEQiEx6hTSF4tFnDhxAnv37kW9XsexY8ewa9cu7Nu3D9lsFslkEj6fD6FQqK9wwnXWF/kGIZlMCj2WTqfFsXk8HqTTaYyMjGBkZAS9Xk8MrMfjQTweRySy9cagv/u7vxPnOzMzg1tvvVX4VpfLJcZQnyHmcrmBY+L+Ih8MnE+xWY8IhUIolUrC2fI8VqtVfPrTn8bo6KhEs16vVwpR5XIZrVYLhw8fxh/90R/h937v9zA3N9d3poft+3q9LnQdFUI8/9zTIyMjonhyOp0YGRlBPp/HF7/4RSiKgiuvvFKknFQb5XI5fPazn8Uf/MEfoFar9ck2GQgNMnKkDfSKB72OnxQas3H92Th9+jRuu+02dLtd3HbbbUI5JhIJHD9+XOaegQudH/f0MAcFXMTostJO76mqKorFIhRFkSITJSh6b5LP5/s0lyzIUTzfaDTg8XhEL8gDS2+hl4ENGhc3HGkBfjcbOKjR5EHmcxQKBeRyOSmS6MdN40tHoNehqqo6NCUFIN/DLIApd7VaxdmzZ/ukXcViEYlEAqlUShokgK3Cw8TEBHw+n0SnjI4ajYZQD9xYeonWIFC9QXoBgESH7XYbi4uLckjorVOpFJ599lm8613vQrVaFa0pJTz6Ao7D4ZCUkAfB4/H0Vc0HzZfe8NZqNeHKTp48iVqthmw2ixdffBEAcM011+ANb3gD3vCGN8DhcODMmTO45pprRFanqirC4bCsoV51AEDmgNH6INjtduH1SVHoVTsWiwW7du3CwsKCOBen0ylOEdgy3IzEXnjhBeRyOXzwgx+UqIrOjHQAxzpsXPr5bTQaWFxcxIsvvohmswmv1ysZXjgclpQX2DovKysrmJiYkCK0w+GQzC4cDqNYLGJ6ehqlUgmPPfYYVFXF7t27pUBLWmI7MItltxifIxaLCQ00NTWFVCole29jYwNPP/20RMEMgPL5PMrlsnxvp9PBX/zFX+ADH/hAnyyL53UQ7aEP5rj2/Df8bMo6ufep1mGg9ZM/+ZNwu91IpVLIZrMol8vw+/3427/9W/zar/1a3/fQdlysXgC8xo40VmTZglqr1RAKhVAul0XGRM6s2WxibW1NdJD1eh3Ly8sSDdBj7tmzRx6SEgx919Aw6LV/nExyZTQQuVxOlAvtdluiDDoIRho0kDQgTLl5QC+Ujg1zBnqynwvJKnupVEIwGBSvWq1WpdLbbDYRiUSgaRrC4TD8fn/fhiBfR56Y49V3vwwzupwbvcGhISoUCigUCn3qAx4yNmTonS9lUHRuLII2Gg0ZJwsYNFTDVCg0JOR02QVIWiGVSiGZTKJUKmF0dBThcBixWEw29sGDB+WzyCdSW8qiBtdWLw8aZtyYgrIK3e12JbhwuVwSGXIfURXCCJPpp9/vR71ex8rKCk6dOiXO2+PxSCs49xb3zDDulGfjpZdeQrFYRDwex+Liohg8SrBYcGTWYLVaMTExIZmpPkI3mUzw+XzCF1999dVIpVJ46aWXoKoqdu3aJVreQYhGo1heXhbnpFcotdttvPjii6Jl5vlPpVJYXV0VrjSXyyGRSEDTNPh8PlGlqKqKp556Ci+99BKuvfZaycY4Z4McOs829xfXhHx1r9cTiodRLiV/e/bskb9nXQjYUmns2bMHzz//vKhX9NQo1/NfVEgzm7f6+6kxbDQaKBQKIrFikWNsbEy4zGKxiFdffRWlUkn6rclTdTod+P1+WK1WkdRQyeB0OqVVVc/ZbgfyV/rogw/N1IapGwuAFKRrmgaPx4N8Pt9XbWdkSiOnr0LqU5RhqNVqCAQC8u8ajQZSqRQqlYoUNqgaoGFh1EKdKeV2jJJ5l0EgEIDb7f6BbipGSsPGpz+Aev6zVqthdXVV+t2LxSIKhYJsuD179mBhYQGKokhxUR+ZsiBSLpdFCeJyufqkZcNAw8jogAdW0zTMzMwgHo9jc3NTOgbpTNl+zGiUvDmzJRZr9EUl4LzYn3t1EMrlsnDNdrtdJJLk/HK5HJaXl6GqW/cLsMDMPWOz2cQQcr95PB6REsZiMZFOsejKrGMYJ9jr9bC+vo5vfvOboooJhUIipwKAXbt2IR6Po1KpiJG32+3ClSYSCVGtqKoq53Bubg6tVksaHMiLO51OzMzMDHVSPp9P5jSXyyGbzUJVVTFMzzzzjOjSWRtpt9uYnJyUOsLS0hJ6vR6i0SgmJiYwMzMjEi+73Y5jx45hfHxconQWbAeNi92wDFKA8+eYc0yjy5oLi+eTk5Podrt49NFHEY/HYbVaEQqFMDExgXw+j0qlIsorCgtozFn0G4ahRpeRJw2RvuulWCyiXq9jYWFBjIWqqkilUnj11VfhdDpRrVbRaDQQDAZhMpkwOjqKvXv3igicKVan04HX6xWje2GXyIWggWRhQt99Y7PZkE6nEQ6HEY/HhdqIRqNykBRFQSwWw8zMjPTsM9Vzu92ioNDLZriQw4yb1WpFMpmUqjSwlaqePHkSfr9fjD+bDRjtVCoVOBwO+Hw+kZV5PB7hdakO4YGm8aYUSF8A3A40aKwq6+Vsx48fFxVDqVQSnS7vDQgGg8KDk0fXUzYzMzMyV0wRGelQKjcIdHiMRmkoyXnS0TBNXFtbw1e/+lXMzc31VfG50Z1Op0Si3K/k/Dk/+n08CJRCdjodidpzuRwqlYrsc4/Hg0ajIZGU0+lEOBxGKpVCKBSSM8IiLg+13W7H6uoqNE0T9QDnjJHqIGiahs9//vOwWCwYGRkR2SZ1sjReAIQHN5vNCAaDSKfTkqkwk+L+mZycFA6bUV2n08Hm5ia++MUv4r3vfe/AbAUAMpmM3Aly4sQJHD16FKqqiiRufHwcN954o+x70kjVahXT09OIRCIYHx+H0+mE1+uVjs5arSZ3fLhcLnzve9/D4cOHsX//fokyB0WVzByZEekLfTwD+m5MUklutxvHjx/HyMgIJiYmpGDscrngcDjg9XqRSCTwZ3/2Z/jUpz4l/550xbDMjhhqdBkhsXIYiUQQDoexsrKC+fl5BINBaJqG1dVV8ZpMK1wuFyqVClwuF2666SbMzMyI9yMvyAiLqSm91jChPwAhvy/sLqrVarKBa7UaNjY2cOedd4rIn96v2WxiY2NDqBG73Y50Oo3Z2VmR95BrIldDgzfMiNB4lkolaJomnJvX6xUKhoeXHXrdblcUBGNjY0JBjIyMyPxmMhnRPFOnSq0jee1h86UvtOm1hORRG40GEokEVFWVi0lo7JrNJq699lpRDXDMvV4Pjz76KN70pjchGAzC7/eLp9dzbcPGped0OceMGBhdhsNhJBIJKaI9//zzmJ+fx+TkJKLRqERCrDHoU04eJmqJX0u2AgA/+ZM/iUqlIsJ9u92OyclJPP3009i7d690CqbTaSlI1Wo1zM7OQtM0KeZlMhlceeWVorMeGRmR7jrKuGjEC4WC3DkxCM1mEx/+8IclqtW3qtPAAlsR3Re+8AW8/PLLCAaDEoysr69jamoKL774IsbGxqQg7vP58OKLL0rxWV/FP336NN75znfC4/EM1BD7/X5sbGzIbX0MhPx+PwqFAiYmJqQAxYagdruNK6+8EvF4HG63W+RczKBptFOpFObm5hAMBmG1WvHUU0/hn/7pnxCNRvHWt751oMSOOmiqDPTUx4UyQhaUga2Iv1wu45FHHkG9XkcoFOorfFqtVmmY0NdIgPMt3f/iNmAWIhgdmM1mjIyMIJ1OY2FhAXv27EEul0On0xF1w0033YR2u42bb74Z0WhULi4Bzt9EVSqVJAph6s9BM70fBKZyjPj0noreT9M0HDx4UCaHVEQ0GkUymRSejoeSnGm1WkWhUBAPy+iWHq/ZbA7sSEsmk5ibm0M8Hker1cLKygqy2Sz27t2LbreLM2fOCP0BnI9GKG0CthyK3++HzWaT+aF8jDSEvnuMqgpG6duBz8ADweeKx+NwOp1YWlqC0+nE5OQkTp06BZPJhFtuuQWJRAJnz56VOzMYUXItbTYbJiYmpJhHkFrgOoTD4W3HpS9esqrc6/VEbE+Jod/vh8PhgMPhQCaTQbfbxfHjx3H06FEoioIjR45gdnZWmnay2SxcLhduvPFGoToY1XFcPNTb4emnn8bMzAxWV1clCmy1Wti9eze+9a1v4aabboLX60WxWEQsFoPFsnU1JrDlPGKxmBQbFxcXhcNfWFjA7/7u7+LFF18U8T3PQavVkiLbIDCaJF9J+i6TyQgtEw6Hcf/998Nut+Puu+8WtYPVasX8/Lxw86lUCk6nEz6fD48++qhIolgv4R0YNpsNb3/727G2tjZwXC+++CJcLhe+9a1vYWlpSc4zr3ZcXl5GpVKRAh8phvX1dbRaLSmy6ZukSAOQRkwmk0J3dLtbV3/+yZ/8Cebn57fN8iwWi6iIGJgxg+Z5ZrCi7+zsdDoIhUI4efIk9u/fjyeffBK9Xg/T09M4dOgQQqEQKpUK7rnnHvzH//gf8Yd/+IfStAQMDzKIoUaX0hJ+GA+J3W4XKRYbGfS3ZMViMWmaYNGABQ7er1AsFhEMBqUFkDKq11KNv7DSq+/S0usAaZgcDgdisRhSqZRoA7vdLpaXl+FyueByuSTCu+mmm4RXrdfrffQFo+VhYMHnueeeQ6PRwDXXXCMHglcDstpeLBaFj67X64jFYhgdHZU0m3w1OeGxsTFxfmzsYBYyrNDBFJbPzQJBKpXC+vo6Dh06hFQqBU3TMDk5KWk/I+uvf/3rGBsbw+joqDhFcpFf+tKXcOedd0qkoufYeZ/GIFDdQlkio/BUKoWxsTH5TOo0acTJZ5L+In/JYsn4+Li0lOoduf5ADFvH3bt3i/qF+m069re85S34sz/7M3S7XallVKtV2ZOKoiAcDqNcLiMcDmN1dRVmsxlXXHEFNE3Dz/3cz8HlcuH3fu/3hGLQz9MgRwBAJHrkiynDZObH+2HJ3zscDgSDQVHBeL1eZDIZAFvdgG63G+FwGLOzs9IdyKCFFICqqhgZGRm6v7rdrkSGgUCgT7vP+QgGgzKnkUgEk5OTMJvNWF5elnPY6/VEepbP55FOpxGNRnH69GkJrpgdhMNh2O12KV5ut7cuDAS4HwCIpplnkjh9+jRUVcU999yDVColNAQAaQ0PBoOYm5vDww8/LHter+kfRvUBr6GQxiIKNxYH7nA4MDU1BQB9+ky2ALPLiJIhffUc2JKZ0LgwpdbrKYeR0Syi6KuF+use9YeYOkVSGWazGeVyGbOzs30RIgtgbGlmJZkpM4tzwzrlqIT43ve+J1QD50TfiURvS6E1C1GBQEBalPWqimAw2Bex6Q8msxA6x+3A3n7y8eVyGYlEAvF4XKIam82G06dPS7Hj2LFjorDI5/Mi8mdBgRwci6pswGAkTdpoGFjooRidz8uoxGazSVHL6XTK+urlP9PT07BarZJBcc31lxzR2OodwrBmkmQyiVgshomJCVlvass3NjZQKpUQi8Ukmut0OqL6iEQiKBQKwh2OjY3J2lPvGQqFkM/n4fP55EyxQJpOpweOS9PO3+RVLpdRKBSkRVlRFORyOZTLZbznPe/B888/j6WlJdRqNYyPjyObzWJxcRFerxdXXnklFhYWhIvc3NyUYIXnlJSU0+mE3W4f2MoNbCmRWFR3u91y+XmtVkMwGJSzx+yyUqkgnU4LpXHixAlMTk5K4xIAyfJ4oRadgf5mPF7ifzEwi+YcU9vu8/mksUN/XwXPud/vl5sA+T28o8Lr9eL6668Xx6e3V/8ieoGeNZlMSqrXbreFR6QAWc8x0iOxIMLNR8PFkJ7UAGVkNLj6AzJsEvn3F/bTc8Pwd/gM/D3qKqmgyGQyqNfrcp0fDQgrwoxu6cEuFul+5zvfES4bgBh/enmz2SyyO73qotfrYWNjA+Pj4/D7/aK82NzclJZEFrKuvvpqWQM9iT8ITKupXy4Wi8jlcmg0GohEImIwaQCZOTCy4H2nNpsN2WwWqVQKk5OTsl7z8/M4cOCASG703WvDoHeadJa8MInPo28EoCFmkWtyclIKffw9fbNIrVbrM9bcW2yaGAQGEcwQaOyoOuBeZ4GKlyBR/sTAg9EhI3HSSMx6WHjhedHfn7Ad2BbNoIBrphf2M3KORqNynSo/98orrxQ1Ed/KEQgE+u4dVhQFoVBIslJq6cfHxweOy2q1YmxsDI1GA9FoFF6vVy5F8vl8olkGIMX2xcVFeDwejI+PY2ZmBvl8HslkUi7c4dzb7XZkMhm43W5UKpW+e3HZubkdSI1y3zCIYgbMcetrSQwSmRkwGPJ6vT9wMxwAhEIhvPDCCyIzIxvwLzK6JpNJbuvXc036+w44kTz4PKycMBpqcjn8feoqnU6nTPBrIaH136/3ToxEmV7Rq/Fg8/dYuOp2u2Ig9NxiMpnE2NhYHzes72IZZkiWl5fx4osvStFQr0PlAaQxpUHjz8hTkTem7CibzQofyQiYsjv92yzY3jkIfMMDNcPkEGlQyR3TGdDY6jWuXq8XqVRKqAoaZ1IU7NijA+XYBkHfsKGX7env6WABjBctsSCpaVst1eQr9eoHOkh9tMuf6cXxg8CiITWvrAdQGsUmHqfTKekp9zC7svRFRb7pwu/3IxqNIp/Pi6PQUzLUtg8C230Z1ZP312cUPp8P1WoVsVgMtVoN8/Pzws3GYjFsbGwAgOwfUhDcEzabTXhTjqdSqQyVsnU6HUSj0b6x0fGUSqW+bi3eslcsFjE1NYVIJIJgMIj5+XmcOnUKHo+nT4KmfwkCjSfXj3MwaEy0J1wH4Lwd4F7RR8H8exb52ZpN2SyzGe4nRu98Nv33DMNQo6soCjKZjGwKpn30GiShWc3mv9G3qFLwzkniIWLVlZ5LT0S/FsMLnPdmnGS9mkHfcaJP4fTdajT84XBYLtcol8u46qqr+jgpjnuYnAcATpw4IZNOh8AxMmK6sMGCnpbcMdN+tp2S6+Jre0wmExYWFhCJROReALabDgIPJrl06kODwaBcKGI2mxEOh/teB8MuODoqn88nF4jrW4OpidZvbGKY0WXUQYfMz/T5fMhms30XWVPbrCiKXKzC9eEF4Xpjyj2lvz/gte6tUCiEeDwuCgpSCOwU1GcsPNwc39TUVJ8O2+v1SkWekVmpVOrj2PVG92JNLnw2UjLcpzQWdMQ+nw+VSgXLy8uiiuh2u0JfsN5BGoz0IaN1Vvn5h/Wa7VCpVDA5OYlyuSzOkwomvk+O+4O1A8oJm80mTp8+3Zei06kxkBodHcXm5maf5pYR+LA2c2YEej6Xa6e/CEsfPDKAYY3J4/EIlcEAjfus1Wrhuuuuw/j4uOwrSvGG4aJ3LzBF42Fkus2ottVq9ckwmL7oO5v0D0TjwjRfb3iZBl6s3dZkMolEhulkr9cTo0ojw4nj5POA05AyQgHOC6UZmfCQcrK5MMMmtNvtYnp6WrqTmPZ1u13h3Vjk47isVqukMEwx6XmZBfD2KfKnHA855wvvi7gQPFzFYlEkey6XS1Li9fV1SUFJH/HCIjpQvXMkr8YqOCv13Bd6AziMjmFEzP3D9YhEItjc3ARwnl7wer2iIeZBo5PVt/kypdSnuNyrwHmnPixj4TyR92MdgDpnjpkZkF5SyUv5SYMwYxgdHZVL1fnZPKj6iGtYwapWq2FsbAzdbleMJKM9Gi0WppvNJqampqCqKr7xjW/IepLS63Q6SCQS8Pv9CAQCoqKgooeX+PDzhjmreDyOWCwm+7zZbCKRSEj9YX19XX7O2guDiHQ6jeXlZdx8882YnJwUZ8D9XiqVcPr0abjdbhSLRXHMel39dmAgo2+SoJOn4WV2qy+Uezweae+maobdfvV6XfZTpVLB4uIifuqnfkoyA9qIf1EbMC+WYTq7srIiFXcaC0bAvP2d6SoLa9x43Ezkw3i7GA80D6ieYxkEffRDr0hZDotmdBKcTE6u2+0Wp2CxbF1Pyaiu1+vhqquukq4XfeTGA91qtUQTeiH4xlE+GxeCi83v00f2AKTowCiOzQJ8Yyw1yHv37oXL5cLc3BxCoZBEFBfrZGo0GqLO4FWE5Jw5HlJJHBspBz3/SeNFBQoN6/j4eF/LLR2KfiNuh0gkIpE3r+DTS+JoVGhgaNjZGRmJRMTQ6PntQCCAyclJWTu9IaOhHOakaJhpkAqFAtLpNBKJBFZXV6V7kFEtiz3kTz0eD0ZHR7GysoJ6vS7zwfshGo0GisWi0DHcC3o6bDt4PB6sra3J1ZOsYbBwTM0qO7nY8DA9PS33KKiqiqNHj8pFVdxbdMbxeLwvQ+V5HHb72ZVXXol6vY5EIiEUUbvdFhVJqVRCLpfDzMwMgsEgpqamcN111+Gf//mfoWka3vzmN0sRkDYllUoJt2q325FKpeTmOtaQzGbzQCmb3iYx6CIlQLtBDpyBFwPKTqcjiiruK6qFWFh+5pln8Pu///t9OmF93WoYhlq3crksGzscDgs3RUOSy+XkQHa7XeloajabIoPRX57NBgp2d/APo1+9gH1YWrq0tCS8K3+PB5yfR46KBp28IQB5kwAXhf+eLclsvOA9AxcW0waBKg2+WVVfaOTnr6ysYHJyUvg8FkIYpfPuCEaZMzMziEQiwr/Ozc1JysODdzEuibwwKQJGr61WSw4KnQKAbS94oS6Uho8VX/19EFR+AD/4Kp7twMvoud6M7FV16+IaFqVouGh4zWazXLJCJ05HzGiRKTL3ANdf3/AyCA6HA5FIBJ1OB2fPngWwdVdyt9vFm9/8Zjz00EMIBoMSnVerVeTz+T55Ja8lHB8fl7eEvPDCCzh58iSeeOIJ/OZv/qaku1SV6DOv7cCUm/QQU+xeb+uNwBxPuVyWt7GwaJXJZMR4LS4uSoC0vr4u1BTlV+12WyR3kUgEPp9vqEqAdoDrQEO9vLyMyclJjIyMyB7iWbfZbLj77rvxt3/7tzh16hR+4Rd+Abfeeiu+9a1v4eTJk2Loe70e/vN//s9QVRXHjx/HE088ISqMWCw2UJKor/PoMxu9AobBA7NKq9WKUqkEv98vcsXJyUn5PWZOi4uL8Pv9cDqd8tms21BAMAxDjS6jDrbP6gsUPHgXpljc6DSIuVxOXufCC6H5gExTacT1nO8wo0vxub5Qopd36SkCcsf6K/C4SViAoWRqYmKi78Vz/Dt9IW3YuHj9IO8RZqrN1K9cLsPn8wnHyMJXtVoV6U8sFhOJmNvtRjQaRSQSEePGOdIrQPQ35G8HtopSXM9xlUoleZ+YXmfaaDSkMwk4r3lkVEXnyeiUnwecjxK5GYelpXSCnB9WielwKG6nYyctwz1Gw06OlNwbjRGpEP14yLUOo4nW19elwYL0Fwu0L730Ev7dv/t3uP/++6V+wT3rdDpl3KQl2EK9tLSE5eVlrK2t4XOf+5y8ukqf6lKzPAi8fJ8vXGQXFeWZLPYB5zOY2dlZ/NIv/RIsFotcdkOeU9+UYrfb5RIcRtDAFnXw2c9+dqgkcWRkBIlEQt76wgCDxttisUgXXzgcFkrA4/HgQx/6kDxbt9vFvffe20ejAedpKN6hvLGxgWeeeQanT58W53AhuCd5fvU62na7jXA4jHe/+9147LHH5ObEQCAgTov/JpvNynyw2L2+vo7f+73fk/HR4DLI/BfpdHkbvl6fC0AKUaxgXxid8mc8SPy3NHQ0IPqLwvW4WOTGzUouk5+hjyiDwSCy2axsKo6PBpFKBEraeFD51gS98Fw/ucOMG3C+gMYqOz+HHpB92ZTjcLOHQiGp5rJXn8U0vWPS89PkhBVF6XvH24UYGRnpS6NYTKSucmRkRGgWGiNWxplKA+fvc2WKTKE6HSjHQoNHgzIIrCDTeOizAzpm0i78fQASZbMgwn1IDe0tt9wixpv0DIMFfs4wZ9Dr9XDo0CGhNXq985cU0eCxwYWfxXkKhULyyqN6vY7FxUXpqMpms/jwhz/cJz27UAc+bH/x1j6+zojFXzp4GlOeCb2aiNkD15CUCx0K552RKtfO7Xbj137t14bylLyHRS/LYmTbarWkG01vjBRFkTdJ6Gk4fQbKAh+blEglzs7Owu/3Y21tDV/5ylcG7i099UQlhNVqxdraGkZHR3+gkMksyuv1ylunmdnVajWUSiV5/RQlm9wvHBvrSMMwNP9jhwony+v1ynuNaPn1HIZeSkaDo//DFFDf86yPbPULPmyRWcXXR2I0oKQY2HLIy1624wX1RUDyqRdK2/STqq+eDgInvNlsityI80IuXD9m3mA0OjqKiYkJhEIhMdj8PXKCzDT4eUzV9MWA7cC3spKf4h9GwIFAAPl8XgqnTOcp8aGRpuFh+m61WuWiIr08h4f/YvPFIigNBflNOutgMCgFSXKFwPk3Fet1lozc0+m0OEsqP/RV/9eiRDGZTPIiU0b2vEWNF4UzlaRT8Pv96HS2WuFZeAa2DNLa2hoajQbuvvtujI6Oyr4lHUBOlgZgEFKplDgcvaGioQDOR4x0RORlCT23SSdJJ8KoUL/f9RTJIPh8Pqmp8N/r2925rnRYPNtU8rC4xjmhEqPZbMrbJ/R1C5Np6zKlkZER3HfffduOSS9B5LMwgOQdCsBWkERHxvHydjRy3bych81C1FqTFqJT09Nzw3BRnS69lclkki6N7dJGLiy9ir5AAEAKObztSx+hXmicgX7Z0XbQv+tJv1GZ5mmaJlEkJ1QvJyL0F3zw8hF9pHChMbnYfHEseg5Y/yJFyrOoHOBViOyuIU9Ew8Jx02vroxq9xnNYREnjpL8Vi3NM1QSjLL0Mj1EHD69e7sb5cblc8Hg8P5CZMOoZZkT0GlP9jXbca/p0Vb/OjFoYbbARQm/AyfVy/fTKmYvRVx6PB5ubm9ICSoegj4r02li9CqPRaMgVigCk7Xbfvn04cuSIfIa+Yk6w4DoIpKH0ckd9Ff7C+gANMrl2Ghz91Zb6c6EvSOrPJiWLg6C/RlJfwWcRjMGP3vDpgwp90ZTrq6pbbwzh95JyYpbH77vuuuu2HZO+iK7X3NNAkj4Mh8NiWPWdmyxu07AycMtkMqJl5/nWR+m8vW8YLnqJOReOaRQXmsb1QqOnpw2YuvR6PayuriIQCIg6gFGu3jDzv/k9g6CqqhSr9OPgBqaC4sJuNP0BZHoTj8fh8Xhw8ODBvqsP+bv6CQUwNKLkwbuwUEOPWyqVRIoSDocRCAQk4uKc6r25vsFDn7Lr6R4+zzCHoOc0+XuMsu12e99F5Pw7plo8xPqCFPeEoijSuafXwXLMF6NjqDKhweVz0TjS4LGXn3uLERqlUkz/aFD0/COzKn3RVT+H24EZHg8sD56iKMIfs27Az6PhoRyMb0Bot9u4+uqrceONNwodxmfhwQfO3ys97BXsNptNaBU9H6tpmvDfTHF5U5fT6RTNM59Db0zp0CgX1DdscB00TZOIczskk0kJcjgmyqjIQ+sdA/cr2/mB88afa8tCKI00o08AYnR5ac12YISvp0f1dBSwZZD3798vLd6k/PT7nHPRarVQKBSwsbEh0S3nkcEFFVMXM7pD6QV9YwHpBC7shdpaHmYOkhuwUCiIh2a0pqcWLixoXIwP4XdwgfUUB3lKGjL9K2T0HCQNxfr6utz8RUWD/gYzgqnKxTrSuNkYcTDy4gabn5/va3NlIcbhcEgnDyMYfpf+7toLddLcdPr53w7lcllugAPOV3C5+Z1OJwKBgKTLrKTzAPFQch5IQZCjpuGgYSe/frFCGvfIhc6bm9nlcmH37t3weDx9TTV8/l5v607lfD4vRoHXYdKB6fvt9QdwGDY3N/vSRRpDHrB8Po99+/YJpcF7B0gn8Za5VCqFWCyG6elpoZtIJVAmx6BEL1caBBZB+eyM0Lgv9FQdL7ynGoZyR31GQkfHNdefF2YdzCCG7a/9+/fD4/EgEonImgaDQZFTsdjJ+gl5Zl5zyfqEvgZSLpeleMnsR98A1Wq15EWX20FPOwEQqSTPF+ebErVsNov19XXE43F0Oh1pfOEZaLW23hNZKpWQSqUk2uXc8mWc1Wp1YGsycdFXsAPn+Ud6qlAoJGG/PnLkgaPRpUFlNTccDot0idGH3mvr+aRh4EUoNIR6eRKrj7xViVELIxM2LnBjzs7Oyiu76e35OYyM6GAY2QwCXyPD19+wyaDX6+HEiRO44447xMDpI0QW6riBKBy3WCyyUchDMkLVN3uwoDIIvDeYm4jPxFSq1WrJm2v1xSrOKQtFdGzZbBbVahX79++X3+HnkYoAIHM2iA+kc2MUqlfHsIhYrVaF9tE7A6/XK4YiGo0COH8RUyKRwI033igRrz5jY0Y0jI6ZmJjAM888A6vVKvQPo3JN27o3YdeuXXjllVf6btQKh8Nyq106ncYrr7yCW2+9FXv27BF5HeebxlZfHK3X60OvUFRVVd7orOfDmWFks1k4nU5x+HzebDaLkZERGTu5dqbMnE86706nI0VNGqe5ubmB41pYWECj0cDCwoLc28CL2vmmDRY26cRZN2CzEN8FSHtAI5tMJrF7927kcjk5N7w0h3t2O9jt9r5Le7rdrujeec7p8G+++WZ4vV4cO3YMwFaAyYvoSbP4/X6Mjo7K/b/6ez1IQzAIuZhjV4ZFbgYMGDBg4PXFa7tK34ABAwYMvC4wjK4BAwYM7CAMo2vAgAEDOwjD6BowYMDADsIwugYMGDCwgzCMrgEDBgzsIAyja8CAAQM7CMPoGjBgwMAOwjC6BgwYMLCDMIyuAQMGDOwgDKNrwIABAzsIw+gaMGDAwA7CMLoGDBgwsIMwjK4BAwYM7CAMo2vAgAEDOwjD6BowYMDADsIwugYMGDCwgzCMrgEDBgzsIAyja8CAAQM7CMPoGjBgwMAOwjC6BgwYMLCDMIyuAQMGDOwgDKNrwIABAzsIw+gaMGDAwA7CMLoGDBgwsIMwjK4BAwYM7CAMo2vAgAEDOwjD6BowYMDADsIwugYMGDCwgzCMrgEDBgzsIH4kRldRlGVFUeqKolQURUkqivIpRVHcP4rv+nEeE6Eoys8qivLcubFtKorykKIot1wG4/qgoijHFUWpKYqSUBTlk4qi+I1xbTsm/f7KK4rydUVRJi+DMf3EBT/7oKIoj1+qMenG0Tc2RVHec27e3nwJx1TR/enp1rOiKMr7Xq/v+VFGuvdomuYGcC2A6wD8wY/wu14rLrsxKYry7wF8AsBHAUQBTAH4GwDvuITDgqIovw3gYwD+AwAfgBsBTAN4WFEUqzGubcH9NQogCeCvLvF4fiygKMoHAPw1gJ/SNO2xSzUOTdPc/ANgFefW89yf//l6fc+PnF7QNG0DwEMArvhRf9drxeUyJkVRfAD+GMBvaJr2ZU3TqpqmtTVNe1DTtP9wCcflBfARAL+lado3z41pGcC7AMwAeL8xrsHQNK0B4IsADl7qsVzuUBTlVwH8fwDu1DTtyUs9np3Aj9zonkux3gbg2I/6u14rLqMx3QTADuArl3gcF+JmbI3ry/ofappWAfANAG+9FIPC5TuuPiiK4gTwbgBPX+qxXOb4f7AVdLxF07TnLvVgdgrmH+Fnf1VRlA6AIoCvYyt9vtS43MYUApDRNK1zicdxIcIYPK5NAEd2eDzE5TougvvLBSAN4M5LPB7g/JgIK4AXLtVgLsBbATwC4PilHshO4kcZ6f60pml+TdOmNU37dU3T6j/C73qtuNzGlAUQVhTlR+n8/k+QweBxjZ77+0uBy3VcxE9rmubHVjT+mwAeUxQldmmHJHvef25sv36Jx6PH/wNgL4D/riiKcqkHs1MwJGOXFk8BaAL46Us8jgvBcd2n/+E5tcfdAL5zKQaFy3dcfdA0ratp2pcBdAFcchXKZYwkgLcAuBVbxeP/K2AY3UsITdOKAP4IwF8rivLTiqI4FUWxKIpyt6IoH7/E4/oIgL9SFOWuc2OaAfAFAOsA7jfGNRjKFt4BIADg1Us9nssZmqbFsWV471IU5S8u9Xh2ApdbWvt/HTRN+/8URUlgS772PwGUATwP4E8v8bg+rihKFsCfA9gFoATgqwDep2la0xjXtnhQUZQuAA3ACoAPaJp24hKP6bKHpmmriqLcAeB7iqI0NE373Us9ph8lFE3TLvUYDBgwYOD/Ghj0ggEDBgzsIAyja8CAAQM7CMPoGjBgwMAOwjC6BgwYMLCDGKpeePHFFzWz2Yx2uw2TyQSr1QqTyYRutwu/349OpwNVVVGr1aBpGjRNQ7fbhcVigcViQTqdBgDY7Xaoqop6vY5arQaTyQSXywUAePXVV+F2u+Hz+WCxWNDpdNDtdgEAb37zm7cVTD/wwAPa6OgoKpUKHA4H3G43Op0O1tbWMDk5ibNnz8JsNqPT6cDtdsNms6HZbKJUKiESiSCdTiMWi6HX68mzdbtdrK6uYnx8HKurqwgEAvD5fDCbzajVaiiXy7DZbPD7/bjtttu2HddnPvMZbXJyEu12G3a7HTabDSaTCX6/H8ViEe12G61WC06nE71eD51OR+bMbDZjaWkJNpsNgUAAqqqi0Wig2WzCbrcjlUpBURTYbDZ0u12YTCbY7XaYTCZkMhkUi0X81m/91rbj+u53v6v5/X4AgKqq6Ha78p21Wg1OpxMmkwmNRgNWqxWapqHVasHtdqNQKKBQKMDr9aJaraLVaqHX6/WtYb1eR6FQgNVqlTlrtVrQNA3xeBy//Mu/vO24vvWtb2m1Wg02mw02mw1msxkmkwk+nw+5XA4A5O+q1Srq9a1eFqvVClVVsbm5CYfDAa/Xi0ajIeMzm80YGxtDqVRCvV6XeXc4HPB4POh2u9A0DW9729u2Hdff/M3faNFoFL1eD263G7VaTfZMuVzG7t27USwWYbVaUS6X0e124XK50Ov1UCwWUS6XYbVa4Xa7Ua/X0Wg0oKoq7HY7Go0GWq0WAMDtdsu5cjgcMrf33XfftuP62te+pjmdTqiqCqvVim63i3K5jHq9jkAgAEVRYLFYZI2bzSZarRZMJhMcDgfS6bQ8u6Io6PV66PV68Pv98hnFYhEmkwmKosi/d7vdaLVaeNe73rXtuO6//34tEAjA7XbD6XSi0+mgXC7DZDIBADRNQ7PZhMViQa/Xk/MNbNmGp59+Gg888ACi0ShisZjsH7vdjieffBIejwc+nw+NRgONRkPO9TXXXINrr70W733ve39gXA888IA2Pj4Om80m/4Z7zO/3Y3V1Fa1WC6Ojo6jVaqhUKrKn8/k8AoEAstksTCaT2Id6vY56vQ6Xy4VWq4VWq4VisQiPx4NAIACHw4F6vY6NjQ188IMfHNjsMdTo+v1+VCoVuN1uWVCLxSJfbrFYEAwG5RADkIXsdrvweDxot9tQVRWqqsJms0FRFJjNZlgsFpTLZZjNZsRiMVitVrRaLSiKArvdjmGqilarhVQqhXA4jEqlgnw+D5fLhZGREZjNZvh8Pvh8Pnz2s5/FLbfcglAohFQqJca3VquhVqsBAJxOJ9rtNjY2NrC0tIT/9b/+F9797nfD4XCg2+2iWq1C0zR4vd6+zbIdfD4fyuUyqtUqwuEwrFYrarUaCoWCOBOXy4VSqSQHzGKxwGQyoVQqoVqt4h/+4R/w/ve/HxMTE9A0DaqqwuFwwGKxiCE3m81oNpswmUzy3zzI26HT6aDRaMBsNsPpdMrB6PV6sFqtcDqdKBQKcmA1TYPNZpP1dLlcUBQFDodDDpLZbJZ1r9Vq6PV6CIfD8nMa8ZGRkaH7i8afxtbj8aBQKMDtdiMcDiOXy6FcLss89Ho92SP8DO4ps9kMTdPgcDjkoHm9XmSzWZk7/ZwMwsjIiHxmp9OByWRCMBiEw+HArl27sLS0BJPJJIa8VCrhsccew9e//nUUCgWUy2UEAgGMjY3h1ltvxf79+6GqKnK5HGw2G3K5HMLhsDgAHmBFUTCsMcvj8UDTNHHYdrsdDocDmUxG1qzRaCAUCsmaAICiKKjVarBYLFAUpc/w2mw2qKqKdrsNAOh2u7DZbOh0OvL3zWZz6HkcGRmR9dA0DVarFS6XC9VqFWazGV6vF5lMRvaF2WxGr9dDq9VCPp/H/fffj127dsHpdMJut8Pj8aDX66FcLmN9fR0+nw+pVArj4+Pwer2YmZnB4cOHJQDZDjyzuVwOXq8XwWAQABCPx5FKpWTfcd/TaQJb9oVjN5u3TGSz2ZRgs16vi3PnHi4UCqhUKuLEhmGo0eUXMYrlwebmbjabSCaTfREwH5gRZLPZhKqqaDabYmS48NVqFbFYDI1GQ6InHkAu4qBFZlTscrngcrlksR0OB3w+H775zW+iUqngkUcewezsLObm5sR7ciPFYjFomiYR++LiIlRVxT//8z/jnnvugcfjgaqqcgCHjQk476QikYgsYrvdhsVigdfrBbAVFTocDjidTrRaLdmIvV4PjzzyCCqVCh566CG8+c1vxqFDh+B0OtFoNMQgXrgRKpUK2u02JicHX93KLEJVt9gkHqZqtSrGnB4dgPweI0S73Y5erwdVVeV3GA0xovJ6vbBYLLL+JpMJbrd7qKNqt9sIhUIyJs6DPisym81i9LkH+ZlOp1OMh8lkEgPCtWq324jH41AUBT6fDy6XSw58qVQaOC6v1wubzQaXy4VisYhCoYBer4d6vY5EIgGv14t2u42nnnpKMhG73Y57770XqqqiVCqh0+mgWCziiSeewHe+8x3s3bsX73jHO2Sve71eeSZ9NMWDvx3Gx8eRzWbl+dvttuwfk8kEp9MJi8WCdruNdrstTptnpVariQPn9zCQslqt6PV68vcMCnq9HjY2NjA/P4/3vOc9246r2WzC5XKh0+mg3W7DbDbD4XCgXC5LhMvInFBVFeVyGZ/73OcwOTkpGYLX65Wz4XK5cN999+GBBx5AMBiExWLB4cOHsWfPHgQCgb6zcCGCwSAqlQpisRja7TYqlYqsE7CVLVksFlSrVdRqNbTbbSiKgna7ja997WsyX+9617sQDAblmWq1GhqNBhwOh8wZ19RsNoutGIahf2u1WuXLWq0WOp2OeEBODBeWHpgG2WQyibFuNBpyMEwmkyxOt9tFIBCQz+TfK4oiB387zMzMIB6PyybVp0rBYBDVahVXXHEFLBYL4vE4FhYWUK1WccMNN2BsbEwiUpPJJIalVquh2+0iEolgfX1dnA0dAY0vI4Lt0Ov1QNqDkQsjWUZWNpsNdrsdtVpNUs5OpwOLxYJarQaPx4ONjQ3k83mZb/49MwaOrdVqoV6vIxqNDl1oGlUaRQASuTDD4HNyLuPxOB566CF4PB689a1vlcOkN9yqqqLVaqHdbsPlconh4Dpy/QehVqshGo3KZ2qaJhSCzWaTbMhms/VRV8DWQXc6nRIZ8nv4HESn00EgEIDL5ZJ/S9pg2Lg0TUMkEkG9XhfDTufebrfx6quvQlEUVKtVbG5uQlEURKNROJ1OeDweyaR8Ph9qtRrOnj0r0bfT6ZSzxfnmnA6LwHlOOB46PJfLBafTKQFLvV6H2WyWiNVkMqFaraLdbsPhcPQ5Tz6P3W6XPcvscX19HQsLC1hZWUGlUhk4LrfbLc6Sma3dbofT6US32xVDpD/TyWQSX/7yl9FqtZBMJnHw4EGkUim02205y4VCAalUCo1GAzfccANmZ2cxOTkpBtdisQzcX1NTU0gkEsjlcuJIeMY9Hg8ymUzf+cvn81hbW8Pa2hpOnDiB8fFxJBIJNBoNOb+0Yx6PR4IhTdPk2fS2bxgu2pHmcDhAXpcPyDRI/2U0RjxsvV5PHpKpEOkFRoCkLcj5crDDDBuAvnSl0+lINKR3DNPT01hdXZV0lTwNU2t6Nh5mbmgexmZzq7mJHvG1GJFCoYBQKCSLY7VaxSgwQgsGg5K+kJvjwpnNZlitVpRKJTmIdE76RdVzwZqmScozCKR2eMg7nY4cMAByYDgf6XQaL730Eubn52G32zE9PY2JiQm8+uqrWF9fR6fTQSwWw+HDh1GtVuF0OmVt6Ty5J4bRHlxzrgnXj0aFG91q7b+bnIbFarUKzUUnoGmaRHuNRkMyIe4xrvMwJ8Uopt1ui9FiKq9pGhYWFoTLJRXW6/Vgs9nEEdAA+Xw+2Gw2JBIJPP7441AUBUeOHOlzEvqAZVhmUCwWAWxRADTamqbJd5TLZckmuZ6cE2aarVZLol9gy5CTp6zX60ilUhKkFAoFrK6uYmNjY+g66g24vk7CDJipOseSSqXw0ksvYWNjA4cOHUImk4HD4cD09LREjzabDfF4HMlkErfeeituvPFGRCIRWWv+GeSkmL0ySwQgz95sNmWu6TBMJhPK5TLOnDkj9A2fSV8DsVgscpb0RpfPyu8YhqFGl5EkDwMHR76OxoiTyX9TrVaxurqKSqUiRmJqagpOpxMAJNLz+XzCjZBvo8EddiiYhtAYsZhGot1qtaLRaEjU5fF4YLfbUSgUoKoqqtWqbG4eQh5KfTpGA8IUjM8/COSoSHUwXeYhp5ErFosSjfD7aKD5O/y5xWIRPpZZgL7Y6HA4AECKWttBT9vQGHDeW60WbDabGN5MJoOXX34Zr776KsbHx7G5uYnHHnsM99xzD55++mk8//zzKJVK2LVrF2KxmFBEeidAQ9JsNoc6ULfbDavVKo6HRpiGl/tH7xTojMiVLy4u4sCBA7IvGo0GbDYbPB4PyuUywuGwHFTOKyPAQYhGo+h0OigUCqhWq2JMaexWVlYwOjqKU6dOIRAIYPfu3RJN0egmk0nEYjHhDDVNw6OPPgqLxYJdu3bB7XZvG+kOoxeq1Srcbrc4YEZqrJ1wvsLhsOwRrjf3Fp0VI1BGlGazGWfPnsXCwgKefPJJWCwWjI6OYnJyEg6HA+vr6wPHxUyHBUNFUcSp22w2yaQ0TUMikcBLL72E06dPY9++ffB6vThy5Ajy+TwOHz7c58wYlf7iL/6i7PPt9vZ22NjYgM/nkzpAtVqVDIf7Ip/PA9iyNW63G8FgEHa7HRMTE8hkMmL76NjdbrcEXgz2tsuGL4ahRpdFJpvN1nd4GAEwutET7YVCAc8++yy+9KUvwev1olarIZlM4md+5mfwlre8Rbg2p9OJer0um4gRKrBlSIbxp6urqwiFQiiVSnC5XMLdkR+sVqu46qqr4HK58NBDD2FzcxNmsxmf+cxn8P73vx9+vx9ra2tiwJi+U5EBAJOTk7JhGD2ZzeahadaBAwdQKpWwd+9eObAOh0McitVqRTKZFJ6XG1EfSXHOGTEw4vJ6vX2bt1wuy5gBDE2XyX3yMxmJ0JCUSiVJs55//nnMz89LdBAMBrG5uYn5+XnMzc1hbGwMy8vLWF9fxzPPPIO5uTnE43EZI4A+5zI6Ojp0XIwOmAnw3zKCZOTAqI37LZlM4rHHHsN3vvMd/M7v/A7S6TTm5+dRqVRQqVTwzne+UyrKpGQYMPD5B6FcLgu9Q6VEvV6XqJfzOD4+Dr/fj3A4DLvdjkqlIllUqVSCz+fD9PR0nxrF6/XiH/7hH/Cf/tN/kvHQKZAbHAQ6Ya61/vcrlQrK5TL8fr9kBr1eD81mU5wQlRPM4gCgVCphYWEB6XQa999/P6LRKDRNg8fjgdfrhdfrhdvtxszMzMBxeb1eydS4dwk6rWq1imaziQceeACJRAKHDx9Gp9PB8vIybrnlFiwtLUlhqlaroVqtwufzSb2A806jRyfNQO5CMOgBzmfmzL6516vVqsyrzWaTepDD4ZDAbGNjA6FQCMFgUGguCgkYJDBAZHR9McM71OhyozG8ZkTWaDTEo5Ob5IbLZDJ47LHHpKJJ/uM73/kOCoUC3vnOdwqh7/F4hLRnyM9UdVgaHwqFUCgUMDY2JtwWDQsLJjSSdrtdFsDj8aBYLKJYLMLv96NQKCAajSKfz+Opp54SfpPSmVgsJhEwxzPsUGiahqmpKaRSKYnOmPLFYjGsrKxIxdpms8Hn80FVVZw9exapVEoMPsdNDtlms6Fer8umYTpot9slS7gYJaNPY1l0YoSZTCb7jBENldfrxdjYGKLRKACIU6Kxz2azcDqdWF9fx/z8PH7+538ee/fulZSVaoZh80UHxEhcj1wuJ1QBwSjqwQcfhNvtxs/8zM/gi1/8Ilwul0SPAPCxj30Mn/rUp/oOAWmkbrc71Hm2Wi34fD643W5UKhUkk0k0Gg1EIhE8+OCD2Lt3L+bn53H99dcjEokgk8mIosHr9WJjYwMrKyvYtWsXfD4frFYrRkdHYTabceLECTSbTTFGDC5YcB6WsejpG1JUzJgASIGPNQpN04Q2YJTHTKzVauHkyZN46qmnxKkcOHAAa2trqNVqOHjwIJxOJzY2NrBr166hQZDH4xGDw+xY7yiZAT344IMIhUKiShkfH8e+ffuwsrIiRU5gy1Cvra3BZDKhWCwKFUDnpE/5B9ExPLOkNhm8MDol9cRMgA6fzmFqagonT57E3r17+zIHfjdthX5MpAv/RZwutXH8gmaziWazKTwIH67RaOCrX/0qjh07BkVRkM1mcejQIXi9XpTLZUSjURQKBRw7dgwvv/wy/u2//bfiUck1cWLIuQzD8vIyYrEY6vU6stksbDYbotGoTOS+ffvw/e9/H263G/v374fD4cDp06dhsVjwwAMP4Dd/8zeRTCbh9/vlWVjNDoVCOHHiBN73vvfJxuGkttttlMvlgeOKRqPI5XIolUrCEZXLZRw5ckSUII1GAx6PB81mE4lEAsDWpo1Go3jooYfkQFqtVni9XvGsev6VKbnH4xFaZVi6rC9oAvgBDqrX6+FjH/sYVFVFLBbD2NhYn7TsiSeewDvf+U5JqaxWK0ZGRkTLyAzgv/7X/4o777wTb3rTm0TBMYwLZEpOKod66GAwKFVhKif00UqlUkGj0cA111yDQqGAq666SiJz6i3Hx8fx3ve+F263G3/wB3+Affv2yaGu1+tDZT21Wg0HDhzA5uYmWq0WgsGgpOZmsxnf+9738Pa3vx2RSATAVoSzsrKCz3/+87jzzjtRLpel+k7eENiKKsfHxyUidDgckmlxPS7kr/Wgs6BDJq3m9/tF18wIkZX5fD7fp5RRFAUf/ehH4XK5MDY2hkAggNHRUZFdrq+v4/bbbxf5mdfrxcLCAgKBwMBxUVpHY6Q/wxaLBc1mE//tv/03WK1WjI2NIRKJgHrjsbEx0cw6nU7E43HY7XZcccUVOHXqlES7DH70skam/9shHA5DVVVRnTBQKBaLCIVC2NjYgMfjQavVQqVSQbfbRSgUwo033ojl5WU5f6xlcc3K5TJGRkb6NO36Ogup12EYanQZPusrxNQV8iC022189atfxerqKvx+P0wmE8LhMDKZjMiy4vG4VPYTiQTe85734Kd+6qfw4Q9/WAwuPSm95LCIknxtJpORcVL+xMrryMiIGCTysV6vF6lUCh/72Mfw7ne/G61WC1/60peQSCQQi8WkQPOWt7xFGhvsdrtQAeSYBiGVSsnGqlarsNvtmJychKIoWFtbA3BeMkZqplwuw+FwoFKpYGxsDNlsVqIezrHH40EoFMLKygpqtRrC4bBUq2lsh5H35G4ZyXIdGTV6vV44HI4+Pt3j8cBqtWJzcxN+v1/4SWqwq9Uq4vG4pMezs7NyYNxut/BfwyIkcpOcd+C8XIubmCllr9fD2bNncfz4cXi9XuzevRvNZhOHDx/G+vq6ZCKkaahWabVa+J//83/ibW97G66//noAQCAQ6NPsXgi32421tTUpiNIBmUwmBAIBSbnNZjNKpZJE5G9729tw11134eDBg8jlclBVFU8++SQef/xxNBoNXHnllZiYmEA2m0UkEunTanOfDVtH0l0A5KCTR2WqTaqGDh+ANI58+9vfhsfjwa233ioa5mAwiHK5jP3792NzcxN79+6Fz+eTFLzRaCAQCCCVSg0cl75wRv6YzrTZbOJzn/sc9u7dKzpjrhUjaa/XK9p1NsZQQURDq9+33BMABnK9esdKlQf3VD6flzPX6XRQqVQkKGJtxe/3w+/3Cx3KZ/T5fH1SPb3Mj889zHYBFzG6rChns1kcO3YMZ8+ehd/vx1133SVcrKIoeOWVV1Cv1zE+Pi7dK7lcDs1mE2tra/B6vdi/fz+cTieWlpagqiqeffZZfOhDH8InP/lJCfn1iohhA/f7/ZidnRXhfL1eF26FqarD4ZC/B7a4yWQyiUAggF6vh/379+P73/8+8vm8GBmPx4NSqYTbb78dfr8fHo8HlUpFCnCkVgaBUanH4xGKIBKJSOfQ1NQUFhcXsbGxIWn50aNH0e128ba3vU0E3YVCAZqmCa9EbjydTiMYDPZxdtx8jHS2g34j6PW4vV4P2WwW4XAY9957L5588knpoGIWAmzpQ4vFIqanp0Wr2mw2oSiKUAgU45OC4noMoxf0xR7y5hwfDZnNZkOlUhGt7czMjGQem5ubKBQKfdV8fi75yGQyKRFis9lEMBjso4u2w+joqDgYt9stDRZf/vKXkUgkcMMNN8DpdCKTyWB5eRnPPvss5ufnsWfPHszOzkrhORQK4ZprrkGv18Pp06eFp2ZKy4xFr5AZtu/Js1IrygyIBUnyjMwaaaRbrRaOHTsmc6JX4nQ6HYyOjooudc+ePchms3IWaaSGFdL0XLteGUIH7fV6MTc3J5wyo3uqAJjp0Ll3u12cOXMGzz77LAqFQl9AxqBM3wyzHdLpNFwulwRJFotFggWPx4NcLodutyudqXp6pFAoYHx8HADwt3/7t3j729+O6667DgDEPukpUe5Z/vt/sXqBBzSXy2FjYwPZbBaPPPII7rnnHnQ6HXzta1+TaIASsfHxcQQCAVitVlQqFUxNTUlha2RkRNLpp556Ch//+MfxK7/yK5ienu7Tog7D2NiY6CepizSZTMK/+f1+qb4yjZucnEShUJDI7OzZs8hkMtLmmclkMDIyglQqhZmZGdTrdakGk2O2WCzCb24HFt2oAe50OtjY2IDFYsHExERf91U8Hkcmk4HL5UI6ncYXvvAFeDwe+P1+4dwYxVBGxmfVC82Zyg3jdOv1unBi/H4euFqthuPHj0vV+9VXX5XNGAwGpfONXUb6JgRgK2qkkdbLBvWynkFgNEWnyXGRg6TReOaZZzA/Pw+/348jR47AbDYjnU7D7XYjlUrB6XRKcwj1sCaTSXS2LLCSHrnY/mKGAWwVhtmEUqlU4HQ6EQgEUKlUkMlkxLHXajV0Oh1x9pSXMfInZ84/3Oc0HqROhjkpvbSL3DwNBlUbzPb0joiRLvcPO7noJDnPk5OTKJfLcDqdUvXncw6j1bjudBg06O12G48++qik4awVcD+yg4vrQkpJTyMsLCwIN6xXA3H+BjmpcDjcR59xTKyPUOdNqooZBCVunU4HwWBQ6jN8PmZdpFH4h4EAgKEUEfAajK7FYpGqOmUcCwsLeOGFF1Cv1/Hkk09KxZQey2q1SrrOKjkHGwwGMTMzI/3yZ86ckUM1MTGBI0eOSLFgEPRtvaqqSs83W2zJ9TDVYavoxsYGarUaFEXB0aNHxYuymJfL5ZDL5cQIkEtihfRilUluZhpN4Hxl1Ol04tSpU1L029zchNVqxaFDh7C4uIjHHnsMc3NzqNVqwnPTeLG1mHpMelR9t+Cw+eLz6KNQplzdbhfHjx/H2NgYvF4vAoGA3FNBJQWjF3KcpVIJtVoNLpdLKBsAwn/R61/M6NLAMMuhioUa216vh+XlZWxubgpFRWPMA7y8vCyyJt53sLm5icnJSbjdbhkjZVvcW8MMb6VSkYp7tVrF+vo6ksmk3ItBxQz3uj4C5QE1m81y7wMjPpPJJFEqx6MfE7nDYfNFBQvPY7vdlnVUFEVazrkXaWBYaHS5XHA4HJJNmc1mUR8FAgHU63XEYjGZBwYPw7h5yg/1RpDU1dmzZzEzMyNnSa8dZos9+VO2lNNWOBwO2Vu0JTR8/IxB+4scNKViQL8zZVfZSy+9hFQqJfMWiUREfWKxWDA2NibFTRbNeC4ZiPG59WdlGIb+LSvnNpsNExMTaDQaKBaLqNVq+O53v4t8Pi+byWazCY9aKpVEAhOJRJDL5bC5uSnSFUVREAgEcP3112N6ehqvvvoqTp8+jTe84Q04fPiweJFB4MSFw+G+4pDX65VIgBfgkIezWq0YHx/HwsICAGBpaQlWqxV+vx+hUAhmsxnr6+sol8vY3NzExMSE3DXAaIQc1SC43W7ZwLlcDlarVbqUTp06hXQ6jVwuJ11KNpsNsVgMlUoFe/bsEU0uZVJ0cnp6g4eARZJut4uJiYmB0hn9nOm7zhgpm81m5PN5TE1NwWq1Yv/+/chms8jn88J7ut1uVKtV4d3S6TSKxaJ0BlHRcCG/pW94GbS/gPOaZH3ay6xpfn4esVgM4XAYwNYhcrlcGB8fl25DGn4qDpxOJ/bv3y/cPw8w+b8Lu9YuRKvVQigUkguVTp06haeffhrj4+MYGRkR/pQXu5DjbTabkuKzuMlLd+h4M5mMPBvXEjgfHQ1zUuze1BsvRqNsu6VszOl0Ip/PS6BBLtrhcEBRFBSLRTQaDQSDQYnQm82mdGySXiFNNj09PXBcF2rbgfNRLwtYdBjMypjhsDuPFAINPNVGtAOMKPUqHD0/fCGoeuF5pMEk7bO5uYlOp4Pjx49jaWlJLgN64xvfCEVRsLm5KRkenT0vqmKQBkAyR712/mK4aEcaBc7XXnstdu/ejcXFRTz++OPwer19kR8r36Ojo3jkkUdgt9tFA1goFCTMt1qtmJychNfrxdTUlETRFosFgUAA6XQaMzMzQx8gn88L10YKwGKxYGNjQ6RYu3fvRjAYxMrKiqgadu3aheeffx4A5KBwYcgnJZNJScm4wOShgOGpA4tBvGWq2+1iaWkJgUAAx48fh8fjwfPPPy+XgYRCIbnkxe/3I5VKSWZBT+52uxEKhYRnK5fLUBQFi4uLeOqpp9BoNPArv/IrkkJvBxbtGBnpI0u32w273S795frOvv3798Nut+OVV15BIpHAfffdh3K5jOeeew61Wk34Z73gnk5D3ygxCIyQuKkZgVKLyiLj2NgYOp0OEokE0uk0/H4/RkZGEI/Hcfz4cczNzSGbzaJYLMqhIt/XbreRy+Vgt9tFL6vvyNoO/PfM4JiS04DooywW/Wq1Gqanp5HL5ZDP5zE+Pg6LxYKTJ09iZWUFgUCgT9/OyE/ftMJC0bD9ZbPZUCqVJELU89OFQgFTU1PCg9frdemy2rVrl4yVgYVea+/1emWPs/GENEC73caHP/zhgeMKBoPiZPRRILOjt771rcINFwoF5HI5ZDIZrK2t4ciRI8hkMuL4GazRQPPzmN3xmfVa9u3AeaGDZfGazzw+Po5Go4FwOIzV1VVEIhEEg0G8+uqrsNvt2NjYEGeRSqVEAsvMgJ8JnM/UXks9CrjIfbqMPmhYHQ4HDh06hF/8xV9EtVpFMBhELBZDNBpFrVbD0aNH8fDDD0PTNIyOjuK6667DbbfdJvzQ0tISvv3tb+Ps2bPiSYPBIKLRKEZGRvDMM8/gj//4j2WCB4FX+FEQvry8LLzkqVOn5Bq706dP49FHH8UDDzyAz33uc/jzP/9znD59GqqqIhgMSlSeSCQkGpiYmJBNXSgUpOChPyiDEAqFkMlk4HQ6MTY2Br/fLwWPqakpNJtN7N+/H7t378bc3BxMJhOWlpZQr9dht9vx4IMPwmq1ivJhamoKsVhMbkULBoP45Cc/ib/8y7/EQw89JHzin/7pnw5N/3h1pj6dZdTATr3l5WXx5lyvVColfB4NSDablTSe0dWRI0dE8sPojtHKMOPm8/mE/qGjY3QKAKdOnZKIPhwOY2ZmRnTFZ86cQbfbxZ133omf+ImfwB133IEDBw4ILZRKpbCxsYFGo4GVlRWkUinJIGjoB4FVdfLL7XZbKAQGGvpqOltmNU3DV7/6VXzsYx9DKpVCOp2Wm8hMJpO0rt91112IxWKiYSfdA0AaTLZDsVhEJpOBzWZDOByWm8/06e3S0hI2NzdFO3zmzBnEYjGh3hKJBJaXlyUzOHToEKxWK66++mq5cY6RvtvtRiKRwMbGxtB9z4uJgsGgPA8lbVdddZVcH1osFnH8+HEsLy+j2WzipZdeEtnjN7/5TbzyyiuSAVLDzCIhKRU+q75TdDtkMhlxvFTTkIJhAPJ3f/d36PV6OHLkCObm5pBKpXDs2DGcOHECu3btgtfrhd/vx+nTp3HixAn0ej25GVHfMAWcLxrqA7RBGBrp6g8NORW29/3Kr/wKTp48ieeee04OGIsBY2Nj+PrXv46pqSmcOXOm7x5LFr+oJKD2lxV2pszDIkqmDqdPn0YkEkEsFkOpVMLq6qoUKrrdruj/SCG4XC48/PDDmJmZQS6XE0/I7+52t65u+9CHPoS///u/x9TUlKRybGgYJqp/+eWXRVubTCYBbCktEokEvvCFLwifFovFJDKNx+NotVrIZDK47bbb5F7aSqWCl19+Ga1WC9FoFKFQCL/7u7+LRqOBWCwGi2XrvmK73Y4Pf/jDQyNK8q96Q6FveGm329jc3ITdbsfY2BiCwaDwWt1uF1dccQVeeeUVHD16VO4TmJubw+joKNbX13Hy5Ekx5ExH+WeY2iOZTCIUCknlmIU1VVXh8/lw/PhxdDodHDp0CKVSCe12G7Ozs9jY2IDb7cbo6CjOnj3bV4AJh8PodruYmprC0tJSn+SLBopt1YMQj8f7Lt5h8YX8P1POer2O9fV1iaQdDgdcLhduvPFGfPe735XOS653Op3G0tISDh06hFQqBZfLhVAoJEU3vfHdDmNjY8jn84jH48LvU4NKntvv9yMQCOAb3/gGTp8+jdHRUUQiEZhMJjGep06dwpvf/GbccMMNsFqtCAaD+PKXvyzF7pmZGSSTSdRqNfj9fpFPDoLf70epVOqLLnmuWDwuFos4deoUxsfHEY1GkUwmJahIJpN44YUXMDExgcnJSdFpk0YjJcKInkEZA6LtwEaPubk5kTfyylXWd3w+H9LpNHbt2iU8fTAYhKZp+Pa3v43bbrtN1p28rsfjgcvlQiqVEo6ZEk/WtS5G9Q01uux0YipD0pidHYcPH8bu3bvxv//3/5YrAEkrWK1WnDx5Ek6nUxoq5ubmJNLy+/0iNqahjEaj8Pl8F+XcLBYLcrkcRkdHUa1W0Wg0MDs7i3A4LFFZt9vF/v37hYs0m80YHR3FLbfcgpMnTyIWi8ml1KVSSZojvF4vbr31VkSjUXEWNFSMogaBHWb8XVVVsbq6in/4h3/AoUOH8OY3vxmf//znYbPZ4Ha7YbFsXfmYTqfFaE1OTqLb7eLZZ59FPp/Hm970JhQKBczMzEj0azabsba2hv379+Md73hHX6qzHchN6T0ws5dKpSJFnY2NDblrlJzfvn378Pjjj2Pv3r1461vfKpTCxsYGTp8+jZtvvhm1Wk3uDrbb7QiHwzKeYVcojo+Po1AoSIrLKIGGhxK5lZUVhEIhuTR8ZWVFNOAcezabxfz8PE6ePImDBw+iWCwim83KXbw0mJznYTpdNqj0ej3RavLQM2jgs7LxoV6vSzGNRo53EoRCIVEI3HbbbWi1WqLnJs/I/V4oFAaOixV1ivzJH1O4T1XQ//gf/wPFYhHj4+NiZLLZLK688kqcPXsWp06dwvXXXy/NGTabDXfddRfi8bhIKykd9Hq9+PjHP45sNjtwXNzvDHZoHPX0EqkCyihHRkZQKpWQSqWwtraGz372swgGg6jX60JDdDoduVeCLesshtGwDzqP8XgcjUYDzz33nETT+jber3zlKxgbG0M8HkcikcDk5CRuvvlmbGxsIJfL4eqrr8a3v/1tsSubm5s4e/YsZmdnpWjPmguf9WLnkBhqdNlRRq9DkBshP3bvvfeiUCjgzJkzOHPmDAKBAAqFAiKRSB/nxAVxuVy44YYb8NJLL0m3m76q+uSTT+KNb3zjwHHxXkvyj8ViUSKcZDIJu92O5557DqurqxI5UkLkdDqxsrIiFyOPjIzA7/dLH7aiKBgZGcFf/MVf4Bd+4Rewe/fuvmv4hqXLDocD2WwWu3btkuaNVquFK664Ao1GA4uLi7jiiiuwtraGXC4n8pRTp07hX/2rf4V4PC6OLRQKIZfL4R//8R+lw2hiYgK93tb9pjfeeCOOHDkiPO0wnS4jMz33xIIFMxd6c33kxisKp6en5X5ZFlzsdjvK5bJwwnrKAYDcxj9sE16owOD88jBNTEzA7/cjHo8jnU7D4XCgWCzi2LFj+NVf/VXRWJ8+fRoTExMYHR2VaP3AgQM4efIkXn75Zdxzzz2Ym5vrk1ENiyjppKjiyGQySKVSmJiYgM1mg9frhd1ulwtomHrTiXY6599YQg1zPp9HpVLBHXfcgeXlZSkokwe12WxyT8mwcenvkHC73dJw4PV6MT8/j0QiAU3TRNwPAIlEAo899hje+c53wul04sCBA6hWq1heXpYOOSob8vm8KHlsNhtmZmYuSscQLLzRgX/zm99EOByWmsRzzz0n8zY9PS1O6r777sP4+Di+9KUvIRKJSGGYbc56iSKzae6dQQV3BmPsjOSe4ksMyCFPT0/LtY71eh2jo6NiD3K5HEZGRuB0OpFOp/H8889j9+7dKJVK4rT1xTzauotJEi/6jjR60gu70mjV2Vc+Ozsruk7ye9ycIyMjsNlsEiEVi0UxErxvgZFIJpPBpz/96aFV3GQyKZ0kLpdLJpZtl6wodzqdvh56yrUmJiZw6tQpNJtNKeTxgHC88/PzEnVRvsRDMghsjKjVaigWi+j1tt6mwIibXUpMcfP5PFKplLzuhlGJ/g0NPJDMONLptKg8fD6fjGuYM+C66flMFkm8Xi8OHDgg6xkKhRCJROD3++XmfUZQvPthaWkJjz/+uERGNOITExNSYWcEPSyipHZUv9bkmtlebLfbEQqF4HQ6USqVkE6nMTIygoWFBUSjUezZs0fukQgEAhgfH8fExAT27dsHv9+PF198EWNjY/JWEeqa2c24HXjBeCQSkTdY7N279wfu5aXUiWoBRtB0UIxA0+k0SqUS3vSmN4mhIY/Ns8XC0TDulA0IjIxJZ5BLd7vdOHr0KLxerziIjY0NPProo3A6nSiXy1JvSafTWFtbk6zwmWeekYumuM+ojKHkbBD0RVN980A2m5XORNZwDhw4gHA4jNOnT6PT6eDIkSMYHx+XM0G5pF5PTmke50BfwB/kDEgrkYennIsF0Xa7LbUTFgJfeeUVpNNp2Gw27NmzRy4xajabaDQacjEUqVR99x2zqGGtycTQSJdREB+YXlZ/8xONAwXqc3NzWFtbQywWE6kR+685GYVCAWtra32VR72+lZdCD0I+n4fdbhfVgc1mk5vnfT4fMpmMXKZDIr5YLAoPo5d8UPcZiUTEQDOC00dEesczCOxg0stYqPVj1FQoFLC5uSmcYa/XQyAQQCaTkYOiv1RI/x6tTCaD8fFxXHvttdJZx7R3mHHjIdV3oukLhNdccw0effRRSVGZNpnNZiQSCXE0uVxO9KcAhOvjTVC33norxsfHZc7ozAaBTlAvNWIxgk4SgNxBzPX2er1YXl7GjTfeKLevMeJwOBzi/IEtR+jz+eQmLP3tUoPAOyH4hpL19XXRnvPveIDdbjdGRkbA93FZLBbJCOiw6VyuuuoqacjR329MqRk76QaB0TGfE4DozvmHCga73Y5EIiER3dVXX414PA6PxyPvjyuXyzhx4gRqtRo2NjYwNzcnPDE5ckrPht1ix7nX70fe0UEKg++Yu/baazE1NSWSsH379okTYxGOWVi325WL44HzlBiN3rDXCDFj5H5l/YKKHTaRMENj/YHviGPhtlAoSDGcbzDRSxv1skg++7+4DRg4/3oefjgfVH9FnslkwtzcHCwWCx588EFJ5VgAoVIhGAxifX0d+XxeerVNJpO8d8hqtSISiWBtbQ0HDx7cdlwUqbOIwFbdZrOJ8fFxnD17VqIURh/hcFgqu61WC2NjYwAgxTMaG3JrvOuXz8GJHmZEGDXQYLNBg8U1XoSSSCTkeyORiFzOQRkWNccU6DPV8/l8uP322yWlZCWXVM8g6Lt4Op2ORBK87GdqagrdblcaIni5CDk0RuKU3kUiEbzxjW9EuVzGK6+8gldffRW7d+/GxMSE7BlGesPGxUIE55bPQ6enl2ZZLBaR9TCCYx0BgNx2xxuvjh07hng8jltuuUXewcfOLXKjg9DpdOR+BhZ1FhYWcPvtt4ujIh3jdDpFvcPok86Gkjg6ekVRkEqlMDk5KU6BgQZ58WH7S29oGTgwggyFQhLssLBVKpXg9/vxnve8Bz6fD1/4whegaRqi0ahccvPss8+iVCrhxhtvlJQ8mUwKF02HfbE7NPgs/H06ZGZW1A97PB7Mzc1hbm6u7wYwdkGSc6W++Q1veIPs2wuLafoXK1wI0pb8d4xGqY6Ym5tDuVxGNpsVnn5kZATlchnFYhGRSATXX3894vE4Tpw4gVQqJdnzdpG4Xk88rOgIXIReYDRLKQ+pAx4OvdCenGEkEsHP//zPSwWfUQijAkYBF1b/9FKLRqOB//Jf/svAcbHCPjExIb3klKfwjt5wOIwbb7wRLpdLiimqquKJJ55AMplENpuFy+US7ovpK18DND8/j2w2Kx09bMsdxgUyYqFW02QyyetouMGuuuoqXHPNNTh8+DDm5uYQi8VwxRVXCB/Kd575/X6R+fA2tV/6pV+C1+sVI6qv2g/afABEo0jnxrEwveUaUC9rsVj6MgVFUcTAsLuLRZBPfOIT+NCHPiQtnaRDGL0MGxc3MDcsubpSqSR3LDAqZx89dcz899VqVYqWPMDHjh3Dd7/7XXzta1/D3XffjVgs1nexCQueg1CpVDA5OYlSqSQ0EQX8fAOKXhERDAYRDocRj8el0s75VdWtKzIjkYhkYsD5F3tSJ85GpGHjWl5eRiKRQKFQkNcB8QL6jY0NHDt2TKi0YrGIYDCIa665RlQh1FlzT3u9Xlx99dW47rrrsHfvXin8LiwsYHp6Gnv37u1rLx4ErjszCs4RgxByzIuLi3Lu2ayib4d+xzvegenpaRQKBekI+8hHPiK/Q7qPXYuqqsrbNC6EnuagtItGtl6v41//638tXC/faedwOPDMM8/gzJkzEhH7fD7s2rVLrjJl1kmtt77gz++8WEZ8UaPLcFn/YbyJR3+Jir4dzu12433ve5+8K4wbg2nd7t27EQgEsLKyAlVVkc1mkU6nJVpQVRWf+tSnBo5rdXVVCgk0PJ1ORy5JsdvtOHDggOhkz5w5g+effx6VSgXXXnutXMpDiQ0lZXNzcwAgvBm1ufrLjocZERa6ePu93++Xe1R53WOn0xEJkT6ipAaaHCdbkulFadi4JqR+uMmHqT3sdrukjFw/fSRKzpqi9EqlIt+9d+9eOcSkflZXV6XCTKfKdSY3/1qE4kzp6Gh43wU5PrvdLtkGxf58/l27dklffCAQgP/cXb+pVEoMy8bGhhQReWMYM4hhYOdRu93G6uoqSqUSJiYmJDPTdyORnuJem56ehsl0/nq/Wq2GXbt24T3veQ9sNhtCoZBU8ilV5FWZF/LbF4KyRTpPyhcdDgc+/elP4/Dhw6jX63j++efF4OodTCqVwh133IG77rpLzt/y8rJcWtTr9cTJkFbkXAyT/vV6PTFgNKh79uzBb/zGb6BUKiEcDotclPQZ100fMNDhR6NRHDhwAAcOHJDONWba5EyZ3Q1aS75vENhSwWQyGVgsFmlaaTQaYlDb7TZqtRr27t2Lt73tbbjjjjtEXsfsiioWtnHzOfROks04F1MwXJReuDBs5iTpFQwApDJIY2yz2ZBKpcSwuN1u4Wp4F0On08GLL74Ii8UinAmphV27dg0c1/j4uFwJl81m4fF4cMUVV4hebnV1Fc899xwikYi0HrfbW69ZP3LkiNxlQM6ZkhSHw4FwOIyFhQVpi9XfysSOsEGgLrLX23oFyvr6utyZ8P73vx/f/va3AUDmglI8vkwzHo8jEAhI5Z+Xvd95550IBAJyz65+AzLSPX78OA4fPrztuGhU+e8pgSI10W638b73vQ8PPvggKpWK8HFM4cgTUovZbDZRKBSQzWaRTCZx8803913bx89WFEUisu1Ap6koijgFOiVN0/C+970PX/jCF4QWcDgc0hsfCASkVXl6elocBemYYrEockXWAPQX0g+L3Ng+zqyJUa/ZbJbWVIvFImurqluXuJBL1jdNVCoVZLNZbGxsAIBc/G4ybd2kxqYK8rXDIl1V3XqdErl3Gi+Xy4XZ2VmYzWZkMhk8++yzGB8fx+TkpLRo2+12uWDJZDLhyJEjCAQCmJ+fRzwex9raGlZWVuD1evFv/s2/gc/nE0fLK1IHgUZG/woqZk1cDzoU/f207OzSZ1i8B4G89PHjx3HzzTfL3FBVQuM3yKkza1QUpe9uXdouOjBVVbF7924J2tLpNHbv3o2RkRF5nQ+VSGfPnkW73UYkEhF7x4heL3O9WM1gqNHl5ADne/fZF0+tIH+HHpvGuNvt4td//ddx5swZPP30032Xy5DbHBkZkaiZHFez2UQ6nUY6nR44LkY4k5OTUNWtt1acOnUKtVoNrVZLrpFj+tlqtRCJREQeMjU1JdIcdhzpi3iqquLOO++UAg4AuXeBMpztEAqFhLBngYc3/LOwQX5ML2jXG7/19XWYzWYUCgW43W5cccUVot31eDx9l9ewhz4ej2N2dnbguGgI9Ncf0ulxg1AcTqqBjkhVVYyOjmJpaQnBYFDUIdyg9Xodv/qrv9p3gQs/m5z2IBQKBXmDSCaTgaIomJ6elrSQcji2ZNOQsdjDqHF1dVWeTdM0lEolVCoVfPCDHxQliJ5no9xoENxut7TQjoyMiNSQ/45cLd880Gq14PF4MDk5iePHj2N0dFRS2UgkgvHxcdGmU4JJWsFsNvddKjUsM+DtZfqspl6v46WXXsLs7CyWl5fx93//9/j93/99XHXVVSKpMplMUi8gRcb1UVUVBw4cwNGjR/HLv/zLomXN5XJ99+QOq8jrtfsAJKuw2+3SBEF6jjQjKQnuM3YkvvGNb8SpU6dw9OhRWCwW7N27V+RjbLdmsKcv6l6IRCIhZ5XGmeeMmXc6nZbrLvmMrA/t378fvd7W1ae1Wg1TU1NiNxj16qV0pIrYuj4MQ+kFkufcIDRk3PSMGsjN6bVzqqrC7/fj0KFDuPfeexGLxeTwM51ktwm5RZLTZrMZd91118BxORwOkVyxCk8pBzktFk527dold5zSGPJVzwBk01PWwggyEomIoSLfyk07CJ1ORxaJhYxGoyHFjve///1SUGNRIJPJSBR19uxZuWOATomtr3RkVEe0WlsvwWTqO8yIsIDAdSFlpC8yWK1W3HXXXRgfH5foiM6Rhi+ZTCKZTCKTycg9tmwdJvQRNHn/QeDhZGGIn6M32ryzQ3/RPavajUYDc3Nz6PV6yOVyErElk0lUKhXs27dPggVGkNyjw9Zxenpa2rn5GnI6Rd4Cp4/gaQRCoZDQS3zP1+7du3HFFVfAYrFICzUPJw0QC698ldQgRCIRpNNpcSI86MViERsbGzh69Cj++I//GPv37xfHTA6eDpZBDpudWq0WUqmUaN0ZydMo6i8JGoRms4lIJCJnkGeq0+nIOwGtViuuu+46jI2N9UnLSA+QwmRB/p577sHtt98urfq8MY2vq2KNaVBzBPleOhZG+1SgUONP2oqUz+7duyVCpyPkpTzxeByf/OQnRc3APaVv6OFzD8NFbxmj1pCLQMtOvk3f+qdPLbhIlDxdffXVePnll3Hq1Cn5u06ng5GRESm+MOX2+XxDW+modODVcIy2qTvlmzzJoSWTSSwvL8NiscDn88nl4DzsjDwYzfKuBPah87P4+4PAiIwHnYvHKHJqakreWKvX+jmdTuRyOalir6+vY9++fTI35G/JGWmaJrQIi2TDXsHOTa83tJqm/cCl05Sh0QlwTdkQQIPCKLBUKolmGjh/3yiNMSOZQaCciA0sNptNWnQZbd9yyy04deqUPANTOXYJ8aIbGrlyuYxms4mlpaW+PaTvkroYR8kuOqvVimw2K9xpp9MRZ6APNvjZbLhpNpvI5XI4ePAgRkdHxdDpgxJeEkSNLg/txSJdvTKGTm1ubk6KnVdffXVfoYlyTcrMWENg2j0zM4OVlRXccccdsr94vSLPFCVXg6CqqjSv8PP5Hffdd59cRBUOh2UPMbrl89LoMXDiZVacd/29Bnx2fZ3oQuilZ5T3USVBhQSv2OT80Kbw7g4W31jrYLTOZ+ZZIg9/Me0wcVGdrj4V0280piH6QtuFpDL/t9frYXx8XDpdFhcXJcLiZRi8QR/YUicMOxSMWrfT6bHlmBNPw8abv6iz5Nte6VjoPHgROqu/jJJonIdFblxoRnAUYXNeeMPawsKCUA56hYLZbMbi4iISiYRcpcd/r6/Gch2ALed3sUXmdzFd1BsAvQwul8sJn8w7Fij2pwPifDLKYMTL8dDoXrgftgMdiL5yT8NGR3/o0CGcOXNGrgulDpb8Xi6Xk8iDh4MXBF3Y0KP/72HRCPcE156RMVt/9XeN6Lv8uE9yuRySySRuv/12uVGO6gs2KOidEx0Uax2DwItoqONmxT0Wi8Fms0kUCUCcln5v6KMwZqIsJO3fvx8ApHDF56dTGVbg0zds8LyTlnjTm96E73//+3I1APcesyl+NvcM50XfhKV3dDRy3W5Xsu/tQKOvDwDYHchi3NjYmNympl/7arUqSgW9I9e3OTO74b7SB5sXO49DTwWNFT9Er5Ejx0M5ld4A86F5oOgR5ubmcNttt0maTmE8jSglGsN4U4JCZU4uU2R6UQDC8VICxZZhejUuHAserNyura3h8ccf74vAmKoNcwa8f4BpOXvN6cFVVcUNN9wATdNE+tNqtYQHIs9UqVSwtLSE1dVVmU92w+mzDqaY3FiDwHngptFvYhayOp2tNzmzK4lUAtUAAGSz0vno01ZGIfqDTp5/EFKplDQO6BUxlJ/RsDINzufzyGazUpxh9xTHz0ikWCyKkuRCqoL3fAwzbnRkVGSoqipqjWKxiFKpJA6fESGLwWwEIFXFs8J2VmZYNNgXtkIPA+9w0HO1+oPudDrF4QPnaUF+NtdOf3dBIBDADTfcIAVZOhPShcxih2V4XItGoyGZDYuVDocDN998swRpdOIEn5lRL4MWOn7y+PxcjpvOf5Bjp5RQrxXX9xdomoarrrpKbBztGVUo+XxesjkW7SqVipxJGmrufc6X/m7gQRhqdBk9cKPyoLLdlpVs/o6+2Mb/ZRcb5USxWAz33nuvRLY0sPT4lUoF6XR6qBEh10plAaMzYMvwra6uolarSdvt9ddfj7e//e2oVqsoFotyly0AMRT1eh3FYlHuf+CNWqxqJhIJufdzENgIoteRAuebJqg35RtcSb2YzWZRJ+zduxfBYBCnTp3C/Py8OC6S+uS3OA/6KGwQ2GHGFE1vgGhgeJfF1VdfjWuuuUYuvNY3sJB/7XQ6olZotVo4c+ZMn0PWX440LNptt9vIZrMyNkbPLJowu7juuuvkBYr5fB5nz56Vw8C3JnAeSqUSqtUqDhw4IHuWz819erFmEr5yPZlMisPmK52YITHlpRPj75PT5xwEAgFx+DTKqqr2ZRTMeGjoB4GNH3zpK/eGqqqiR2cQRLkX9x4LxpwvZgN8DmYZmqZJxxbXhNTEINRqNTH8jBTZrMRCKZtr9K+W4lrQweqduf6z6aQYhXPd9YqBC1EqlaTLlEoUqlHY7MP54f4n3dBoNJBKpeS+DFJX1HkziORrk4Dz7ckALmp0L8rpUkjP6+e4EEy1eFsYowlO/oURrz7l1DQNy8vLoplkEYvp4ezs7FCj2+l0JNrgJeC8mJldb8ViEbFYTDgq3vvg9XplM7BQoE8JPvWpT8HtduP48eNIpVKi07Pb7XjmmWcwOjo6cFzUTrKvnp01vDmKXDKdDbvP2u22XHy9urqKZDIp8idee8mKOS+34YZhU8OwtxTzJi9SDIwA9fKparXa17pJobvD4RBHw43Hy3q8Xi+i0egPvL6GOl0W4AaBVIE+Oqb6gyk7lSfsoddHh9z4PLjsYjtx4gTm5+clA9AbWQYNw7S6+nsjGAToKQUaGc4hn4MRUrfbxTXXXCOt53w3GdPbZrMpXY68U5g028jIyMBx8d17zOooH2ThttlsiiJIX2DiGvD17XwOgs9iNm9d2M3bxVjHKJfLQw3J9PQ04vE4wuGwRIBsz08kElBVFbfddht+5md+RugBfaMO148Zq55i0F/cDkBUEXRcg8YVi8Wk+Foul0WVQEUJZXDvf//78cgjj+DMmTOyP0ZHR1EsFjE/Py8vlu10OrBarQiFQnKeeKY4pwxAy+UyJiYmBs6XcrGUxoABAwYMvH646C1jBgwYMGDg9YNhdA0YMGBgB2EYXQMGDBjYQRhG14ABAwZ2EIbRNWDAgIEdhGF0DRgwYGAHYRhdAwYMGNhBGEbXgAEDBnYQhtE1YMCAgR2EYXQNGDBgYAdhGF0DBgwY2EEYRteAAQMGdhCG0TVgwICBHYRhdA0YMGBgB2EYXQMGDBjYQRhG14ABAwZ2EIbRNWDAgIEdhGF0DRgwYGAHYRhdAwYMGNhBGEbXgAEDBnYQhtE1YMCAgR2EYXQNGDBgYAdhGF0DBgwY2EEYRteAAQMGdhCG0TVgwICBHYRhdA0YMGBgB2EYXQMGDBjYQRhG14ABAwZ2EIbRNWDAgIEdhGF0DRgwYGAH8SMxuoqifFBRlOOKotQURUkoivJJRVH8P4rv+iHHdYuiKE8qilJUFCWnKMoTiqJcfwnHoymKsvuCn/2/iqJ85lKNSY/LZR0VRfldRVEeuuBnZwb87D07O7p+KIqyrCjKT1zKMWwHY1yXD153o6soym8D+BiA/wDAB+BGANMAHlYUxfp6f98PMS4vgH8C8FcAggDGAXwEQPNSjelyxmW2jt8DcLOiKKZzYxsFYAFwzQU/233udw0YuGzxuhrdc4btIwB+S9O0b2qa1tY0bRnAuwDMAHj/6/l9PyT2AoCmaZ/TNK2raVpd07Rva5r28iUc02WJy3Adn8WWkb363P+/FcAjAE5d8LNFTdPiOzw2AwZ+KLzeke7NAOwAvqz/oaZpFQDfAPDW1/n7fhicBtBVFOXTiqLcrShK4BKO5XLHZbWOmqa1ADwD4E3nfvQmAN8H8PgFPzOiXAOXPV5voxsGkNE0rbPN322e+/tLAk3TSgBuAaAB+DsAaUVRvqYoSvRSjekyxuW4jo/hvIG9FVtG9/sX/OyxSzAuAwZ+KLzeRjcDIKwoinmbvxs99/eXDJqmvapp2gc1TZsAcAWAMQCfuIRD6mIrbdbDAqB9Ccaix+W4jt8DcIuiKEEAEU3TzgB4EltcbxBb62lEugYue7zeRvcpbBWm7tP/UFEUN4C7AXzndf6+/2NomnYSwKewdVgvFVaxxZHqMQtgZeeH0ofLcR2fwlZB70MAngAke4mf+1lc07Szl2BcBgz8UHhdja6maUVsFWD+SlGUuxRFsSiKMgPgCwDWAdz/en7fDwNFUfYrivLbiqJMnPv/kwDeC+DpSzUmAJ8H8AeKokwoiqKek87cA+CLl3BMl+U6appWB/AcgH+PLVqBePzcz4wo18CPBV53yZimaR8H8HsA/hxACVsFkDUAb9E07VLKs8oAbgDwjKIoVWwZ21cA/PYlHNMfYytFfhxAHsDHAbxP07RXLuGYAFy26/gYgBFszRfx/XM/M4yugR8LKJqmXeoxGDBgwMD/NTDagA0YMGBgB2EYXQMGDBjYQRhG14ABAwZ2EIbRNWDAgIEdxHbid8Hx48c1u90Oh8OBTqeDdrsNk8kEi8UCs9mMcrmMer2OUqkERVEAAJ1OB91uFy6XC16vFwAQj8ehqiosFgsURYHD4YCmaWi1Wkin0wgEArDZbOj1euh2u7Bareh2u7jpppuU7cb1ve99T9u9ezd6vR5MJhOsVitUVZVxNBoNdLtddLtdNBoNNBoNAIDX64XT6USj0cDS0hIcDgd8Ph9sNhsAoN1uo1gsQlEU2O12qKoKRVFgMpmgKArq9TpMJtPAcT344IOa2+1GJBKByWRCvV5Hq9VCMBiEqqqwWq3QNA2lUgmNRgMulwtutxuJRAKdTgfVahXh8FazV7fbRa/XAwCZj8XFRdjtdlQqFdjtdlgsFvR6PdjtdrTbbbz97W/fdlzf/va3tYmJCVk7q3XrvpparYZut4uRkRGUSiUAQKPRQLPZRK/XkzVVFAXlclnWT9M0NJtNlEolOJ1OaJqGbrcLTdNgNpuhKAo6nQ5arRaKxSLe//73bzuu1dVVzefz4ezZs3A4HAiFQjCZTCiVSvD7/SgWi1BVFR6PB41GA5VKBa1WCwDQbDaxtraGPXv2oNPpoNPpoNlsot1uy+/3ej00Gg0Zl8VigclkkrHefPPN245rfn5eSyaTGBsbg6qqqFQqaDQacDqdso+r1SoURUGlUkG9XofFYkE4HEYqlYKqqohEIkilUkilUqhWqzCbzRgZGUG5XEa73UYsFkOj0YDdbofZbEaz2US5XEY2m8Wv/uqvDhxXLpdDvV6H3W5Ht9tFpVKBz+eTPdvtdlGr1WA2m+F2u2EymbC+vg6Hw4FqtQpVVdFqteTsKIqCdrstZ6DZ3BKm+P1+AEA6nUa5XIbX68W73/3ugefRZrPJuWu321AUBcFgEPl8HsFgEOl0Go1GA2azGS6XCw6HA41GA9lsFk6nE+12W8bPM9tqtWAymaCqKjqdDqxWK1wuF3q9HsrlMnq9Hmw228BxXa4YanRpHBuNBjqdDnq9nmzgdrstm0hRFDSbTXQ6HWiaJpudkxgIbF1zYDabYTKZ0OlsdZcuLi5ibm4OqqrKITebzbBarfI722FqagrdbhfNZlMMgclkgsPhkAPP8bbbbXS7XZhMJgBbm8jhcGBmZqZv49VqNWQyGVitVoRCIbRaLXS7XQCQ/7Xb7ahWqwPHxc3DTex2u1Gv11EsFhEKhWRurFarGORutwubzQaz2YzPfOYz6PV6ePvb345oNAqbzQaTyYRKpQJVVTE2NiYHgJtRVVVomibPtx0OHjwoB0/TNDidTgSDQdRqNZw9exaFQkGcTafTgcVigdvtRrFYRLvdFsPebDZRKBRgsVjg9XrhdrvlsPLfNRoNtNttqKoqTmUY1tbW0Gw2YTabZS743DabDcViEaVSCVarFWazGWazGaVSCfV6HYqiIJlMyjPx3/Z6PTgcDtTrdQCAx+MRB6KqW8ndsHWs1WqwWCwoFAqw2+3iVBqNBoLBILLZLBwOh+w5q9UqzsLlcsn56PV6MJvNCAQC8Hg8svZcP4/HI9+paRqq1Sp27949cFwnT56Ew+FAq9VCuVyGy+VCKBSSdRkbG4OmafB4PKhWqygUCrIPuYc5z5wHRVFgs9nk/3OuOp2O7Au/3z90f8XjcYRCIZjNZrRaLWiaBqvVimKxCLPZjM3NTVgsFkxOTsJms6HT6aBcLst6K4oiAY6maXKGXC4XOp2OBAsM1Bi4qaqKfD4/dH9djhhqdE0mk0SJ9PB6z1MoFNDr9eB0OqEoCgqFgkREjKZ4WGhQaeBWVlYwPT0tUTQXnd/Fw7wdms0mNE2DxWKRBeKiVSoVuFwuKIoiB81kMkmU4nK54HK58NWvfhXXX389gsEg6vU6MpkMarUaxsbGtibmXPRhsVjEsKmqKtH7dlAUBT6fT6IFj8cDv9+PXC4Hi8WCYrGITqcDh8MBv9+PVquFUqkkG03TNGiahr/8y79EIBDA9ddfjze84Q1QFAUejwedTkfmhc9HwzvMSTWbTUQiETFItVoNlUpFMpdms4lvfOMbKJVKuO6663Dw4EFxWMwMaLBNJhNWVlZQLpdx7bXXyuHi9/d6PaiqCrPZjIvJEfVG0WKxyLzRaNE4eDwemEwmtFottNttWCwW1Ot1PPvss+j1eigWi7jllltw8ODBvmeu1Wqw2+19ER2DAe6N7ZBKpRAOhzE2NibOeHV1Fd///vfxG7/xG3A6nfD7/ZKJFAoFlEolyQAVRUGpVEKz2YTb7YbZbJbn8ng88js0MsViEZVKBWNjY0ON2+HDh/Hyy1uX4jmdTlgsFrRaLTgcDvkOq9Uq0T2NJ8+Kz+dDsViEpmmw2+0AIPux2Wz2GeJyuYxyuQyTyQSXyzV0LV0uF2q1muxhRrL6z+Ma8qx6vV6Uy2VxuIyOrVYrnE6nBGh0FhbLVre8yWSS4IV798cNQ43uhdEAjQJTCHpI/Qbqdrvwer2wWCz43Oc+h1qthne9610YGxuTA59Op2EymcQDm0ymvkhXVdWhm48GgREux6aqqjgAfgYPAhfNarXiwQcfxMLCAk6fPo1bb70V4+PjiMfjeOWVV/DMM8/g3nvvlagZgDwjI61BYEpGaqNer6Pb7cJut4uDcrlc4pDouWnMSBfUajWoqor5+XnUajXccsst6HQ6MsfceADkWYeNSx9J8jDqDXa320Umk0GpVMKzzz6LVquFw4cPS+RCqoBGL5/P4+TJk8hms3jnO98JRVFk7JwrOgK9M70QXHs+OwDZV8ViEb1eD4899hi63S6uuOIKjI6Oyl4BgHK5jEajgXQ6jUqlgm63K2PhPNHAcR2ZVdDoDEKj0cDm5iaq1apEztVqFV/60pdQqVTwtre9DX6/H2azWaI30jx8fgYfnHsaCq4B90iv14PX65UodhAWFxeFPnE4HLKH9EaL88D9wezUarXK3/GMABBnx3PEYKPb7cLtdsPpdALA0IyF+1VPH7pcLrRaLTHmpCcZqVosFqES6RT0DoM/p/Gmc9Bnp8lkcui+v1xx0REzuuKEknflBubBYkQIbC3c0tIS5ufnUa/X8cgjj2B2dlbS71QqhY2NDfzsz/6sHFQeEBqCYUaXB5SekZEoea16vS6HX38AGe28+uqrcDqdePjhhxEIBGCxWJDNZuWP2+3GW9/6VhkTDcPFFtjhcAifxvEzheLPFUURrkqPXq8nBjgajcLj8aDdbmNpaQk33HCDGHI6Nj3fCuCi86WfE64RDSXX0OVyIZPJYHNzE1dddZVEq/rIM5fLIZfLoVgsIpvN4t5775U1YLSrHxMjle1AY6Z33Pw3NCKLi4uoVCrw+/2SlnP8/A59Ssrv1jQNp06dQrPZxOHDhyXi5P6i0doOdFKVSkWiNI/HA7fbjbNnz6LZbOLo0aPQNA27d+/G2NgY7HY7er1eX/alXyPOIek1jqNer/fxr9zb24H0FzMDAOI0NU1DvV5HrVaT30+lUlhcXISmabjrrrv6HDfHwHHRYVgsFuRyOaiqCrfbDZfLhXa7PXS+2u02gsEgwuGwBE+qqspZpG0g5cc/pDY4B9wDeodgt9tRLpeF++Y54Gf5fL6B47pcMdSKWK1WIauZkrFQxmihUqlIMYveKZ1O46WXXsLc3BwA4Lvf/S6CwaDQCeVyGQ899BAOHz6MgwcPivHkgeKiDYLT6RRjzX9H46GPAGksO50OGo0G4vE4Go0GQqEQIpEI7HY7UqkUVldX0Wg0MDk5CY/Hgy9/+cu45ppr+nhVelhGWdtBz7MyC2CkwTS9XC5D0zS43e6+DcZIkuk06Qc6E6ZUPGQXOqlh6TK5ZUZX/ENjaTab4ff7pZimaRqy2Sx8Pp84SjqKdDqNbDYLm832A8Uzzo0+rSQ9tR30/K0+4uchBCCHPZVKwev1YmJiQp670WiI8eH8AFtGM51O4/HHH8fm5iampqaEq+TYhjmpdrst+4qGp1AoIBKJoNVqIRQK4cyZM1hcXEQymcQVV1wBv98Pn8+HkZERFItFFItFSctpYJiN0SkzzeccXsyxT05OolqtCmXCf0PuNJlMSoZgMplw8uRJfPe730Wn08GBAwdQLBYxMzPTVxQ3mUzyefqsRk8R6CPj7RAMBhGJRIRfZoHW5/OhUqmI8SQ3D0AKY+12W/YC9z8dl81mk/pOIBCQCLxaraJer0t28OOGoZKxarWKQCAgfCgNgNPp7ItIms2mVJYrlUqfkfV4PBgbG8PIyIhEDD6fD7fffjs+/vGPo9lswmq1igHiphtm3JxOJ7xeL6LRqDgGq9UqjoEHix613W7jzJkz+JM/+RP89//+3yViuvLKK9FqtbC5uSlpp9PphNvtxrPPPtt3+Ghwhx2KQCAAn88nhqDZbKJYLAq3WK/X5aA5nU44nU5Jc81mM0KhkFS1WaD0eDxSbODv8eDy0OmN93bgczGa5sHKZrOwWCxwOp244oorhGNbWFjA1772NeH0NU0T48g02Ww2S2RHR6d3OpynYelyIBCQuSVXTSeuV0EAwEsvvYQTJ04IPUNen4fWYrFIRFWr1fBP//RPwnXS+bHAOiz6BoBdu3ZhfHwc0WgUXq8XNpsNoVAIt9xyi3CIk5OTuPHGG1Eul/GFL3wBn/70p1Eul5HJZIQj9fv94lzpMDlnrVYL6+vr6HQ68Pl8wvUOw+zsLEZHR6UI22q1UK1WxWBVKhX88z//M773ve/h6NGjaLVauOWWW3D99dfjs5/9LP7yL/9S0ns6b0ax3OuJRALhcBher1fOPJ3uIOzZswd2ux3xeBxnz55FuVwWVQsdb6VSQTqdlr1DBUWhUEC324Xf75fiOPeb2WzGxsYGwuGwBBalUgntdhuhUAhOp/Oia3k5YugqHzx4EPl8vi81oOSEnlFVVWQyGTz88MNYW1sDsHVAPvCBD4ix2b17N1wul6QwwBb/SdmXvnKpj8AGgdITh8MhxSF91ANsGRqO+ezZszh58iTe97734eWXX5YN5Xa74ff74ff7Ua/XRRo0MjKC+++/H9ddd50sODf2MGewuroqxtlqtcJms0kqyGiEzoHfRd6LaVKtVkMoFJJ0yuv1SqRE3lCvWmDUPKygQKkZDbxeikbJ1p49e3DmzBnhoc1ms3B1pBl8Ph/cbjcsFovQTpxnvdGnYbvYYS0Wi/B6vbKefr9fqB4Afek31QnNZlM4SErdWFSiIQG2olUaWXKGdAqMmAYhGo0inU4jGAzCZDKhXC5LpPuud70LX/nKV2C1WiW6Gx0dxcrKCj760Y+i1WrhE5/4hDx/MBiUKK/ZbEqtIJ/PY3JyUjIxUkbDxpVKpSQypTyOe+mv//qvsXfvXuzatQuBQAClUgnFYhFWqxUzMzMYHx/H5OQkPvaxj6FareI973kPbrzxRvlufRGQPDWjdEoEB2FjY0Oys0cffRTtdhtvfetbJZjas2cPEomEqI64Z0ulEihJXV9fFyPNYlqn0xGFB4u/LpdLCm3c/z9uGGp0E4kEnE6nkOEs/NjtdjEWiqLgscceQ7vdFjphbGwMo6Oj4sVWVlbwyiuvIJvNolgsYmlpCb/xG78hEc6FhYdhURuwlXLSOzMSYtTHaILGYmlpCclkErOzs8I5Pf7447jvvvswOzsrn8Wq9sbGBrrdLn75l38Zk5OTfdwhOexBcLvdUsEFIFkAPXcoFEI2m5WIsV6vo16vS5GGhp0Hj/NN6sbpdEphh5EuHdWwQ+F2u1Gr1YSb5zxZrVa0Wi3Mzs4inU7j0KFDeOGFF5DL5QAAf/3Xf43f+Z3fQa/XQ7VaRTKZRKPR6ItmWTjhc+vpEnKjg6AvALXbbVSrVeGZmVZ+6EMfwmOPPYbNzU243W6ZD6bIoVAI5XIZNptNqBCOEQB+/ud/HrOzswAgP2d2MAjcgzTwfI5SqYRgMIi7774b3/rWt1CtVuH1ejE1NYVoNIpoNIrV1VV85CMfQTKZxK//+q9jz549fYVTfk6n0xFeXW9oh9ExgUAA5XK5L8uwWq2o1Wo4cuSIyLDW19dlfxUKBTH0c3Nz8Pv92NzcxOc//3m88sr/3963x7ZdXu8/Thwn8d1OfEnixG1uTdIrDayswBfoJApjgzGKQDDGxJBGB5vEn5uE9j/TtH8mTd2kjY1J2yRgaCvjfunoSkuhlzRp2sRtc7Xju2PHdyf+/ZHfc/o61M7+mtopR0JjJXU+fj/ve85znvOc847imWeekfMyMTEBr9crWREzDu65amYwGJBKpYQCunLlCt5//3088cQTSKVSCAQCoh9mMYwqCmrn6+rqJEgAq/x1NpuF1+sVxZNGo8GHH36IkZEROBwO/PCHP1y3IHo92n8kGePBIU9KBLOysoKlpSUhw+fn5xEMBmE2m3H58mXRKra2tmL79u1wOBxYXl7G+fPn8dprr2HLli0AIC9YLajUQrrU/7KazmiczWalkeDgwYPQ6/XYsWMHurq6AKwGEZPJBLfbjZmZGSSTSTnglK55PB6cPXsWe/fuldRSPaC1OCRypalUCgAE1TJI0enp9XrhWPm7p6am5HmYQtGp6fV6OBwOLCwsQKfTVSB6Nlvwd17LSqUS2tvbJbVkMNBqtZibmxMnQ9SfTCZRKBSg1WoF+VIbmkgk5NnpNFW6g59NJLxexkKnWyqVBNUSXXL9uO5TU1OYnZ3FQw89hIaGBkxNTYn+lcWrSCSC119/HRaLBalUCj09PUJBAZCAUcu5ZbNZ6PV6BINBkQFSqeD3+6HT6bB//340NTVhZGQEgUAAJpMJPT09aGlpQTabxeTkJI4cOYLXXnsNXq8X9957rzj/aDQKt9v9pYIj17KajY+Po6OjQ3j/UqmEWCyGhYUFRKNRJJNJjI6O4pFHHsGWLVvQ2NiIYDCIY8eOwel0orGxEZs3b65Y41/84hdIJpP42c9+hra2NskcuabpdBrFYlGklNcym80mTT1+/+q9oIlEAr/+9a/x9NNPSw3CYDBUBDH+rpdeekkc/Fe/+lV0dnaiXC6ju7tb6I+//e1vQqns2LEDN910E3K5XE299fVqNZ2uqkhgWkB0S67v0KFDaG1tRWtrqyxsf3+/OKeZmRmYTCZs3rwZRqNRKsI+n08iLNEXKYb1kC47X4CrlXIWy5LJJA4fPozbb79dKJBUKgWv1yvVz97eXqFGzGazbAa9Xo9wOIyRkRHhh9WAsB5/lEgkhLKgwykWi8LlEtnQ0VBWs7S0JEVIdq9xPcxms6ANolNSNES5QG1JDw+EWlnmwfN6vSKA7+jowPj4OFZWVuB2u+FwOHDo0CH84Ac/gF6vx/Hjx5FOp2G1WmEymdDf3y+BkuiTGYFWq0Uul6toAFhrdJTFYhE2m026jdQqv81mQy6XQywWQ6lUgtlslv/OQhXXYG0zDIOMWnSi+qZWWsrCcSaTEU4zFovB4/HAYDBIIMpms/B4PCgUCpiZmYHb7YbVaoXL5ZKshI0c77zzDjKZDLLZLJ577jlROxDxMkOz2+1Vn8tms6GtrU2alc6fP49jx46JXjUej+Opp57CTTfdJFpbg8GAbdu24a233oLX64XH40F7ezvMZjNisRjC4TCy2SxefPFF/PznPwcAeSauk9PprOncmpqa5EySTiI1BKzuU6vVitnZWTQ0NEjjSrlcRiwWk2ylWCzio48+wvbt27Fv3z7JZH/3u99Bo1ntcJubm0N9fb1IUG/EQlpNp0unQ2dIh0h0+dlnn1U0QdjtduH3yHlxkcm7sbvllltuwTvvvIO//vWvOHDgAFwul/weclXVjJtCLU7Q8vk8CoUCOjo60NjYKKkysOp8Zmdn4XA48Morr2BoaAhGoxFGoxErKyuIRqPI5/Po6+uTziIWeiiT4/e9lrFCrlapVUkcOVlg1eFcunQJIyMj0Gg0+MpXvlKB2lW6hCiZCJ+Om9kGU/JqRr6bWQrbfOkY8/k8gsEgmpubYbPZYLPZJIPh7yCHyMKZTqdDb2+vOLK14nr+uyphWmsMeiymAlebK7hG+XweQ0NDyGaziMViKJfLeOutt7B//37pggqHw2hoaEAgEMDZs2dFxxoKhSrkR6pKotb+yuVysvZqayrrDVarVRQczIYcDgf0ej0uXryIUqkEu90Oq9UqrbDRaFSQ2rvvvgur1Yqbb74ZDodD3jn3YTVjFsUCktVqxeDgIAqFAlwuF3K5HMxmM0wmE+LxOBYWFjA3N4dIJAKz2SyaYO5V8qn5fB7nzp3DSy+9hOeff16eQ6PRwGg0rquOCYVCaG5uxvLyMvr7+7G8vIyLFy+isbER77//Pm677TY0NjZKa/fMzIzUGSYmJuBwOCTbmZ2dRSQSqVCzMOCRI+fPk5640ew/croqmuCBKJfLCAQCkq5QQqbT6TA9PY1MJiNcJPmcxsZGKU4MDg7iiy++wOHDh3HXXXfB5aq8lHc9gpwHmy8mn89jbGxM5j6QeyU/RU6IB3x2dhbd3d3IZDJSEY/H4wgEAjhw4IAoNFSJEZ1hNePvYkst+SuiZcpglpaWMDc3B5/Ph9nZWaTTacTjcSksMPWlFI8HQNWyqlpPporVbHFxERaLpUKSxzUmhZDJZDA/P49YLIZUKoW5uTnY7XbodDqMjY1JxZ1ryP5/8twsrnKvsIhZy+mynTiXy8leI1pmYSmVSqG9vR0+nw/xeByFQgGhUEg+Q10DImIG+Jtuukn4TO4XNQBWMxZsVEldXV2dOBcCC6bILpcLdrtdMpbp6WlR67DoYzAY4HA4EAgEMDMzg8nJSRQKBezZswcdHR0VDQPVrFQqVRQOqecOh8Po6OiATqdDIBDA0tISJiYmcOnSJWkg6ezslPNCzXZDQ4Og52KxiFOnTsl5bG1tlUBVKpWkSeJaRt1vuVwWGisajSKdTmNsbEwoNBa8Q6EQZmdnodPpEAwG0dXVJZ8BQJA8gQeli36/H+3t7ejs7BRa8H+uOYLIltFxLd+q1+vh8Xig1+sRiUQqEEsmk4HP54PNZpNiEfvUOdzktttuw+nTpzE+Pi6ysvW6qwAIulI1rIlEAidOnIDT6RQaRHXAS0tLiMfj4tQ6OjqEa2UBIpfLYX5+Hvfff3+F7Eyt4NeK+CrnzcPNlIvrls/ncfnyZYyOjqJUKmFgYAAXL17EX/7yF+zYsQMNDQ3CIxMZ8XO4EelwidYKhUJN58bPIh+sImOm9PX19Th//rzMOmDBJhgM4vDhw9i2bRuWlpYAQCgmACIl4/dl+s5CWi0jpcKMQF1fPhPTUOo/yT9PT0+L7pO0kt1uh81mk8FF3/nOd0RrylRZbQioZmrDD/c0JVEOh0P6/UlzkKvnwKKRkRGp/NNhsDmDiNbn8+GTTz4RZYzb7RbVSDXjkCM1m2T2xJZdnU4Hn8+HU6dOIZFIwOVywWKxQKfTwWg0ggNzAIiEk4OGmpub8frrr0Or1eL//u//4HK55JlqteW7XC4pmpdKJbS0tGBwcBAnT55EfX09PvnkE3R1dYkCgT+j0WgwMDAgXXYEK9lsVgJJJBKRTs94PI6hoSG0tbUBgATAG83Wdbpr03e1yyafz2NwcFD6+FOplPSQ53I5fPDBB+jr6xOOjVxYf38/kskknE4n+vv7cejQIej1enzrW9+qEP1XM242FtKSySQSiQR6enowPDyMw4cPo7e3F16vF9lsFn6/X9Cbx+OB2WyGw+GA1+vF8PAwIpEIPvzwQ6TTaXR0dODgwYM4cuSI8LKqkL6WBEqn0yESiXxJvmQ0GkUCFgqFMDo6ikAggI6ODnR1daGxsRGhUAjJZBLBYBA7duxAW1sbUqmU/D5SLiqlAEAG6tQKBps3b8b8/HyFSkSj0WBxcVFQ2czMDDZt2oRsNisDSRYWFvD222/DYrHA4XBISspnYNsqHScdLSkeVfJzLaPqgZy1SqOwbdVsNgtySiaTaG9vx5EjR3Dy5EkMDw/DZDIhn8/j9OnTsFgssidIEdDRMVtYS/Ncy4jeOeWM752UhcFgkHkUhUIBDQ0NaGlpEYXH4OCgBJ90Oi3yts7OThlYRLrqo48+wuLiIh599FFxLtXMbrdDr9cjGo1WtBJTlphMJhGJRPDOO+9Ap9PB7XaL8mRxcVEknYlEAt3d3YJeqRs3m8247bbb8NFHH6FUKuFrX/saurq6KuZiVDOLxSLqlqamJrS1tUm20tPTg3w+j48//lgmyDmdTskCPv/8c9x9991YXFyE3W7HwsIC/vznP+PJJ5/EJ598ArfbjUKhIFP+9Hq97MFawfN6tXXVCyoXpvJ6dMQXL16ExWKRDXnp0iVYLBbEYjFpt11eXkZLSwusVivi8ThmZ2dhNptht9txxx134B//+Aey2SzS6XTFzINqlslkxBHW1dVhcnISH3/8MQYGBnD+/Hls2rQJ+XweIyMjgnToEH0+n0io2trapKDV09ODN954A/fddx8uXLiAZDIpOmAWtdaTGqVSKQwNDcl0LqoZGhsbBU3/+c9/hlarhcViQalUwuTkJAKBAPbs2YNgMCh64ZmZGZm0RIqCaJUOjmMFGdCqWSgUQmdnp4wPpDKBn7dp0yYcOnQI2WwWW7duRW9vrwTShx9+GDqdDr/97W9x//33w+VyIZPJCEeoKinYOMHvbTQapYh3LTOZTDKOU6PRiK6ZRR5qmTOZDPbu3Yvh4WEAq8jq5MmTuHLlCnQ6HTo6Oiq4R51Oh2g0WkHJMJAzjff7/fB6vdd8rmAwCKfTWSF7tFqtoidl0ZU0SyaTQTweRzwel3Gnzc3N6O/vx+LiorzTcDiMvr4+XLlyBU6nE4FAAFqtFidOnEAoFMJPfvKTmoiSdAfPCLMzTncjlXDgwAGMjo4iHA7L+WBX4ujoqNB+7MzU6/XQ6XS4cOECenp6UCwWcfToUUSjUTz66KPo6emp+kzAqk53eHhYaAEChKeffhovv/wyjEYj/v3vf8Nut6Orq0sCYHd3N+rr6xGNRjE2NoalpSXk83mYTCakUik8++yzeOKJJ9Dc3IxkMokHHnhApgPSaoGz69VqPrHBYKiQshAhMY2YmJioOPgcYHP06FE0NjZi165dkqLOzc0hEAggHo8jk8kgFAoJF7Zt2zbE43FMT0+LZq9WNZ5pFrmt4eFhPPnkkzJ20G6349y5cwgGgwgEAohEIohEIvjXv/6FQqGAyclJKfrRsQ0NDeHhhx+G0WjE4OAgvv/972NqakpSR/5Ty+kuLy8jFAqJrEqv18PpdCISiSAejwuiMxqNaGtrw8rKCkKhEPbs2QOHw4HHHnsM27dvx+zsrMwfpXaVKR4bVQBIt1yxWMTAwEDV5+LkM3JzfA5OCHvhhRdEgeL3+3HmzBnh65966ins2rUL3/3udzE+Po6JiQmhOYgyOEGKNIhOp0NbWxscDkfNYMBnJ2oul8vSysoUtKmpCX/6059w8eJFtLW1YevWrbj55pthNBqxc+dOvPbaa7LWfD+ZTAZjY2Py7rhO1D0nEomaGUtLS4sgVx7qQCAgTtLj8cBiscizk6JqaGiQ0aENDQ24cuUKzp07JzWOxcVFqdY3NjZicHAQ/f39sNvtuHDhAp566qmatQx2cBHRUipGJVFdXZ3McqZWngXwzz77DFeuXEFnZyf6+/ulqYIDcMrlMm699VYYDAZxjj6fDy+88AJ+9KMf1Xwut9uNycnJiu41ZsLPPPMM/H4/EokEMpmMIOH6+nq88cYbWFlZgcfjwfj4OHp6enDLLbdgaGgI27ZtwyOPPAKbzQaNRiPNKewm5fjRWoXt69VqIl12JKlNATxYmUwGJpNJ5qHW1dVhfn4emUwG9957L+rrV+eFfvbZZ3C5XHA4HLDb7SJiJxKx2+3o6OjAqVOnoNVqsXv3buE+q8lBVBF9IpHA0tISQqEQYrGYvJShoSFcvHhR0rBSqYTe3l5cunQJwCo/ND4+jvn5eRgMBpH6ZDIZOJ3Oa460ZKGnmhFtcfNFIhEAV9O3crmMxx9/HMeOHUOxWBT0cerUKbhcLvh8PjQ3N8Nut4tWlxVfu90u30Ntvy2VSnA6nTUHpbB5gLxpuVyuoArYkNHU1CTFKmYIV65cwZYtW5BMJhGLxQTta7VauN1uQaocEEMnx8JbLalRNBqVGRPU9aoabDrlRx99FGfOnMHx48exa9cudHV14ZZbbkGxWMRzzz2HP/zhD9i9ezduvvlmNDU1SeZA1E2KiO8lnU7XfC4WAEl9WCwWmM1mzM/Po66uDrOzs9Dr9TCZTMJTxmIxnDx5El6vF36/XyirtrY2DA8PI5lMYnl5GV6vF42NjVI0DQaDgtaDwSC++c1vYnJy8prPRfqFe4lIm803VCI4HA7MzMygUCigq6sLoVBIug7Z+efxeNDS0iKyLKJLZl8mk0lklqdOncL+/ftFg7vWCF40Go0AIipPGOBIEdTX18Nut8Nut8NisWBmZgYXLlwAsEpnLi4uIp/Py/gBZo1cP+Bqu3k6nYbBYKj6Hq9Xq+l0qUWkAoEdVNxwbMnjsOTW1lYYjUZEIhGZU0unyn5uptVE0XV1dYIa1KaCWpGVKgBWNllF37NnD06fPi2oo1wuIx6Py4ujbnHHjh2w2+3CRdLBEC1Q7K3SCUT8tZ6Lm5+tlXTSnKvKz15aWpIB4BqNBul0Gi0tLYjH49i7dy9SqRROnTqFXC4ncwY4KYwOjoHOarWuqyFWeS91RgGd74MPPojjx4+jra0NNpsNs7OzGB0dRXt7O+x2O4xGI1wuFwYGBjA5OSm3ffA9sbBDThWAFKxqTYFiO6s61pGpo8ViEcc0Pj4uEq2pqSnkcjl4vV5Zg7vvvhs+nw8nTpzA0NAQDAaDdFPSiEgzmQxKpdKX1DKqUUfKjI7PajKZJLAzQJ06dUqooEwmg9OnT6OnpwcmkwmPPfaYfAcA8q7Vjjuz2SxUDp1VNeN+4HwK7jN+Fqv9b7/9NmZmZoSHzefz2Lt3L8bGxnDgwAGEQqGKwUf8LPKmW7duxczMDLLZLLZs2SJa6WrG51b5fipFNBoN7rzzTvh8PlF4LCwsyP7jrSkDAwOYmZlBS0sLXC6X0IcejweXL18Wek797PUKoter1XS6RHnkYJjessJKBMG+eCILFk/q6urQ0tICm80mgnoOISEflclkkEqlcPfdd2N4ePhLE6uuZdTQUi/KyNfZ2Yljx44hFAqhUCjIBH1ycps3bxZOb2VlRagM4GpFnu2MBw8eRFdXV4VyQC1gXcvoGGl04qw4q6qGdDoNh8OB1tZWHDt2TLqYent70dLSAq/Xi/n5eRlyzg2stjkDVxUltRA4Ubo6e4GpNrm1Dz/8ELFYTIp+Op0OiUQCXq8X0WgULS0tMtSbgYQ8tzrLQVUKUD1Szbim3FcqP8cCFYto7IwkcmJTQn19Pbq7uxGJRCTjaWpqkiIYnRFRIQN+rWCg6pqpjslms+Lk+d8INugI+/r6hEaiTCsejwu/n81mEY/HZSZES0uLtCbz2WoZZ0+oc1Co5uDnB4NBedfcG1arFTabTQBDX1+fSLg4PId7lNPw7HY70uk0/H4/MpkMOjs7qz6XXq8X2dlamalGo4HL5cK5c+ek2adUKsnIydnZWaysrMggLHW+B510sVjEnXfeKUBIVcrciPYfFdK4mEwd6VyBVcdqMBjQ2NgoqQrvS6KWs6GhQdJZoiIegng8Dp/Ph4ceekg6adZbTA7OYapMp8QRdOR5rFarOBez2QybzSbOb206y3uZ4vE4zp49i+effx4tLS2CBlSdZ63n4lg7HgwOKCmVSqJVNhgMcm+W2+1GZ2enbK75+XnY7XYpfEUiEYyNjWHTpk0Vv1t1CABqIl2iBmYsKqIkOs/n8wiFQlhZWR2oPTAwgNnZWVEykPNlUYjvkPMO1BZuoPaUONX4/FxfBhDKttZqiznRjgVK3nPn8XiwsLAg4yn5DGsHybAtu5Y0i5QUOwjL5bLcucYUfnl5dbawTqeDzWZDJpORKXMajUau7uEITKJJUiaLi4vCSzqdTiQSCSngVTM6d1V5oU5ao+7VarVKek8ntry8DLfbDaPRKOMdKX0j6tRqtVJkZgGcf16rwJfJZOQaI74ronkCIzVjINCith+AFFAdDkdFFpBIJJDP57F7926YTKYKJYoKPm4kWxfpqnIpVUupCuy5sRldKRvi8GHqBylgz2az0sfPyMzqMimHWoiSnB/1nTxQRFqbNm2Srhp2yrDazIv8WltbJWUkDcBnAq5uHDoU9ZqcakZHQYfLnycipLH6XCgUpNtmbm4OHR0dkkKaTCbY7XaZ4Hb//fdXaIbpoBhU1mtRVh0P15ADb/i5DBacGEVHTIkU/5w0AoXt1KsyANKxU0Nbzfj+uK9UbTRTRxYR1TGWDE5Go1GkT06ns6LQZDKZKpwdm1VUaqWakTOl5Izrxf2dSCQqGmfY9hwOh2E2m+H1etHa2iozY1mjIFUHoEIix++XzWZrInA+Ex0igQfPaUtLC8xms2QGlLK1trZCo9FIEUu9fICBi4OYmCEmk0kYjUbJDik3u5bF43F516QA6GwZHN1ut+y3YrEowYkdiW63W7rWgKtXIPGZDAaD7FHuGe7rG83W7UjjhqVzU/WOer1exjeqaT6HfthsNrnyg4fQZrNJKjg/P49wOIxnn30WAwMDsvlKpVJNp8uoSXTEjcyIzyLc8vKytGlSa8hBKkTsTJc5ZjEcDuOXv/wlbDabHDR1lmytl7ywsACDwVChNVaRGzcOnTLRNTcrC4fhcFj+TiaTwcLCgjgLFaHx4JVKpZo96GzTpdCdh40Hdnl5WYKQTqcT2ZPL5cLU1BS6u7vFkXE9FhcXMTIyIrMi1K452Vz/P82uZmw8IFfN98R1ZqchpYparVYcf7FYxKeffgqTyST0FR2Jz+dDV1eXBG+uOYOOOgP4Wkb1DAECAHmnGo0Gra2tKBaL2LFjB+rr6zE+Po5Lly4hEonA7/eLioKFNq49h/R4PB5RdrCOYTKZsHXrVgQCgarPxc9Ub8pVwYxWq8Wtt96Kl19+GbFYDG63u2IS2djYGAYGBsThsx26UCjg8uXL8nNE3+VyWbIKgpFrGbvi1JGsDIAcNL5v3z4cPXpUuvbYich1SaVS6OvrQyqVkmwlGo2K7p3NGyqgWQ+cXa9W0+kSiahflI51ZWUFDzzwAD744IOKKjFnGHB4C1v2WKVlKra4uIj6+npMTEzIvFS+MKYltRzc2oNOJHPHHXfg+PHjomcEUHFwqapgSycjaSqVkqIbb+4lulq7HtWMDlYl93mAWXDk1d1qWlgoFHDs2DE8/vjj0Gq1OH36tAQNOhI6JTpOld5Zr5BGJ2CxWOT38r3Ozc1h+/bteOihh/D555/L+6VyxW63Y+fOnYJsWTXnaD6m4er8WnLfTKVrrReVEnS27Kwrl8tS9GMRknwz15jNLw6HQ4bMkJPkwWV7Kh0UP5vFy2sZA4yK2NS/63A4cOnSJZHJbdu2DQMDA5ifn8err76Kixcvwul0iqaat09QrTM+Pg6v14uVlRWZLJdOpzE6OirjUa9l7K5kU0Y8HpeAScTY0NCAr3/96zCbzZiamsKRI0dgsVhkpi7nUbCukc1m5d21trbCarUiEolgbm5O5HdTU1PYtWtX1eeikkktCPI9Ed0CkPZjDvpnAwu52zNnzgglw6CbSqXwve9970vKIZ79/7lCmjqLk+hApQLcbrdETeCqbtRoNMLv98s8Whba1haTotEoDh48KGPjuIn5MlSHp9raAcvqPzt37sR7770nNAevHWEwUOcy0BkvLS1JB9axY8fEsamRm79PbXW+ljmdTtEqEl3x/2cyGUFkxWJRnERzczMcDodwetu2bZOiSH19vegbeXDVebHsvqrVzUQUrRaEOPegt7e34jvxnbMY6vf7MTY2BuDqFC8GhFdeeQX79u0TnTZbkxlUGHhrGW/UUD8DuBpMVlZWsHv3bkxPT8v7tFgsMmOgu7sbvb29iEajksqurKxgfHy8QiWjon2gdmfhpk2bEAgERGoHXL2Pj9kR14/7or6+Hm63G88//7zwv++99x4ASAswawQTExNYWFiA1+uFTqdDMplELpf7Em+/1mKxGPr6+hAIBCqG7zNr4ndkscrj8eDJJ58UCspms4li5J///CdOnz4t68EiYKFQgN/vl5+lU6/l3JiBkQpisGQ3YWtrK+bm5kR7zvZo/lwmk4HFYpH6CbPPUCgkozTpM1TVBff2jWY1nS5H56kpLR0hnSI3IH/earXK/7IiSSRGNKnVrl7DEQqFsHXrVhlzR+REyU61BgnyhuR2+EJ4FfRjjz2GDz74oIKGIGnPzje1MKPybb/5zW/EsfGQ8lCRf6tmfX19SKfTMv2IEiEOYaH+N5vNIpfLyVUupGo4DGhpaUm0pNTqAhARPFNjFjF5yKoZESfnmFJRwJSRkjkWLajC4GwDNgUAq1wkr18hauLhJMfIw0TJXjVTW37pYEkt8Sobu90Oj8cjQ60ByN4gBeDz+SrqD9S9qoOaaPw9tZxuNBoVWopI3Gq1VswXIFdMJ6IO47fZbFhcXMTDDz+M5eXViVuffvopxsbGkEgkYDKZoNPpMD8/L/uX3OrMzEzV53K73ZidnRVAAVy9pDUej4uEktpdUm/5fF7qAy6XC+VyGfv378c999wjUkoVkTKb4x1rkUgEn3/+edXnIpJXu1Z5lnlvml6vx3333YcvvvhCzkN9fT2sViump6clGJAKIhB699138eKLL4oCBLhK9awn4bxebd1CmvrvdIyUpJTLZdxzzz04ffq0OCbOR6Vsh46bU4e0Wi0ikQiKxSLGxsYkxQcg6ak6cehaRiTKZymVSnJZXblcFufG4hE5QjpfCtp5ZUgikUAsFkMoFJICDAl/HghKg2pxSGy8ACCtldwY5KrL5TLuuusunDlzBqFQSFpGKSPj87GQoF4jpA5XUQuZ6208lftSaSIeFDpUXmpIRA1ABsm43W5EIhHEYjF5FjZwqMGIzo8HpxYSIVXBAhk5Tlax+d+I5skP05mm02ls3rxZUDH3jFarRTQaFaqDlIU6LrPW7AVmaaSjCoUCFhcX4XA4ZFQovy/fBQuJGs3qNeiUR5ZKJfT398PlclWcH74zFjLD4TDefPPNmoiShWlmK1y3QqEgE+5I7ZCCYjGRgUQt7lFhwEyQ84O5V4eGhrBp0ybEYjH8/e9/r/pcvMeMIIXnhM0OVIx4PB40Nzfj8uXL0u2ZSqVgNBol2DJ4Mzu0Wq2Ym5uDy+US+R8psvXURNerrTvwBrha+Vb5U/ZZszLKw8uCVUPD6r1gLApxM6gVTrZ7qo6DqdB6BDl1jeQ7gavoW6fTYXh4GGfPnpXbdznhDIAI1On0yAFOT0+LmoCbmqiNRb5aSJecFTeRqsTgGiwvL8PpdFZceV0oFOB0OuH3+6X7JpVKiZoiFotVcOYqn6t2CFYzIhhVbsM1p4MEgJ07d2J6elo6y/j7FhYWZIo/izj8u6p6hZ/JZ6TUsJrR0aocI9eXhSL1O6iaUjp90kB0Fjzszc3NMmdXDQi0WoVH7lMWkdUmEGZ3DPzqdwFWB42rzoDZCAMZP5ND9EulkmRZ3/jGN6o+E7AaDNra2qSbjnQeKRDSSIlEQt4pn1u94p2/m2eNyJEggZ/H4OdwOPDAAw9UfS7SfXTwROKU19XV1VV0rK2srIgmnEGmrq5OppXx7Pj9fhgMBvzxj3/Ej3/8YwkkPOd0zjea1QwT6iHiQVJ5SraytrW1ieSFbaU0pu6MunS6oVBIhq/wM4l0AdR0brzmhVIpHjjqL0ulkjiJaDSKeDwu6IzOhJyS6jgaGhrg8/nEqXEjqlrRWmkpcDX14d+hI1lbdXW73WhtbZWUjFXpaDQqU/S5Hiq3TBSuIsi1a77W+K7Y2sqDyHdCrra3t1cGv/PdWCwWoUjYJlooFERArz4nU0BVH1sLifAmBTbJUOLH76Sup8PhgMViEX6b2VM0GhW6gI6SGmzWG9bWB9YWSNcasx11bgMAaUVVm1HUoML9od4aoqbFqoaZAY0aWJvNhltvvRW333571eeKRCIIBoMCVFRKjgiez8VzwaDKSWRULBDUsKmCem0qlRis+PNDQ0NVn4sqB74vvj8iXzZ0cO3Yck+1Bzlcggdmyo2NjXA6nfj000+xtLRUIUnkZ/3POV3gakWeTpFOki+Z0+sNBgOSySSSyaSk+kyF1e4Xjv0jqqPDUGcArDdPly9APRDcfEStdXVX75GKx+Ny3QsAaU+ldpAvur29HRcuXBDUrgr+mQrXks6ojRB0FnRC/O9EAt3d3ejo6BBUS96L6SbRpMVigcvlkj9Xi4fA1eLWemkWHYBKRRAtMBjyz5aXl4Xa4AQ5DsRmN9rKygra29tlXVXlgnrAaqk9GIC5r4iGVCcCrCLPvr4+dHV1yfhQBvLLly+LtCgUCiEej1ccdjoflZtXp+Rdy+igOFCFZyCdTguCY0cU0TWzjnA4XPHd+b34+5gJch0ZVKlIqPUeSXMYjUahLnie6HyWlpbkmbjf6EzJm/Jmbq41AzmdsnoLNKV6tZojYrGYFH2Bq5LOVColRT4CtcbGRvT29sqcDL/fL/uGg6KA1Uykq6sLnZ2d0Gg0OH/+vFxEwOxgPb319Wo1TyoPeD6fFxShah8piGbKEI/HMTMzI1OyisWiTP6iLAiAtBsODg5iYWFB0jVyrmuF/GuNbZ18WcViUegGVva1Wi0efPBBDA4OIpvNIhKJiIyIBZ7FxUVMTk5iYmJCnmFubg4AJI1W5VVM9asZi2esIjNAMfVX5/PyQPIammAwKEUuDrwhn1oul3H27NmKGxb49xkganGUVG6oKIRoiYeBf757927s2LFD6A1e9aLRaOR+sHK5jM7OTlgsFpw4cUIOLYs2rMazKFjN2trahFfm4VG7tlRHR7ke6aJcLoc9e/YgHA7j0qVLmJ+fRyQSQSKRkMM9Ojoq303NMrh3qhmHepMCYysv16hcXh1ETiTZ1NSEuro64SCJ8Nfq19ciUVWOyd9Xa26tTqeD1+tFe3s73G63IHKOLSXnmcvlpKbAbjEGtrq6OglOLALyyhuO+1TPutqkUmt/EQTxHfJ9Um2Sz+elCFssrt6J9+1vfxutra3SzarVauF0OmXuBvnepqYm/OpXv8LMzIx8R97A8j/XHMFNz+o2Iyh79smr6fV63H777TAYDDh79qxwSLw1gugwkUjA7/cjl8tJ7/Xvf/97PPPMM9iyZYsQ5DyI1QZgk3uivpEbmakdDy2H83CYcyKRgMFggM1mw8LCAnw+H/R6PXbu3IlisYjx8XEcPXpU7pri4SZCZLdYNWP0VSkAbpByuSzVb6aGg4ODsNlsePPNN7G0tCQIisVA6pvz+Tx++tOf4tVXX5WiFdNxSqRqORHKb0qlklzbwwNO7W4ikRDHvXXrVhgMBrz33nsVHVPc8BqNBvF4HMFgEB9//DH27dsnShPSDBy9WSszoHZbzVaIYihjI+/I4JVMJqWtnPx3JBKR+/iI+kdGRnD58mXs3btX9ir3xVpFzlqbmppCPB6XO9DsdrsADdJi6ntgMIzFYrDZbGhubsbS0pKk6XV1dYL2KGFk+q0qUajcqWbDw8OYnp5GOByucOT19fXweDxYXFyUz1KpjXQ6XTHek4iWe5N1kGg0ioaGBuk4JGpOp9OYn5+vqSHmoHJyrpyNTKqH9AX3UrlcRjgclsYptcGDTUmdnZ3I5XIYHBzEm2++iXA4jM7OTthsNjQ0NGB+fr7mNULXq2luRHi+YRu2YRt2o9qNp7fYsA3bsA27gW3D6W7Yhm3Yhv0XbcPpbtiGbdiG/Rdtw+lu2IZt2Ib9F23D6W7Yhm3Yhv0XbcPpbtiGbdiG/Rft/wFCNacGYoDy8AAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 26 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "simple_model_Adam.eval()\n",
        "import cv2 as cv\n",
        "for i in range(26):\n",
        "    s = str(i+1)\n",
        "    img = cv.imread(\"./my_images/\"+s+\".jpg\")\n",
        "    img=img.mean(axis=2)\n",
        "    img = cv.resize(img,dsize=(28,28))\n",
        "    plt.subplot(3,9,i+1)\n",
        "    plt.imshow(img,cmap='gray')\n",
        "    x = torch.from_numpy(img)\n",
        "    x=x.reshape(1,784)\n",
        "    pred = simple_model_Adam(x.float())\n",
        "    plt.title(str( alphabet[ torch.argmax(pred) ] ) )\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2368a1ca5b380b480dd91ba0f62cac26d6ae19a36801e0ad3d2e2ce0582ed2c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
